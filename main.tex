\documentclass[
% -- opções da classe memoir --
%oldfontcommands,
12pt,				% tamanho da fonte
openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
oneside,			% para impressão em verso e anverso. Oposto a oneside
a4paper,			% tamanho do papel.
% -- opções da classe abntex2 --
%chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
%section=TITLE,		% títulos de seções convertidos em letras maiúsculas
%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
%subsubsection=TITLE,% títulos de subsubseções convertidos em letras maiúsculas
% -- opções do pacote babel --
english,			% idioma adicional para hifenização
french,				% idioma adicional para hifenização
spanish,			% idioma adicional para hifenização
brasil,				% o último idioma é o principal do documento
]{abntex2}

% ---
% PACOTES
% ---
% ---
% Pacotes fundamentais
% ---
\usepackage{cmap}				% Mapear caracteres especiais no PDF
%\usepackage{lmodern}			% Usa a fonte Latin Modern
\usepackage{helvet}
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{lastpage}			% Usado pela Ficha catalográfica
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{color}				% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{underscore}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{graphicx} % Usado para outros tipos de imagens
\usepackage{float} % Usado para posicionamento de imagens
\usepackage[notransparent]{svg}  % Eis o pacote que queremos.
\usepackage{alltt}
\usepackage{filecontents}
\usepackage{listings}
\usepackage{subfiles}
\linespread{1.5} % espaçamento entre linhas
% ---
% Pacotes adicionais, usados apenas no âmbito do Modelo Canônico do abnteX2
% ---
\usepackage{lipsum}				% para geração de dummy text
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{listings}
\hypersetup{
	colorlinks=false,
	pdfpagemode=FullScreen,
	pdftitle={benchmark bancos de dados multi arquitetura},
}
\hypersetup{final}
\urlstyle{same}
\renewcommand{\backrefpagesname}{}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
\titulo{Benchmark de desempenho entre bancos de dados em diferentes arquiteturas}

\autor{Miguel Magalhães Lopes}
\local{Rio Pomba}
\data{2022}
\orientador{Msc. Gustavo Henrique da Rocha Reis}
%\coorientador{CICLANO}
%\instituicao{}
\tipotrabalho{Trabalho de Conclusão de Curso}

\preambulo{Trabalho de Conclusão apresentado ao Campus Rio Pomba, do Instituto Federal de Educação, Ciência e Tecnologia do Sudeste de Minas Gerais, como parte das exigências do curso de Bacharelado em Ciência da Computação para a obtenção do título de Bacharel em Ciência da Computação.}
\definecolor{blue}{RGB}{41,5,195}
\makeatother
\graphicspath{ {./imagens} }
% ---

% ---
% Espaçamentos entre linhas e parágrafos
% ---

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.3cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}  % tente também \onelineskip

% ---
% compila o indice
% ---
\makeindex
% ---

% ----
% Início do documento
% ----
\begin{document}
	\frenchspacing
	\begin{center}
		\textbf{
			INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNOLOGIA DO SUDESTE DE MINAS GERAIS - CAMPUS RIO POMBA}
	\end{center}

	\imprimircapa
	\imprimirfolhaderosto*

	\begin{fichacatalografica}
		\vspace*{\fill}					% Posição vertical
		\hrule							% Linha horizontal
		\begin{center}					% Minipage Centralizado
			\begin{minipage}[c]{12.5cm}		% Largura

				\imprimirautor

				\hspace{0.5cm} \imprimirtitulo  / \imprimirautor. --
				\imprimirlocal, \imprimirdata-

				\hspace{0.5cm} \pageref{LastPage} p. : il. (algumas color.) ; 30 cm.\\

				\hspace{0.5cm} \imprimirorientadorRotulo~\imprimirorientador\\

				\hspace{0.5cm}
				\parbox[t]{\textwidth}{\imprimirtipotrabalho~--~Instituto Federal de Educação, Ciência e Tecnologia do Sudeste de Minas, Campus Rio Pomba,
					\imprimirdata.}\\

				\hspace{0.5cm}

				\hspace{8.75cm} %CDU 02:141:005.7\\

			\end{minipage}
		\end{center}
		\hrule
	\end{fichacatalografica}
	% ---

	% ---
	% Inserir errata
	% ---
	%\begin{errata}
	%Elemento opcional da \citeonline[4.2.1.2]{NBR14724:2011}. %Exemplo:

	%\vspace{\onelineskip}
	%
	%FERRIGNO, C. R. A. \textbf{Tratamento de neoplasias ósseas apendiculares com
		%reimplantação de enxerto ósseo autólogo autoclavado associado ao plasma
		%rico em plaquetas}: estudo crítico na cirurgia de preservação de membro em
	%cães. 2011. 128 f. Tese (Livre-Docência) - Faculdade de Medicina Veterinária e
	%Zootecnia, Universidade de São Paulo, São Paulo, 2011.

	%\begin{table}[htb]
	%\center
	%\footnotesize
	%\begin{tabular}{|p{1.4cm}|p{1cm}|p{3cm}|p{3cm}|}
	%  \hline
	%   \textbf{Folha} & \textbf{Linha}  & \textbf{Onde se lê} % & \textbf{Leia-se}  \\
	%    \hline
	%    1 & 10 & auto-conclavo & autoconclavo\\
	%   \hline
	%\end{tabular}
	%\end{table}
	%
	%\end{errata}
	% ---

	% ---
	% Inserir folha de aprovação
	% ---

	% Isto é um exemplo de Folha de aprovação, elemento obrigatório da NBR
	% 14724/2011 (seção 4.2.1.3). Você pode utilizar este modelo até a aprovação
	% do trabalho. Após isso, substitua todo o conteúdo deste arquivo por uma
	% imagem da página assinada pela banca com o comando abaixo:
	%
	% \includepdf{folhadeaprovacao_final.pdf}
	%
	\begin{folhadeaprovacao}

		\begin{center}
			{\ABNTEXchapterfont\large\imprimirautor}

			\vspace*{\fill}\vspace*{\fill}
			{\ABNTEXchapterfont\bfseries\Large\imprimirtitulo}
			\vspace*{\fill}

			\hspace{.45\textwidth}
			\begin{minipage}{.5\textwidth}
				\imprimirpreambulo
			\end{minipage}%
			\vspace*{\fill}
		\end{center}

		Trabalho aprovado. \imprimirlocal, 00 de maio de 2022.

		\assinatura{\textbf{\imprimirorientador}, Orientador, IF Sudeste MG - Rio Pomba}
%		\assinatura{\textbf{CICLANO}, Coorientador, IF Sudeste MG - Rio Pomba}
		\assinatura{\textbf{Msc. Bianca Portes de Castro} \\ IF Sudeste MG - Rio Pomba }
		\assinatura{\textbf{Msc. Sérgio Muinhos Barroso Lima} \\ IF Sudeste MG - Rio Pomba }
		%\assinatura{\textbf{Professor W} \\ IF Sudeste MG - Rio Pomba}

		\begin{center}
			\vspace*{0.5cm}
			{\large\imprimirlocal}
			\par
			{\large\imprimirdata}
			\vspace*{1cm}
		\end{center}

	\end{folhadeaprovacao}
	% ---


	% ---
	% Dedicatória
	% ---
	\begin{dedicatoria}
		\vspace*{\fill}
		\begin{flushright}
			Este trabalho é dedicado a todos\\
			aqueles que me inspiraram e me ajudaram durante essa caminhada, em especial\\
			minha família e amigos.
		\end{flushright}
	\end{dedicatoria}
	% ---

	% ---
	% Agradecimentos
	% ---
	\begin{agradecimentos}
    
	\end{agradecimentos}

	% resumo em português
	\begin{resumo}
		\noindent
    Este trabalho busca trazer um comparativo entre as capacidades reais de um servidor AMD64 e um servidor ARM em ambiente de banco de dados.Foi desenvolvida uma metodologia e um algoritmo para que a comparação pudesse ser a mais direta possível e mais simples de se aplicar uma escalabilidade de desempenho comparado.Foram utilizados os bancos de dados MariaDB e Postgres para simular os mais diversos tipos de operações basicas em bancos de dados como seleção ,inserção e edição de dados.
    durante os testes foram utilizados Dockere limitações generalizadas no sistema operacional para que ambas as máquinas fossem o mais parecidas a nivel de hardware,sendo assim podendo ser consideradas iguais apenas com diferença em suas arquiteturas,ao final dos testes os resultados foram tão próximos que apenas no consumo energético ficaram realmente evidentes.
		\vspace{\onelineskip}

		\noindent
		\textbf{Palavras-chaves:} ARM. AMD64. benchmark. servidor. MariaDB. Postgres. comparativo.
	\end{resumo}

	% resumo em inglês
	\begin{resumo}[Abstract]
		\begin{otherlanguage*}{english}
			\vspace{\onelineskip}
			\noindent
    This work seeks to bring a comparison between the real capabilities of an AMD64 server and an ARM server in a database environment.A methodology and an algorithm were developed so that the comparison could be as direct as possible and simpler to apply a scalability of performance compared.MariaDB and Postgres databases were used.
			\vspace{\onelineskip}

			\noindent  \textbf{Key-words}:  ARM. AMD64. benchmark. server. MariaDB. Postgres. comparative.
		\end{otherlanguage*}
	\end{resumo}
	\urlstyle{same}

	\pdfbookmark[0]{\listfigurename}{lof}
	\listoffigures*
	\cleardoublepage

	\pdfbookmark[0]{\listtablename}{lot}
	\listoftables*
	\cleardoublepage

	\DeclareRobustCommand{\beginAutoTable}[4]{
		%nome da tabela e label
		%cabeçalho
		%quantidade total de colunas
		%formatação da tabela
		\label{tab:#1}
		\begin{longtable}{#4}
			\caption{#1}
			\\ \hline \multicolumn{#3}{c}{\textbf{#1}} \\ \hline
			#2 \\ \hline \endfirsthead
			#2 \\ \hline \endhead
		}
	\newenvironment{easyTableAuto}[4]{
		\beginAutoTable{#1}{#2}{#3}{#4}
		}{
		\end{longtable}
	}
	\newenvironment{easyTable2}[2]{
		\beginAutoTable{#1}{#2}{2}{p{.15\textwidth}|p{.80\textwidth}}
	}{
	\end{longtable}
}
\newenvironment{easyTable3}[2]{
	\beginAutoTable{#1}{#2}{3}{p{.16\textwidth}|p{.1\textwidth}|p{.70\textwidth}}
}{
\end{longtable}
}
\DeclareRobustCommand{\myref}[2]{
%\textit{#2}$^{\text{#1\ref{#1:#2}}}$
\textit{#2} \ref{#1:#2}
}
\newcounter{sig}
\DeclareRobustCommand{\sig}[1]{
\refstepcounter{sig}
\label{sig:#1}
\item[#1]
}
\newcounter{ch}
\DeclareRobustCommand{\ch}[1]{
\refstepcounter{ch}
\chapter{#1}
\label{ch:#1}
}
\newcounter{sec}
\DeclareRobustCommand{\sec}[1]{
\refstepcounter{sec}
\section{#1}
\label{sec:#1}
}
\newcounter{subsec}
\DeclareRobustCommand{\subsec}[1]{
\refstepcounter{subsec}
\subsection{#1}
\label{subsec:#1}
}
\newcounter{subsubsec}
\DeclareRobustCommand{\subsubsec}[1]{
\refstepcounter{subsubsec}
\subsubsection{#1}
\label{subsubsec:#1}
}
%\patchcmd{\verbatim@input}{\@verbatim}{\scriptsize\@verbatim}{}{}

\newcounter{anexo}
\DeclareRobustCommand{\anexo}[2]{
\refstepcounter{anexo}
\label{anexo:#1}
\lstinputlisting{{\detokenize{apendices/#2}}}
}

\newcounter{imagem}
\DeclareRobustCommand{\imagemsvg}[3]{
%lable
%arquivo
%caption
\refstepcounter{imagem}
\begin{figure}[htbp]
\includesvg[draft,width=\textwidth]{#2}
\caption{#3}
\label{imagem:#1}
\end{figure}
}
\DeclareRobustCommand{\imagempng}[3]{
%lable
%arquivo
%caption
\refstepcounter{imagem}
\begin{figure}[htbp]
\includegraphics[width=\textwidth]{#2}
\caption{#3}
\label{imagem:#1}
\end{figure}
}

\DeclareRobustCommand{\apendicesvg}[2]{
%lable
%arquivo
%caption
\refstepcounter{imagem}
\begin{figure}[htbp]
\includesvg[draft=true,width=\textwidth]{{\detokenize{#1}}}
\caption{#2}
\label{imagem:#1}
\end{figure}
}

\begin{siglas}
\sig{DACC} Departamento Acadêmico de Ciência da Computação

\sig{UFJF} Universidade Federal de Juiz de Fora

\sig{ARM} ARM, originalmente Acorn RISC Machine, e depois Advanced RISC Machine, é uma família de arquiteturas RISC desenvolvida pela empresa britânica ARM Holdings

\sig{x64} evolução da arquitetura \myref{sig}{x86} evoluida para 64 bit

\sig{AMD64} outra nomenclatura para \myref{sig}{x64}

\sig{x86} arquitetura 32 bit comum nos computadores domésticos atuais

\sig{aarch64} evolução 64bit da arquitetura \myref{sig}{ARM}

\sig{JVM} JVM (Java Virtual Machine) é uma máquina abstrata.É uma especificação que fornece um ambiente de tempo de execução no qual o bytecode do java pode ser executado.
As JVMs estão disponíveis para muitas plataformas de hardware e software (ou seja, a JVM depende da plataforma).

\sig{IOT} internet das coisas,

\sig{SBC} single board computer,ou computador de placa única,é um tipo de computador utilizado hoje em dia em que no mesmo chipset você encontra todas as estruturas principais do computador estão juntas obrigatoriamente os SBC possuem CPU e memória RAM e podem conter outras estruturas de um computador como a ponte norte e a ponte sul

\sig{SoC} System on a Chip,outra nomenclatura para \myref{sig}{SBC}

\sig{WINE} O Wine é uma camada de tradução capaz de executar aplicações Windows em Linux e em outros sistemas operacionais compatíveis com POSIX

\sig{die} circuito integrado composto de material semi condutor gravado a laser que contem as trilhas eletrônicas dentro de um processador de computador

\sig{TPU} tensor processing unit,é uma hardware dedicado para processamento de inteligencia artificial desenvolvido pela google que é um ASIC, application-specific integrated circuits, um cirquito integrado de aplicação especifica, assim como uma GPU é um ASIC para equações matemáticas de matriz

\end{siglas}


\tableofcontents*

\textual
\setcounter{page}{1}
% ---------------------------------------------------------------------------------------------
% Introdução
% ---------------------------------------------------------------------------------------------
\chapter*{Introdução}
\addcontentsline{toc}{chapter}{\textbf{Introdução}}
\markright{Introdução}
\label{ch:introducao}
Com a  crescente adoção de processadores com arquitetura \myref{sig}{ARM} que entregam eficiência energética superior a comumente utilizada nos computadores e servidores convencionais (arquitetura \myref{sig}{x86}), que também tem uma versão com arquitetura de 64 bits (\myref{sig}{x64}), se torna necessária uma reavaliação sobre a possível substituição dos computadores existentes pelos com processador \myref{sig}{ARM}.
Esta pesquisa foi desenvolvida considerando o uso de servidores \myref{sig}{ARM} presentes no mundo corporativo, de tal forma que foi feita uma comparação na utilização deste tipo de processadores para a simulação de uma aplicação de banco de dados. Essa aplicação simula, de forma realística, a utilização de uma base de dados de uma locadora de filmes.\newline

Para que pudessem ser comparadas as arquiteturas, foi escolhida a opção de se executar um benchmark para compará-las, o benchmark é um processo em que a máquina tem uma alta carga de uso aplicada sinteticamente para que possam ser registrados os dados de uso de hardware, e com isso encontrar valores numéricos para se utilizar de comparação com outros resultados desse benchmark em outras máquinas. Para que um benchmark seja válido é necessário que a mesma coisa seja testada em mais de uma máquina, neste caso foi selecionado o teste de operações de bancos de dados distintos de forma padronizada, já que os testes são feitos de forma padronizada, esses testes podem ser replicados em qualquer arquitetura de hardware e no final são comparáveis por conta disso.\newline

Para que pudesse ser testados os dados de uso de CPU, RAM e disco foi criado um programa para a geração de dados baseado na biblioteca Faker implementado na linguagem Python, os dados são gerados para cada país, em idiomas e caracteres compatíveis com a região escolhida, o que permite que estes dados como, nome, telefone, endereço e até mesmo usuário e senha sejam compatíveis com a região escolhida. Essa forma de inserção foi escolhida, já que um preenchimento de dados totalmente aleatórios e de tamanho fixo, poderia apresentar discrepância em relação ao desempenho em um ambiente real de uso, afetando tanto o tempo, quanto a carga dos processadores de forma negativa. Os dados utilizados em cada ciclo de teste foram exatamente os mesmos, simulando o uso em ambiente real, desta forma o benchmark se torna aplicável à realidade e de mais fácil comparação de desempenho que outros mecanismos de benchmark encontrados.\newline

Com os resultados dos testes de benchmark obtidos foi esperado encontrar alguma prova se a arquitetura AMD64 é substituível pela arquitetura aarch64 em servidores, já que o maior custo de manutenção de servidores em empresas é o gasto energético, e o gasto energético de um processador ARM é muito menor que o de um processador x86.\newline
Durante os próximos capítulos foram descritas:
\begin{itemize}
    \item Fundamentação teórica, capítulo 1: explica as tecnologias e programas utilizados durante a pesquisa;
    \item Trabalhos relacionados, capitulo 2: capítulo onde são referenciados e explicados trabalhos relacionados ao apresentado neste texto, mostrando pontos e ideias relevantes que os respectivos autores encontraram durante suas pesquisas;
    \item Testes, capitulo 3: neste capítulo são descritos os testes que foram feitos e o que cada um testou;
    \item Metodologia, capitulo 4: nesta parte do texto é apresentada a metodologia e é explicadas as bibliotecas criadas para o programa, assim como o próprio programa base e como os dados foram processados após o término dos testes;
    \item Resultados, capítulo 5: nesse capítulo são explicados os resultados obtidos em cada um dos testes que foram detalhados no capítulo 3, apresentando uma análise de seus resultados e conclusões obtidas em cada um deles, assim como os problemas que foram encontrados durante o decorrer dos testes e do desenvolvimento;
    \item Conclusão, capítulo 6: por fim nesse capítulo os resultados do capítulo 5 são analisados como um todo e é encontrado o resultado final do texto onde é explicado o que foi concluído com o benchmark feito.
\end{itemize}


\ch{Fundamentação teórica}

\sec{Virtualização}
Virtualização é uma técnica usada para simular um computador dentro de outro, dependendo do método utilizado ele pode simular apenas uma camada, ou mais de uma das camadas de hardware e software de um computador. Um sistema virtualizado pode receber vários nomes de acordo com o método utilizado para virtualizar, alguns dos mais utilizados atualmente são máquinas virtuais e containers Docker, onde a principal diferença deles é a camada de hardware na qual ele é executado.

\sec{Máquina virtual}
Uma máquina virtual é executada como um programa dentro de um sistema operacional, elas possuem várias limitações, dentre elas, um menor desempenho de processamento, além de não permitir acesso a outros hardwares do computador.
Majoritariamente neste tipo de virtualização é permitido o acesso direto à memória principal, aos dispositivos de armazenamento de dados e a hardwares plug’n’play como dispositivos de entrada e saída USB. 
Entretanto, não é possível utilizar placas de vídeo ou outros hardwares PCI de forma eficiente.


\sec{Arquiteturas}
Por definição, arquitetura de computador é um conjunto de circuitos eletrônicos padronizados associados a um conjunto de instruções, de forma a simplificar a programação para que executem comandos diferentes do binário, os compiladores utilizam esse conjunto de instruções para que o código de uma linguagem de programação de alto nível seja convertido para uma de baixo nível. A arquitetura também define e limita várias propriedades do hardware, como quantidade máxima de RAM, de armazenamento, suporte de saída de vídeo, capacidades de rede, entre outros.\newline

%Uma micro arquitetura é quando adiciona-se tanto um circuito eletrônico novo ao circuito original da arquitetura quanto apenas uma simplificação ou reorganização dos comandos originais de uma arquitetura,
%entretanto, em uma micro arquitetura essas modificações são muito pequenas de forma a serem mais similares a arquitetura original do que uma nova arquitetura.
%Dessa forma as micro arquiteturas podem ser consideradas updates de uma arquitetura e quando são acumulados muitos desses updates, pode ser que seja gerada uma nova arquitetura,
%como foi o caso da arquitetura \myref{sig}{x86} para a arquitetura \myref{sig}{x64}, onde nesta última foi um upgrade grande o bastante da \myref{sig}{x86} a ponto de ser considerado uma nova arquitetura.
%A principal e mais visível diferença entre esses dois é a mudança de 32bit(na \myref{sig}{x86}) para 64bit(no \myref{sig}{x64}).\newline

As arquiteturas também podem ser definidas além da CPU, o que inclui a GPU, \myref{sig}{TPU} e vários outros módulos de hardware de um computador. Inclusive existem arquiteturas especiais que são aplicadas em nível de software, que não são necessariamente arquiteturas de computador, mas sim um tipo diferente de arquitetura, 
que existem em máquinas abstratas e que simplificam a programação de uma linguagem para que ela funcione com maior compatibilidade em várias máquinas de arquiteturas e de hardware diferentes. 
Portanto, se faz necessário otimizações na parte do código e da máquina abstrata, como o caso da \myref{sig}{JVM} da linguagem Java.\newline

No entanto, as arquiteturas não são limitadas apenas a esses exemplos previamente citados, elas também podem estar presentes em todos os tipos de circuitos integrados, como por exemplo os processadores de roteadores e aparelhos \myref{sig}{IOT}, tais como lâmpadas e tomadas inteligentes.
Isso quer dizer que uma arquitetura não necessariamente é algo que precise de um hardware potente ou que só funcione ou exista em computadores, mas sim a forma como os algoritmos são interpretados no hardware, sendo eles algoritmos como softwares de computador ou como sequências de instruções realizadas por alguém.
Sendo assim, desde que exista um software e um hardware que se comuniquem, existe uma arquitetura e provavelmente houve uma conversão da linguagem de programação para a linguagem de máquina dessa arquitetura neste dispositivo.\newline

Após o lançamento dos MacBooks de 2020 com processador M1, que funcionam com a arquitetura \myref{sig}{aarch64}, a Apple lançou uma camada de compatibilidade dos softwares com arquitetura \myref{sig}{AMD64} para \myref{sig}{aarch64} chamado de Rosetta2 esse software funciona parcialmente como um emulador, exceto que ele faz as adaptações num nível mais próximo do da máquina real e do sistema operacional nativo da máquina, resultando num desempenho muito superior a qualquer emulador existente. O Rosetta2 funciona de forma análoga ao projeto \myref{sig}{WINE} do Linux que reinterpreta os programas do Windows para funcionarem no Linux,em alguns casos essa conversão leva a uma pequena perda de desempenho por esse processo de reinterpretação, em outros essa perda é bem mais visível, e podendo até mesmo, em raros casos, ocorrer um ganho de desempenho em comparação com o sistema original.\newline

Existem arquiteturas com propósitos diferentes, como o caso dos processadores \myref{sig}{ARM} que foram pensados para entregar uma grande eficiência energética, enquanto os processadores \myref{sig}{x86} foram pensados para apresentarem grande poder de processamento independentemente do consumo energético. Entretanto, o principal propósito da arquitetura \myref{sig}{ARM} não é se diferenciar tanto da arquitetura \myref{sig}{x86}, mas sim tornar os computadores mais energeticamente eficientes, um exemplo disso é que um computador doméstico comum utiliza de 200 a 300w por hora, enquanto um computador raspberry pi 4, que é o computador \myref{sig}{ARM} mais potente da marca mais popular dentre os \myref{sig}{SBC} atualmente, consome em torno de 15w por hora. É uma grande diferença, principalmente levando em consideração que ambos têm a possibilidade de rodar os mesmos programas open source de Linux, tanto editores de texto, navegadores de internet quanto IDEs de programação que estão disponíveis para ambos. Para um usuário médio não existe limitação ao se migrar de um para o outro.\newline
\begin{easyTableAuto}{Tabela comparativa da filosofia de implementação RISC X CISC}{Comparativo & RISC & CISC}{3}{p{.3\textwidth}|p{.3\textwidth}|p{.3\textwidth}}
Funcionamento das instruções & instruções atômicas & instruções complexas\\ \hline
Ciclos de clock necessários & uma instrução por ciclo & vários ciclos por instrução \\ \hline
Acesso a RAM & instruções dedicadas para isso & varias instruções fazem isso\\ \hline
Tamanho das instruções & tamanho fixo & vários tamanhos diferentes \\ \hline
Quantidades de instruções & somente o essencial para otimizar o uso de CPU & todas possíveis para simplificar a programação \\ \hline
Pipeline & existe desde o principio & implementado posteriormente \\ \hline
\end{easyTableAuto}

As operações RISC são o mais simples possível e diversos métodos de programação diferentes são necessários para que algumas operações sejam realizadas, isso apesar de tornar a execução mais otimizada, também faz com que a programação seja mais difícil.
As operações de um processador levam uma quantidade definida de pulsos elétricos gerados por um cristal oscilador para serem executadas, um ciclo equivale ao número de oscilações por segundo que o cristal consegue fazer.\newline

Nos processadores RISC existem apenas duas instruções que conseguem acessar a RAM, todas as operações e instruções são lidas para o cache do processador e apenas utilizadas as que se encontram dentro dele, já que após uma operação ter sido encerrada o resultado dela é movido para a RAM. A memória RAM apenas é acessada antes da operação de um processador RISC ter sido terminada caso não haja espaço suficiente no cache do processador para a operação ser concluída, nesse caso os dados seriam alternados entre a RAM e o cache do CPU o mínimo de vezes possíveis.\newline 

No entanto, essa forma de troca de dados entre o cache e a RAM não ocorre no CISC, onde várias operações podem ter essa movimentação de dados entre cache e RAM mesmo se ainda houver espaço no cache do CPU.
Os processadores RISC desde os seus primórdios buscaram utilizar pipelines para otimizar o tempo de uso de CPU, o que não pode ser dito dos processadores CISC.

\subsec{ARM}
A arquitetura \myref{sig}{ARM} é baseada na arquitetura RISC, uma arquitetura de processadores concorrente da CISC que veio a se tornar a \myref{sig}{AMD64}, a primeira revisão da arquitetura \myref{sig}{ARM}, chamada de ARM-1, foi lançada em 1985, no mesmo ano foi lançada a segunda revisão ARM-2, que apresentava mais funcionalidades e desempenho no mesmo tamanho de \myref{sig}{die}, já em 1989 foi lançada a terceira revisão, chamada ARM3 operando a 25MHz.
De forma geral a arquitetura ARM sempre apresentou \myref{sig}{die} menor e mais eficiente em comparação com a arquitetura \myref{sig}{x86} e suas variantes, o principal foco de mercado das primeiras revisões da arquitetura ARM foram sistemas embarcados que não dependiam de tantas operações por segundo em comparação com computadores convencionais como servidores, computadores de mesa e notebooks.\newline

Com o tempo a arquitetura ARM alterou o ARM3 até que chegou a arquitetura ARMv6 \cite{ARMv6Manual} onde ela começou a ficar comparativamente mais potente ao ponto de ser mais amplamente utilizada. Após essa revisão, lançada por volta de 2007, a arquitetura ARM começou a ser amplamente utilizada para computação com o advento dos smartfones como conhecemos hoje em dia \cite{histARMEmbarcados}.
A arquitetura ARM passou por mais 3 grandes revisões após o ARMv6, chamadas \cite{ARMhist}:
\begin{itemize}
 \item ARMv7: foi a arquitetura mais amplamente utilizadas em smartfones no principio do Android, iOS e Windows Phone. Isso devido aos seus ganhos em economia energética e processamento em relação ao espaço necessário para o processador funcionar corretamente em relação as outras alternativas existentes no mercado;
 \item ARMv8: foi a primeira implementação oficial das instruções 64bit, também conhecida como \myref{sig}{aarch64}, essa foi a revisão que possibilitou a criação dos tablets e notebooks com processador ARM que existem atualmente;
 \item ARMv9: é a revisão mais atual da arquitetura, nela foram implementadas várias partes dedicadas a propósitos específicos, como criptografia, virtualização e outras aplicações mais específicas como inteligência artificial. Essa revisão possui 3 ramificações cada uma focada para um dos ramos que a ARM trabalha, são eles: aplicações gerais, processadores e micro controladores; onde cada uma possui cortes ou ampliações para melhor se adequar ao propósito.
\end{itemize}

\sec{Bancos de dados}
Banco de dados é um método de armazenamento de dados de forma estruturada para que as informações sejam associadas e consultadas com mais rapidez. Os dados também podem ser armazenados de forma a economizar espaço de armazenamento e, dependendo da otimização do banco de dados, também dá a possibilidade de realizar redundâncias de segurança dos dados.\newline

Sistemas de computadores, dos mais diversos tipos, utilizam banco de dados para armazenamento de suas informações. Dessa forma, as informações ficam estruturadas em um formato padrão, o que permite acesso rápido a elas. Os tipos de bancos de dados analisados são sistemas SQL relacional (os mais genéricos), de forma que podem ser utilizados no máximo de aplicações diferentes possíveis. Isso faz com que esses tipos de sistemas sejam os melhores para serem simulados.\newline

A partir dessas características, justifica-se a escolha dos bancos de dados como meio do benchmark realizado para essa comparação de arquiteturas.\newline

\sec{Docker}
Docker é um sistema de virtualização de máquinas que busca simplicidade no gerenciamento e entrega de desempenho do hardware real da máquina que está sendo usada. Este sistema executa as chamadas de seus ambientes virtualizados, nomeados de contêineres, no mesmo nível do sistema operacional, logo acima do Kernel do sistema, isto possibilita dedicar parte do hardware da máquina real para um contêiner. E permite, dentre outras possibilidades, reservar de forma fixa porções do hardware, como por exemplo, definir limite de memória RAM ou quantidade de núcleos de CPU utilizados.\newline

Outra funcionalidade do Docker é a implementação de volumes, que é a forma de isolar as pastas do contêiner, e mantê-las mesmo se houver a necessidade do contêiner ser reinstalado para realizar atualização.\newline

O Docker foi desenvolvido a pedido da Google utilizando a linguagem GO, desenvolvida pela própria empresa, e ele foi criado visando a simplificação da gerência dos clusters de processamento da Google, que utilizam dezenas de computadores mais fracos para fazer o processamento. Portanto essa implementação tem um menor custo para compor um ambiente de processamento tão potente quanto em um ambiente com poucas máquinas de maior valor. O Docker também facilita a manutenção devido à fácil reimplementação de um contêiner caso a máquina tenha algum problema \cite{dockerdoc}.

\subsec{Contêiner Docker}
Um container Docker executa em um nível logo acima do Kernel, isto permite que qualquer dispositivo, ou dado disponível na máquina real do usuário, possa ser acessível por um container Docker. Além disso, ele possui maior eficiência de uso de memória RAM e de CPU em comparação às máquinas virtuais ou outros métodos de virtualização.\newline

Os containers Docker são imaginados para isolar programas do sistema operacional da máquina real, evitando que algum problema ocorra com o programa e afete a máquina real do usuário e em muitas situações são utilizados como sistemas de desenvolvimento virtualizados, facilitando a replicação e correção dos problemas durante a criação de um programa.\newline

Além disso, os Containers também costumam ter implementação mais simples e rápida do que máquinas virtuais, visto que eles utilizam imagens Docker para sua criação, que são geradas a partir de arquivos Dockerfile ou a partir de um repositório.\newline


\subsec{Dockerfile}
Os arquivos dockerfile são mais leves de transportar, mas demoram mais para serem instalados, uma imagem instalada dessa forma segue todos os parâmetros de criação de um script de instalação. Sendo assim, caso algum programa tenha sido especificado para ser compilado durante a instalação de  uma imagem, o mesmo será compilado todas as vezes que esta imagem for instalada. Ademais, os arquivos dockerfile também facilitam a modificação de uma imagem caso seja necessário.\newline

\subsec{Imagem Docker}
Uma imagem Docker é gerada a partir de um arquivo dockerfile, e a principal diferença é que uma imagem Docker,  após feito o download, é extraída na máquina onde o contêiner Docker será executado. Uma imagem é composta de snapshots que correspondem às etapas de execução de uma dockerfile, ou seja, quando o download é realizado, apenas as partes diferentes de uma dockerfile previamente adquirida é baixada, o que facilita a atualização de contêineres.\newline

As imagens Docker são distribuídas de duas formas: a partir de repositórios semelhantes aos dos sistemas Linux ou a partir de arquivos compactados, os repositórios são o método mais utilizado para se distribuir essas imagens, sendo que o principal repositório é o Dockerhub, o repositório oficial do Docker.\newline



\sec{Docker-compose}
É um método de implementação de contêineres Docker que utiliza um arquivo de implementação para facilitar sua replicação, comumente utilizado junto de um arquivo de variáveis de ambiente .env. Esse arquivo contém variáveis para serem utilizadas na implementação do stack de contêineres, fazendo com que o mesmo arquivo docker-compose possa ser utilizado em mais de um ambiente ou em máquinas diferentes \cite{dockercomposedoc}.\newline


\sec{Elasticsearch monitoring stack}
É um conhecido método open-source de monitoramento de logs, ele se baseia em três programas: Elasticsearch (indexador e processador de logs), Logstash (receptor e monitorador de logs) e Kibana (interface web para monitorar e trabalhar a exibição dos dados coletados), por isso é conhecido como ELK stack. Esses programas são baseados em Java e consomem uma quantidade considerável de memória RAM, motivo pelo qual o programa foi executado em uma máquina dedicada, para não influenciar na análise de desempenho das arquiteturas monitoradas.\newline

O ELK stack foi utilizado sem qualquer um dos seus plugins de processamento de informações, fazendo uso apenas do Elasticsearch para filtrar os resultados encontrados, e gerar os gráficos exibidos neste trabalho a partir de uma aplicação que utiliza seus dados.\newline

\sec{Portainer}
Portainer é um painel de administração do Docker, com o objetivo de simplificar a administração e configuração de várias opções mais complexas do Docker. Inclusive facilitando a definição de uso do hardware que será usado por cada contêiner, e facilitando o backup e download dos volumes e imagens criados, assim como a atualização dos mesmos para versões mais novas.\newline

O Portainer permite controlar, a partir de diversos métodos, múltiplas máquinas executando docker com um controle unificado e simples. Além disso, a interface web permite também a execução de comandos Shell e a atualização dos contêineres de forma simplificada.\newline

Outra característica interessante é a possibilidade de unificar a administração dos diversos servidores utilizados durante o desenvolvimento e testes, sendo necessário apenas instalar o Portainer em um deles, e nas outras máquinas apenas a ativação da conexão remota pelo Docker socket. Desta forma o monitoramento de logs, uso de hardware e outros podem ser feitos diretamente pelo navegador \cite{portainer}.\newline


%\section{biblioteca faker}
%\label{sec:biblioteca faker}
\sec{Biblioteca Faker}
A biblioteca Faker é conhecida para a geração de \textit{mock data}, que são dados gerados aleatoriamente para testar a capacidade de um algoritmo em lidar com dados. Comumente utilizada na etapa de testes de um algoritmo, seja para testes de segurança, para se proteger de scripts automatizados de criação de contas ou algo semelhante, e também é utilizado para testes de estresse quanto para qualquer tipo de teste que dependa de dados reais.\newline

Essa biblioteca foi selecionada, pois é de fácil utilização e compreensão, e possui documentação abrangente e suporte para múltiplos idiomas.
Ainda que a biblioteca suporte todos os tipos de geração mais completos na localização dos EUA, possui um tipo que corresponde a todo um perfil de usuário, contendo desde endereço até força de senha. Entretanto, para propósitos de testes, foram gerados apenas dados na localização do Brasil \cite{faker}.\newline

%\section{biblioteca psutil}
%\label{sec:biblioteca psutil}
\sec{Biblioteca PSutil}
O PSutil (Python System and Process Utilities) é uma biblioteca multiplataforma para recuperação de informações na execução de processos, e utilização do sistema (CPU, memória, discos, redes, sensores). Essa biblioteca é muito útil para sistemas de monitoramento, limitação de recursos de processamento, perfil e gerenciamento de processos em execução, e implementa também funcionalidades oferecidas por linhas de comando e de sistemas baseados em UNIX tais como: ps, top, lsof, netstat, ifconfig, who, df, kill, free, dentre outros \cite{psutil}.\newline

%\chapter{Trabalhos Relacionados}
%\label{ch: trabalhos relacionados}
\ch{Trabalhos Relacionados}

\sec{Um comparativo entre performance de bancos de dados MariaDB e MySQL com carga OLTP}%{A Comparison of Database Performance of MariaDB and MySQL with OLTP Workload}
Neste trabalho foram utilizados vários tipos de bancos de dados além do Postgres e do MariaDB para a comparação de performance, sendo o foco principal entre MariaDB e MySQL, além disso, foram monitorados CPU e memória RAM, e durante os testes foi usado um hypervisor chamado XEN nas máquinas com plataforma \myref{sig}{AMD64} e foram usados 4 GB de memória RAM nas máquinas dos testes. A mesma estrutura de BD foi utilizada em todos os servidores.\newline

MariaDB e MySQL foram muito próximos em relação ao desempenho no primeiro teste, e no segundo teste MariaDB foi ligeiramente mais pesado em relação a CPU que MySQL \cite{MariaDBMySQLOLTP}.\newline
% \imagempng{valores encontrados oltp mariadb}{artigos relacionados/oltp mariadb.png}{valores encontrados para o container mariadb para o 1 teste no artigo citado}
% \imagempng{valores encontrados oltp mysql}{artigos relacionados/oltp mysql.png}{valores encontrados para o container mysql para o 1 teste no artigo citado}
\newline\newline

\sec{Automação do Docker Swarm em SoCs ARM com suporte a MPI e análise de desempenho}%{Automatisation de Docker Swarm sur SoCs ARM avec support MPI et Analyse des Performances}
O artigo aborda uma análise de desempenho de Docker Swarm em \myref{sig}{SoC} \myref{sig}{ARM} onde foi usado MPI como base para os aplicativos. O sistema base dos contêineres é o Alpine Linux e foi utilizado em um ambiente onde uma ferramenta externa configura o ambiente MPI para processamento, Dessa forma foi possível automatizar a implementação e monitoramento do Docker Swarm.\newline

Uma das ferramentas utilizadas é o processo de escaneamento das conexões ativas, usando o netstat para simular o monitoramento do Swarm de forma externa ao docker, e o método usado para experimentar a plataforma virtualizada foi o WRF, que é um método de previsão do tempo.\newline

Para o ambiente de testes foram utilizados mini computadores Raspberry Pi versões 2 e 3, Nano Pi Neo, NTCP chip e Banana Pi, onde o ganho de desempenho de execução entre múltiplos núcleos é maior que o ganho de desempenho de múltiplas máquinas, segundo os autores do artigo. A porcentagem de ganho entre usar todos os núcleos do Raspberry é de 71\%, mas ao usar processamento dentro do swarm, a aceleração é de 17\% de 1 a 2 máquinas e de 2\% de 2 a 3 máquinas. De acordo com o autor, isso ocorre devido a baixa velocidade de comunicação entre os Raspberry Pi 3, ou seja, devido ao próprio \myref{sig}{SoC} dele.\newline

Levando em conta o custo, para essa aplicação o uso de \myref{sig}{SoC} é viável, já que o WRF consegue apresentar resultados básicos diariamente ou até mesmo em intervalos de uma hora, de acordo com os resultados apresentados, o desempenho multi-core de apenas uma máquina é quase o mesmo que o de duas máquinas com multi-core em paralelo \cite{DockerSwarmsocmpi}.


\sec{Um estudo comparativo dos efeitos da paralelização em plataformas baseadas em ARM e Intel}%{A comparative study of the effects of parallelization  on arm and intel based platforms}
Este artigo utiliza a mesma proposta abordada nesta pesquisa, cada vez mais máquinas \myref{sig}{ARM} são utilizadas ao redor do mundo, tendo em vista que hoje em dia todos celulares utilizam processadores \myref{sig}{ARM} e os computadores estão começando a adotar essa arquitetura. O artigo aborda os múltiplos métodos de paralelização que são utilizados pelo autor  para realizar os testes, assim como as diferenças das implementações entre Intel e \myref{sig}{ARM}, já que no processador \myref{sig}{ARM} é impossível usar a GPU para os testes, devido ao sistema operacional utilizado não possuir drivers que possibilitasse esse uso.\newline

Como métricas de monitoramento utiliza-se o total de frames por segundo (fps), visto que os algoritmos utilizados são algoritmos de processamento de imagem e potência em joule (J) utilizada pelas máquinas analisadas. O monitoramento de fps era feito por um monitor interno ao CPU e não um sistema externo, e várias das aplicações foram otimizadas para que funcionassem da melhor forma possível em cada CPU, de forma que na otimização interferisse o mínimo possível nos resultados dos testes. Essas otimizações foram feitas em forma de Kernels compilados diferentemente para o algoritmo.\newline

A partir das métricas coletadas, o autor calculou aproximadamente o total de energia gasta para processar cada frame, ou seja, o total de energia gasto pela função do código no método serial que é o único exatamente igual em ambos. Existe uma diferença sutil, mas com maior eficiência energética por parte do processador \myref{sig}{ARM}, visto que após ser levado em conta o consumo e a quantidade de frames gerados, é aplicada uma fórmula para comprovar a eficiência energética dos dispositivos utilizados.
ao ser usado um dos vários Kernels diferentes, existe uma velocidade de processamento exponencialmente maior por parte da Intel que por parte do \myref{sig}{ARM} no melhor cenário, no pior, a velocidade por parte da Intel é 10 vezes maior que do \myref{sig}{ARM}.\newline

O resultado é que nos melhores casos de cada Kernel, o fps/J é maior no Intel que no \myref{sig}{ARM}. Mas essa diferença é sutil em um dos Kernels e alta em outro, onde no ultimo teste, que foi o pior teste de cada plataforma, foi observada uma eficiência em torno de 8.5 vezes maior no \myref{sig}{AMD64} em relação ao \myref{sig}{ARM}. Portanto concluímos que para um dos testes, teste SRAD, o ultrabook AMD utilizado é claramente superior, nos outros testes sua superioridade nos valores de fps não eram tão evidentes.
Entretanto o consumo energético do \myref{sig}{ARM} é 20\% menor no pior cenário, e no melhor é 60\% menor que o do \myref{sig}{AMD64} e seu consumo médio é de 50\% do consumo do \myref{sig}{AMD64}\cite{armvsintel}.\newline

Como conclusão sobre os valores apresentados, foi possível comprovar que 8 anos depois, as placas \myref{sig}{ARM} existentes consomem o mesmo tanto de energia, mas possuem muito mais poder computacional. Enquanto que os computadores \myref{sig}{AMD64} portáteis, como o ultrabook utilizado, apesar de também consumirem uma quantidade equivalente de energia, não teve um ganho de performance tão grande quanto os computadores \myref{sig}{ARM}.\newline


\sec{KVM, Xen e Docker: uma análise de desempenho para NFV baseado em ARM e computação em nuvem}%{KVM, Xen and Docker: a performance analysis for ARM based NFV and Cloud computing }
Trata-se de um estudo comparativo, onde os testes de desempenho são feitos com softwares  de benchmark que simulam o uso de servidor, estes benchmarks sintéticos foram usados para encontrar um sistema de virtualização com melhor performance para a virtualização de funções de rede para a arquitetura \myref{sig}{ARM}. Neste estudo foram utilizados KVM, Xen e Docker, estes métodos de virtualização conceituados nos servidores comerciais foram selecionados com o propósito de provar qual deles funciona melhor para entregar maior poder bruto de performance, enquanto mantém os aspectos de segurança necessários de um ambiente de mundo real.\newline

Este estudo aborda as diferenças entre containers e hypervisors que se baseiam principalmente no fato de que os  containers utilizarem os recursos diretamente do Kernel da máquina física, enquanto os hypervisors buscam virtualizar tudo e simular um hardware em cada aplicação virtualizada. No artigo são abordadas as vantagens para cada método de virtualização, as principais do container são que nele o acesso ao poder computacional bruto é maior e  nos hypervisors as camadas de segurança são maiores.\newline

Dentre os dados encontrados, vale ressaltar que o Docker apresentou em média um resultado inferior quando comparado a velocidade de leitura e escrita em relação aos outros métodos de virtualização, apesar dessa diferença ser bem pequena numa aplicação de mundo real, onde a diferença não chega a 100 bps na maioria dos casos.\newline

Outro ponto a se destacar é que na velocidade de transferência de rede o Docker apresentou, durante os testes,  valores mais lentos quando utilizados pacotes de poucos bytes, sendo que para pacotes de até 4 bytes os valores eram em média iguais, mas para pacotes de 8 a 32 bytes as diferenças de velocidade eram consideravelmente maiores, nos quais o Docker chega a ser cerca de 20 mbps mais lento que os outros métodos. Para pacotes maiores que isso, todos os métodos utilizam ao máximo a capacidade de transferência de rede do hardware utilizado (100 mbps).\newline

Em conclusão, a autora disse que o KVM é mais simples de se portar para o \myref{sig}{ARM} em comparação ao Xen, já que o QEMU, no qual o KVM se baseia, existe em todas as arquiteturas e o Docker também já existe nativamente para o \myref{sig}{ARM}. As leituras de disco e rede funcionam melhor nos hypervisors devido aos métodos de cache que ele possui e o Docker não, outra informação que foi possível perceber também é que para pacotes grandes, as velocidades de todos os métodos comparados são iguais ou maiores que a implementação nativa em todos os testes de performance. A diferença entre eles é bem pequena, e varia de acordo com o teste, sendo assim o ideal seria uma solução mista onde seriam utilizado um método de virtualização dentro do outro para melhorar a escalabilidade e segurança, além de outros fatores dos ambientes reais\cite{KVMXenDocker}.

\sec{O Raspberry Pi: uma plataforma para benchmarks de desempenho replicáveis?}%{The Raspberry Pi: A Platform for Replicable Performance Benchmarks?}
As vantagens do uso do Raspberry Pi para benchmark, incluem sua facilidade de replicação usando SSH e Raspbian, e mostra as diferenças de resultados entre os diferentes Raspberry Pis usados nos testes. Os dados mostram que os resultados são bem aproximados, porém não são os mesmos.\newline

Os Raspberry Pi usados foram o modelo 3, eles foram comprados do mesmo vendedor com um intervalo de duas semanas, para se provar que o dispositivo poderia ser de fácil replicação. Adicionalmente, foi comprado um terceiro Raspberry Pi de outro vendedor com um intervalo de diferença de alguns meses entre este e os dois anteriores, para comprovar que lotes de fabricação diferentes não influenciam a replicabilidade do dispositivo. Foi utilizada uma imagem de instalação padronizada, modificada pelos autores, usando como base o sistema operacional oficial da época: o Raspbian, isso foi feito para manter uma diferença zero em relação aos softwares usados, e a única diferença existente sendo apenas no hardware usado. Os cartões de memória utilizados nos computadores, também possuíam o mesmo tamanho mas não foram dados maiores detalhes sobre eles.\newline

Um dos testes demandava bastante uso de espaço de disco, sendo assim, foi necessário adicionar mais memória externa por meio de um HD externo.
O autor chegou à conclusão de que o Raspberry Pi é uma boa plataforma para replicabilidade, principalmente se utilizado o Docker para padronizar o ambiente de replicação, além disso, também foi concluído que versões posteriores do Raspberry Pi poderiam melhorar ainda mais esse cenário devido às melhorias de hardware que ocorreriam
\cite{rpiplatformreplicable}.\newline

Cerca de 4 anos após a conclusão deste trabalho, foi lançada uma versão nova e exponencialmente mais útil em termos de testes replicáveis, pois não há limitação às placas de 1gb de RAM e nem a limitação das baixas velocidades de transferência, tanto de disco quanto de rede. A partir disso, as conclusões do autor se comprovaram pouco tempo antes dessa versão ser lançada, e a tendência é de que continue lançando versões superiores, visto que após lançarem versões com 2gb e 4gb de RAM a Raspberry Pi Foundation lançou mais uma versão de 8gb de RAM e posteriormente uma versão estável do seu sistema operacional oficial, agora chamado de Raspberry Pi OS, com suporte a instruções 64 bits. Essas melhorias ocorreram apenas em uma nova revisão da placa, as futuras evoluções tendem a ser ainda maiores levando em conta as evoluções que têm ocorrido nas revisões da arquitetura \myref{sig}{ARM}.\newline

\sec{HS06 Benchmark para um servidor ARM}%{HS06 Benchmark for an ARM Server}
Este artigo se resume em um benchmark e a análise de um servidor de arquitetura \myref{sig}{ARM}, esse servidor possui 12 slots para encaixes das placas de \myref{sig}{SoC}, cada placa de \myref{sig}{SoC} possui 4 CPUs com 4 núcleos, um pente de RAM, 4 portas SATA e um conector de porta 10GBE para cada cpu, resultando em 16 núcleos, 4 pentes e 16 portas SATA por placa \myref{sig}{SoC}. Cada servidor consome cerca de 300w de energia, entretanto apenas um \myref{sig}{SoC} foi utilizado para os testes.\newline

Foram utilizados para essa comparação mais 5 servidores \myref{sig}{AMD64}, sendo 1 HP, 3 IBM e 1 Dell, o consumo energético do servidor \myref{sig}{ARM} entre os analisados é o menor e o mais potente em relação ao consumo energético, visto que de acordo com a tabela de resultados apresentada no texto o único que conseguiu mais que 1 ponto por watt gasto foi o computador \myref{sig}{ARM} \cite{hs06}.\newline

Importante ressaltar que os resultados encontrados na máquina \myref{sig}{ARM} são inferiores em pontuação quando comparado com todos os outros servidores utilizados, mas ao mesmo tempo o consumo energético desse processador é exponencialmente menor que os outros servidores, principalmente ao se levar em conta que ele consome cerca de 5w de energia, enquanto os outros consomem entre 150w e 600w.\newline

%\chapter{testes}
%\label{ch: testes}
\ch{Testes}
Os testes foram realizados utilizando duas máquinas, sendo uma delas um \myref{sig}{SBC} \myref{sig}{ARM} e a outra um notebook \myref{sig}{AMD64}, o \myref{sig}{SBC} utilizado foi um Orange Pi PC + \cite{opipc} e o notebook utilizado foi um Lenovo G405 \cite{G405}. O Orange Pi é baseado no processador Allwinner H3 \cite{h3}, além disso, nesta placa existem 3 USB 2.0, 1GB de memória RAM DDR3, uma porta de rede 10/100 e WI-FI 4. Essa configuração é relativamente datada e seu processador é um quad-core de 1.3GHz no seu clock máximo, ele ainda possui desempenho razoável caso seja considerado um uso básico, entretanto considerando todas suas especificações técnicas, este \myref{sig}{SBC} não é bom o bastante para substituir um computador atual satisfatoriamente, isso devido a sua limitação de memória RAM e da sua capacidade gráfica limitada.\newline

O Lenovo G405 \cite{G405}, é um notebook com um processador AMD E1-2100 que é um dual-core com clock máximo de 1.0GHz \cite{E1}, 2 GB de memória RAM DDR3, 1 USB 2.0, 2 USB 3.0, porta de rede Gigabit e 2 portas SATA3. Porém, as portas SATA e as USB 3.0 não foram usadas, já que o propósito é manter as duas máquinas o mais próximas possível em relação as velocidades e capacidades de hardware, para que houvesse proximidade em velocidade e especificações. Este computador também possui especificações técnicas obsoletas para os dias atuais, mas ainda é utilizável como um servidor doméstico.\newline

Considerando as velocidades de armazenamento disponíveis para as máquinas utilizadas, o Orange Pi teve o seu SO armazenado na sua memória interna eMMC, e no computador \myref{sig}{AMD64} em um HD 2.5“ SATA3 de 500GB. A memória onde o sistema operacional do Orange Pi está armazenada apesar de mais lenta, já que a velocidade desta memória de armazenamento apenas afeta o tempo de inicialização do sistema operacional da máquina host e não dos containers, foi considerado como equivalente para os propósitos dos testes.\newline

Alguns métodos que serão utilizados para manter as máquinas com equivalência serão limitar o clock de ambos para que se mantenham o mais próximos possível. No Orange Pi foi definido para um clock máximo de 1GHz, esse sendo um valor para facilitar os cálculos de equivalência, já que é o mesmo clock máximo do lenovo. Sendo assim é uma comparação direta e não uma comparação em escala. A memória usada foi limitada a 1024 MB para o stack do docker, pois é a memória máxima do Orange Pi.\newline

Considerando as velocidades de armazenamento disponíveis para as máquinas utilizadas, o Orange Pi teve o seu SO armazenado na sua memória interna eMMC e no computador \myref{sig}{AMD64}, em um HD 2.5“ SATA3 de 500GB. A memória onde o sistema operacional do Orange Pi está armazenada apesar de ser bem mais lenta que um HD SATA3, já que a velocidade desta memória de armazenamento afeta apenas o tempo de inicialização do sistema operacional da máquina host e não dos containers, por isso foi considerado como equivalente. Para o armazenamento do Docker e seus dados nas duas máquinas foi utilizado um pendrive SanDisk Cruzer Blade 2.0 de 16GB, ambos comprados simultaneamente do mesmo vendedor, o Docker foi movido para eles utilizando as configurações do arquivo "daemon.json" do Docker que  define vários dados cruciais do funcionamento do processo daemon.\newline

Alguns métodos que foram utilizados para manter as máquinas com equivalência foram limitar o clock de ambos para que se mantivessem o mais próximo possível, modificar a quantidade de núcleos acessíveis pelos containers e definir a quantidade máxima de memória acessível pelos containers. No Orange Pi foi definido um clock máximo de 1GHz, esse sendo um valor para facilitar os cálculos de equivalência, já que é o mesmo clock máximo do notebook, sendo assim é uma comparação direta e não uma comparação em escala. O número de núcleos e a memória usada foram limitadas no stack do docker, a memória a 1024 MB, pois é a memória máxima do Orange Pi, e os núcleos para dois já que é o total do notebook.\newline

Além disso, os softwares utilizados nessas máquinas foram versões do sistema Debian, no Orange pi foi o Armbian e no notebook o próprio Debian netinstall, ambos na versão Buster. A versão do Docker usado em ambos é a versão community edition 20.10.12 e a versão do docker-compose é a versão 2.2.3, sendo essas as versões mais atuais no início da execução dos testes. Todos os outros softwares instalados diretamente na máquina são irrelevantes para o propósito dos testes realizados, entretanto para evitar maiores prolemas de compatibilidade devido as variações do sistema operacional foram desativados vários serviços do systemd para que eles não afetassem na execução, os demais softwares relacionados aos testes serão descritos em \myref{sec}{Contêineres docker}.

\begin{itemize}
\item Um teste generalizado de funcionalidade com valores pequenos, onde  são testados uma quantidade X de elementos gerados e isso se repete um número Y de vezes para cada valor com o objetivo de saber uma média de tempo;
\item Um segundo teste para comprovar a eficácia com valores variáveis onde são gerados N ciclos de testes, sendo cada um deles com uma quantidade X+I de dados, onde X é a quantidade de dados do ciclo anterior e I um valor aditivo constante. Isso para saber se existe um tempo constante por elemento gerado ou se existe um tempo fixo mais um valor constante por elementos. Também são repetidas Y vezes dentro de cada ciclo para ter um valor de média de tempo e não apenas um valor único.
\end{itemize}


%\section{testes de tempo}
%\label{sec:testes de tempo}
\sec{Testes de tempo}
Os algoritmos principais do código são a geração do SQLite e a inserção nos BDs finais, sendo assim, ambos foram testados de formas diferentes e por métodos diferentes que serão descritos a seguir.\newline

O algoritmo de geração de banco de dados é muito impactado pela quantidade de núcleos de CPU da máquina na qual foi rodada, mais do que a arquitetura ou clock dela. Enquanto na inserção do banco de dados, as especificações do computador não pareceram interferir tanto quanto a aleatoriedade da consistência do funcionamento das threads, essa inconsistência acabou fazendo com que os testes tivessem que ser realizados sob supervisão, sendo muitas vezes necessário interromper uma etapa e depois reiniciá-la, além disso, várias das operações foram testadas de formas diferentes. Foram utilizadas sempre duas etapas de testes, sendo que pequenas modificações foram feitas em cada uma de acordo com o objetivo .\newline


%\subsection{teste de tempo de criação do bd}
%\label{subsec:teste de tempo de criação do bd}
\subsec{Teste de tempo de criação do BD}
O teste dessa etapa foi feito para, dentre outros objetivos, comprovar o funcionamento do algoritmo de geração de dados descrito em \myref{subsec}{geradorDeSql}. À medida que o desenvolvimento dessa biblioteca acontecia, testes de geração tiveram que ser feitos, esses testes foram usados para saber a eficiência da geração de dados, isso porque os dados gerados levavam uma quantidade parcialmente aleatória de tempo para serem gerados, muito disso devido aos dados gerados serem semi-procedurais, descrito em \myref{subsec}{Sqlite}. %semi-procedurais pois não segue corretamente a seed de geração procedural
Além disso, esse teste foi necessário devido a etapa de geração de dados de inserção \myref{sec}{Geração de dados}.\newline

Na etapa principal desse teste, foi feito um teste aditivo que testou 30 ciclos com adição de 100 em 100 elementos em cada ciclo, ademais foi feito um teste de 4 sub ciclos internos para quantidades diferentes de dados. Os testes desta etapa foram realizados em um PC \myref{sig}{aarch64} e dois PCS \myref{sig}{AMD64}, os dados resultaram em valores de tempo consistentes em relação a diferença de frequências dos computadores.\newline

Sendo assim, se existe um valor de perda entre as arquiteturas para esse teste é um valor irrisório, pois o PC \myref{sig}{AMD64} mais potente apresentou testes cerca de 2 vezes mais rápidos e seu clock é aproximadamente o dobro do \myref{sig}{aarch64}, esses valores foram dados em relação ao tempo gasto por elemento em cada iteração. Com base nos resultados desses testes, desde que o computador tenha vários núcleos, o algoritmo será tão eficiente quanto, isso se deve ao fato de que levando em conta o PC com \myref{sig}{AMD64} com 4 núcleos e 4 threads com um clock que varia entre 3.6GHz e 4.0GHz, e um outro PC \myref{sig}{AMD64} de 2 núcleos e 4 threads com um clock que varia de 2.7GHz a 3.5GHz, os valores de tempo do PC \myref{sig}{AMD64} mais fraco levou cerca de 97\% do tempo do AMD mais potente, essa diferença aparentemente ocorre devido a duas tecnologias desses processadores:\newline
\begin{itemize}
\item Tecnologia Intel® Turbo Boost frequency 2.0: quando detecta que o computador precisa de mais potência aumenta o clock do CPU;
\item Precision Boost Overdrive: essa tecnologia permite que o processador varie seu clock de acordo com a necessidade, tanto aumentando quanto diminuindo para economizar energia.
\end{itemize}

Dessa forma, o clock do processador foi diminuído, já que apenas 1 dos núcleos do processador estava em carga alta e essa tecnologia aparentemente leva em conta a porcentagem de todos os núcleos somados para funcionar. Essa informação se baseia nos métodos de economia de energia existentes nos notebooks AMD da mesma geração, visto que a AMD não detalha muito esse processo da sua tecnologia.\newline

Também foi realizado um segundo teste referente ao descrito acima, seguindo os mesmos parâmetros, mas utilizando o processamento paralelo. O maior diferencial entre os testes da arquitetura \myref{sig}{ARM} e \myref{sig}{x86} foi que na arquitetura \myref{sig}{ARM} devido a limitações dos recursos disponíveis, foi necessário utilizar um HD ao invés de um SSD. E como dito em \myref{sec}{Geração de dados} isso impacta consideravelmente na velocidade da geração dos dados, resultando em valores piores que o teste anterior devido aos múltiplos acessos simultâneos do armazenamento.\newline


\subsec{Teste de tempo de operação de inserção no BD}
este teste foi proposto para ser um teste de dois tipos:
\begin{itemize}
\item Os dados de inserção foram projetados para não apresentarem erro e sempre retornarem o resultado de operação inserida com sucesso.Isso quer dizer que caso nada tenha ocorrido um problema do algoritmo de geração, apenas operações foram realizadas sem erro.

\item Muitos bancos de dados são usados primariamente para inserção de dados, como bancos de dados de log e de análise de dados.Como o próprio \myref{sec}{Elasticsearch monitoring stack} utilizado durante os testes, onde operações de busca, listagem e filtragem não são a maioria.Sendo assim é um comparativo para esse propósito de teste.Para esse propósito foi utilizada uma variação do \myref{subsec}{Teste de tempo de criação do BD} benchmark de criação de BD.Foi usada uma inserção fracionada dos dados, o que significa que foram realizadas as operações em grupos de 5000 até completar os 100.000.Diferente dos testes de criação, não foram valores aditivos, mas sim interações dos dados em grupos de tamanho fixo.Para que a máquina onde os testes finais não travassem foi definido um valor mais baixo de subprocessos, sendo 1 para cada thread do processador da máquina, onde 3 executavam os testes para o arm e 3 para o amd.
\end{itemize}
para esse propósito foi utilizada uma variação do benchmark de criação de BD,foi usada uma inserção fracionada dos dados,o que quer dizer que foram realizadas as operações em grupos de 5000 até completar os 100.000.
para que a máquina onde os testes finais não travasse foi definido um valor mais baixo de subprocessos,sendo 1 para cada núcleo do processador da máquina,onde 3 executavam os testes para o \myref{sig}{ARM} e 3 para o amd.


\subsec{Teste de tempo de operações variadas no BD}
Após a confirmação da funcionalidade de forma satisfatória da geração do sqlite, foi iniciado o processo de interação com o banco de dados.Esse processo foi dividido em algumas etapas, primeiramente para verificar se a operação funcionava corretamente.Essa etapa foi feita seguindo os testes de funcionalidade já descritos, onde uma pequena quantidade de operações era gerada, usando a geração de sqlite em ambos os bancos de dados ao mesmo tempo.Após essa etapa de confirmação de funcionalidade não foi feito um teste de desempenho, pois foi deixado para a etapa de testes paralelos.A qual se mostrou mais importante, visto que após a confirmação de funcionalidade mais testes para essa etapa não eram necessários.\newline

Apenas testes de realização de operações sem retorno, leitura de arquivos, criação de usuários e comunicação geral com o banco de dados, foram feitos todos esses testes que tiveram resultados satisfatórios, tornando-se possível as funcionalidades utilizadas da biblioteca \myref{subsec}{gerenciadorDeBD}.Os dados foram gerados seguindo o seguinte processo:
50.000 operações de inserção foram gerados e posteriormente foram pedidos 5.000.000 operações randômicas, o que resultou em 50.000 operações de inserção seguidas de 4.950.000 operações randômicas geradas.\newline

O principal propósito deste teste foi mostrar que muitos bancos de dados, principalmente de sites de comércio eletrônico e sistemas de gerência de estoque utilizam muitos tipos variados de operações, como as que foram utilizadas nesse teste.Isso faz com que os resultados sejam facilmente aplicáveis para essas situações do mundo real.Para que a máquina onde os testes rodaram não travasse, foi utilizado o mesmo procedimento do \myref{subsec}{Teste de tempo de operação de inserção no BD}.\newline

%\subsection{teste de tempo de operações paralelas}
%\label{subsec:teste de tempo de operações paralelas}
\subsec{Teste de tempo de operações paralelas}
Essa foi a etapa que demandou maior quantidade de testes, estudos e desenvolvimento dos testes implementados.Visto que além da programação paralela ser mais complexa que a programação linear, ela é bem mais difícil de ser testada.Apenas foi possível após as outras classes principais,\myref{subsec}{gerenciadorDeBD} e \myref{subsec}{geradorDeSql}, serem finalizadas.\newline

Basicamente para a execução desse teste foi feita a execução dos testes de tempo, porém com modificações no código para que ele funcionasse de forma paralela.\newline


%\section{testes de eficiencia}
%\label{sec:testes de eficiencia}
\sec{Testes de eficiência}
Esses testes não apenas levam em conta o tempo que foi gasto para concluir a operação, mas também a forma como elas foram concluídas.Isso quer dizer que o tempo é um dos parâmetros para a sua avaliação, mas também a quantidade de falhas apresentadas, quantidade de cpu utilizada, e quantidade de interação do operador do algoritmo para que ele funcione como deveria.

%\subsection{teste de eficiencia de operações paralelas}
%\label{subsec:teste de eficiencia de operações paralelas}
\subsec{Teste de eficiência de operações paralelas}
Esse foi o teste que mais demandou tempo e esforço dentre os realizados.Isso porque devido a complexidade da programação paralela, como já dito em \myref{subsec}{Teste de tempo de operações paralelas}, uma quantidade maior de testes foram demandados.Um dos grandes motivadores foi a etapa descrita em \myref{subsec}{Teste de tempo de inserção no BD}.Apesar dessa etapa não ter sido complicada por si só ela demandou muita atenção pois apresentava muitos erros.Essas operações demandaram muitos testes manuais alternando o método de programação paralela, sendo usando threads ou subprocessos, quantidade de operadores paralelos, quantidade de elementos inseridos e forma dos elementos inseridos.\newline

Tudo isso pois em vários momentos foram apresentados erros randomicamente sem nenhum indício de justificativa.Os erros apareciam em certos momentos quando era usado o processamento paralelo em threads e em outros utilizando o processamento paralelo de subprocessos.Os mesmos erros eram corrigidos para que em sequência ao se implementar a próxima funcionalidade necessária o mesmo erro se repetisse.Isso gerou um loop do processo de desenvolvimento , onde muitos testes eram realizados e alternados com leitura de documentação das bibliotecas utilizadas, ou mesmo leitura de exemplos de códigos de fóruns e sites.\newline

Essa etapa se misturou muito com o desenvolvimento do programa, pois a otimização do código era necessária para que certas partes dele funcionassem corretamente.Também se misturou com as outras etapas de teste, isso muito por que as outras etapas acabaram por servir como etapas desse mesmo teste.\newline

Durante estes testes foram detectados outros fatores interessantes: primeiro que o postgres apresenta uma demora maior na sua execução em comparação com o mariadb caso ocorram operações que não retornam nada.Esse tipo de operação constitui a maioria das operações geradas para os testes, isso devido a única que é garantida de não dar problema ser a operação de inserção.Além disso, foi detectado que o quadro se inverte nas operações válidas, onde o postgres é bem mais rápido que o MariaDB.Outro fator detectado é que caso seja feita uma implementação sequencial, a inserção dos dados será feita mais rapidamente que uma implementação paralela, além de apresentar menos erros próximos a zero.\newline



%\chapter{Metodologia}
%\label{ch: materiais e métodos}
\ch{Metodologia}
O desenvolvimento do software foi feito utilizando vários métodos de análise de log com o objetivo de agilizar a depuração.Possibilitando que os dados gerados pudessem ser facilmente conferidos durante o desenvolvimento.\newline
Durante esse capítulo, serão descritos os procedimentos mais importantes das etapas de desenvolvimento e funcionamento do software, com o intuito de proporcionar um entendimento simples.\newline

%\section{bibliotecas criadas}
%\label{sec:bibliotecas criadas}
\sec{Bibliotecas criadas}
Algumas bibliotecas foram criadas para facilitar o desenvolvimento delas, algumas valem a pena ser mencionadas mais detalhadamente, mas outras apenas serão citadas aqui, uma dessas bibliotecas foi uma para o tratamento de erros.Essa classe é uma derivação da classe padrão do Python de exceção.Essa biblioteca é composta de 3 classes, cada uma para um tipo de mensagem e tratamento de erro, apenas para simplificar e facilitar o debug do código durante a manipulação dele.Ela não faz real diferença em relação ao funcionamento em si, exceto no fator de poderem ser chamadas correções específicas dos erros, quando um try-catch é usado numa função.ainda foi criada uma biblioteca de timer, usada nos testes de tempo do projeto, essa biblioteca apenas é uma contração de forma simples e com tratamento de erro do uso da biblioteca time do Python.Essa técnica de medida de tempo é amplamente utilizada, mas apenas para fins de simplificação no momento do uso foi criada essa biblioteca.

%\subsection{loggingSystem}
%\label{subsec:loggingSystem}
\subsec{loggingSystem}
Essa biblioteca é a responsável por toda a gerência de logs e por todo o \myref{subsec}{monitorContainer},essa biblioteca basicamente é um complemento da biblioteca padrão de logs do Python \cite{logging},que tem uma implementação de comunicação com os servidores Logstash.A biblioteca de forma inteligente verifica se os parâmetros de comunicação com o Logstash estão funcionais, senão, automaticamente salva todos os logs em um arquivo .log cujo nome foi informado durante a instância do objeto da classe.
A classe apenas consegue fazer essa verificação durante sua instância,caso após isso a conexão seja perdida os logs não são enviados a lugar algum.\newline

As mensagens de erro são gerenciadas de forma simplificada,onde existe um parâmetro que define o formato da mensagem de log e o nome do gerenciador de log, além de outros pequenos parâmetros para identificação de onde saiu o log que foi registrado.\newline

Existem alguns métodos nessa biblioteca que auxiliam no tratamento de erro de stack overflow, onde esses métodos monitoram de onde saiu a execução do elemento que chamou essa função, um exemplo é o caso do tratamento de erro do stack overflow na criação de um dado de inserção, da classe de criação de banco de dados, onde caso durante o tratamento de erro que faz com que a classe seja chamada recursivamente algumas vezes até que consiga retornar um valor válido.O tratamento de erro acontece na etapa da chamada de uma nova recursão para evitar um esgotamento de memória, já que caso chegue a um valor máximo de execuções, que é verificado pelo método nativo do Python chamado inspect, é chamado o encerramento da recursão e simplesmente em vez de retornar um valor de inserção é retornado um valor nulo.\newline

Além de saber qual a função que a chamou esse método existe uma outra implementação onde retorna toda a pilha de chamadas do algoritmo, sendo assim permitindo que um tratamento de erro mais complexo seja possível sem grandes alterações no código.


%\subsection{paralelLib}
%\label{subsec:paralelLib}
\subsec{paralelLib}
Essa biblioteca possui 2 implementações diferentes de paralelização, utilizando a classe threading \cite{threading}, e a classe multiprocessing \cite{multiprocessing}.A classe threading utiliza threads para a paralelização de execuções, esse método foi inicialmente utilizado por ser de simples implementação e simples monitoramento da execução.Entretanto devido às limitações de segurança[referenciar seção do erro de segurança de thread] dessa classe foi escolhida uma implementação utilizando a classe multiprocessing, onde essa classe cria um grupo de subprocessos para o código que irão ser responsáveis pela execução do algoritmo selecionado.Ambas as classes implementadas, a derivada de threading e a derivada de multiprocessing, foram feitas de formas análogas e de simples substituição em código de uma para a outra de acordo com a necessidade, sendo assim funcionam de forma parecida.Ambas funcionam com uma classe de gerência chamada paralel, no caso de threading sendo paralel\_thread e no caso de multiprocessing sendo paralel\_subprocess, assim como classes worker com nomes semelhantes, worker\_thread e worker\_subprocess.\newline

As classes de gerência funcionam gerando um array de objetos da classe worker, sendo cada um equivalente a uma thread ou subprocesso da execução paralela respectivamente.Também existe um elemento, que pode ser apenas um elemento ou array, com as funções que serão executadas no processamento paralelo, além disso gera um objeto que contém os elementos que serão processados durante o processamento paralelo.Esses objetos são passados como kwargs das funções que serão executadas, podem ser aceitas várias funções desde que sigam apenas uma regra.Essas funções devem ter exatamente as mesmas entradas de dados, no caso utilizado no algoritmo, cada função é a referência de uma função associada a um objeto com uma credencial diferente para a comunicação com o banco de dados, de forma que não seja executada mais de uma comunicação com uma credencial por vez.\newline

Os workers vão ciclando as funções a medida que vão inteirando pelo array dos parâmetros.Durante a execução dessas funções vão sendo removidas do objeto contendo os kwargs um por um logo antes de ser usado.Dessa forma garantido que uma operação não será feita 2 vezes, isso é importante visto o propósito desse algoritmo, que é simular a mesma quantidade de operações em bancos de dados diferentes.Se um elemento fosse utilizado mais de uma vez esses valores se alterariam, caso um dos elementos já tenha sido usado e o worker tente usá-lo de novo, um erro vai ocorrer, o worker vai ignorar esse elemento e tentará o próximo disponível, caso o número de elementos seja menor que 1 ele irá então terminar o loop e parar a execução desse worker.Após o fim da execução de todos os processos paralelos a classe parallel terminará sua execução e retornará os dados pedidos.\newline

O objeto de gerência, se for requisitado, irá retornar os resultados das operações onde o processamento paralelo foi pedido, para os propósitos deste algoritmo isso não foi necessário nenhuma vez.Sendo assim essa funcionalidade está incompleta, além disso ele pode retornar o tempo gasto por cada worker, essa função foi a usada para calcular o tempo gasto.\newline

Essa biblioteca demandou muito tempo do desenvolvimento devido aos diversos problemas possíveis de acontecerem durante o manuseio de aplicações paralelas.Uma modificação em relação à classe nativa do Python foi a implementação de um time out para a execução dessas funções, de forma que as operações mesmo que travem não apresentam problema no benchmark, isso foi um problema percebido que impactava muito na velocidade do benchmark, gerando subprocessos zumbis, já que uma operação do banco de dados acabava levando mais tempo que o necessário e em algum momento os subprocessos acabavam gerando um problema de travar um ao outro devido a essa demora.Caso isso ocorra, o elemento utilizado voltará à lista de elementos a serem executados e será chamado pelo próximo worker livre.\newline

%\subsection{monitorContainer}
%\label{subsec:monitorContainer}
\subsec{monitorContainer}
Essa biblioteca se baseia na biblioteca \myref{sec}{Biblioteca psutil} e utiliza um método não muito seguro chamado eval, uma função nativa do Python que consegue executar um comando de console Python declarado como um string.Sendo assim podendo facilmente serem alterados os parâmetros que seriam consultados do hardware onde o contêiner está sendo rodado.Essa biblioteca faz a consulta a partir de um arquivo json que lista as funções da biblioteca psutil que devem ser executadas acompanhadas dos parâmetros de entrada e o filtro de retorno que será aplicado.Isso faz com que muito facilmente possam ser pesquisadas apenas as informações realmente necessárias, simplificando assim o trabalho da análise de logs.a biblioteca ainda implementa o uso da biblioteca de logs para poder enviar todos eles de forma automática para o Logstash ou para um arquivo de log local, como descrito em \myref{subsec}{loggingSystem}.

%\subsection{gerenciadosDeBD}
%\label{subsec:gerenciadosDeBD}
\subsec{gerenciadorDeBD}
Essa biblioteca é feita para que a gerência das conexões do banco de dados seja feita mais facilmente, visto que tem as funções adaptadas para serem iguais para o MariaDB e para o postgres, além disso existem tratamentos de erro customizados para todos os erros que foram observados durante a etapa de desenvolvimento.Dessa forma todos os erros que acontecem são tratados de forma similar, mas como as bibliotecas são diferentes e desenvolvidas por entidades diferentes, várias das correções de erros e funcionamentos também são diferentes.Um exemplo simples disso é que para a biblioteca do postgres para executar um arquivo sql só precisa do string contido nele, mas na biblioteca do MariaDB precisa ser lido e executado linha a linha.Na biblioteca criada foram feitas as adaptações para que independente do banco de dados usado, a função de executar um arquivo sql apenas precisa do caminho do arquivo no sistema ,ela já abre o arquivo e o executa.\newline

Algumas outras coisas são feitas, no postgres por exemplo existe uma função de rollback, que é usada para desfazer alguma operação quando ela é identificada como erro numa comunicação com o banco de dados.Não existe algo equivalente para o MariaDB, sendo assim a classe criada trata esse erro tentando executar mais 5 vezes a operação, para garantir que não foi algum erro de conexão aberta, após essas 5 vezes o algoritmo considera que a operação inserida está com problema e a ignora.\newline

     Essa biblioteca serve principalmente para essa generalização, além de controlar a inserção, execução de sql, ainda gerenciar consulta, criação de usuário e ler diretamente o sqlite para realizar as operações escritas Dessa forma essa biblioteca simplifica muito a interação com o banco de dados, essa simplificação chega num ponto em que se tornou possível a paralelização, visto que uma adaptação para isso é bastante complexa caso o código não tenha sido pensado para este fim desde o começo, sendo assim o algoritmo sendo modularizado acabou fazendo possível a implementação de forma paralela.\newline
     
      A biblioteca ainda faz com que seja possível consultar o sqlite dos dados gerados diretamente na comunicação com o banco de dados final, isso faz com que seja mais econômico de memória RAM o algoritmo, mas faz também com que ele consuma por mais tempo disco e cpu, mas não necessariamente em maior quantidade.Isso faz com que tenha sido necessário um controle mais preciso da quantidade de threads na execução do benchmark, pois como o cpu é usado por mais tempo, isso poderia causar um travamento da máquina que está gerando os testes e uma subsequente inconsistência dos dados de benchmark gerados, como apresentado em \myref{subsec}{Resultados todos parte 9}.


%\subsection{geradorDeSql}
%\label{subsec:geradorDeSql}
\subsec{geradorDeSql}
essa é a classe referida na seção \myref{sec}{Geração de dados},todas as informações detalhadas dela estão descritas nessa seção

%\section{software de benchmark}
%\label{sec:software de benchmark}
\sec{Software de benchmark}
O benchmark foi feito utilizando um software desenvolvido para o propósito deste teste, o software de benchmark está mais para um software para gerar estresse na máquina na qual está rodando o banco de dados por meio de várias execuções de comandos direto no banco de dados.O software de benchmark funciona carregando e construindo os dados a partir das inserções no arquivo sqlite, os testes de estresse foram tentados de algumas formas:\newline
\begin{itemize}
\item Primeiramente o algoritmo inicia o contêiner que contém o banco de dados que está sendo analisado;
\item Após isso é inserindo uma quantidade definida de operações que é lida de forma sequencial do banco de dados inicial;
\item Após isso são executadas essas operações até que terminem,depois disso o mesmo procedimento é feito para a outra máquina;
\item Após isso o contêiner com o banco de dados é desligado e o próximo tipo de banco de dados é iniciado nas duas máquinas, e o processo se repete;
\end{itemize}
A outra forma é um pouco mais rápida e eficiente em relação a execução das múltiplas
máquinas.\newline

Isso se dá pelo fato que o processo de inserção é feito de forma paralela,sendo assim as inserções dos bancos de dados em todas as máquinas é feito simultaneamente, mas também de forma sequencial e o funcionamento é muito parecido com o da anterior:\newline
\begin{itemize}
\item Primeiro é criada uma thread para cada máquina;
\item Em cada thread é lido de forma sequencial as operações que serão inseridas;
\item O container de banco de dados escolhido é iniciado na máquina associada a thread;
\item As operações são executadas seguindo a lista de operações;
\item Assim que as operações acabam em todas as threads o contêiner do banco de dados é parado; 
\item O algoritmo aguarda a outra thread iniciar para poder começar o mesmo procedimento para o outro tipo de banco de dados;
\end{itemize}

A terceira forma é parecida com a segunda, diferente apenas na forma como as operações são executadas, a partir desse método as operações são inseridas de forma paralela;\newline
\begin{itemize}
\item Sendo assim cada thread de cada máquina possui uma quantidade definida de threads filhas;
\item Essas threads filhas executam as operações a partir do que existe numa queue de elementos;
\item Após esse ponto o procedimento é igual ao teste descrito anteriormente, do 3 ponto em diante, com a diferença de a queue não ser tratada como uma lista sequencial e seus elementos podem ser readicionados caso de erro;
\end{itemize}

A queue de elementos não garante que uma operação será executada, visto que pode depender de uma operação que ainda não foi executada, isso é possível em alguns casos raros, assim como num ambiente real, onde um funcionário de uma empresa pode editar um elemento ao mesmo tempo que outro edita o mesmo elemento, em ambientes reais existem tratamentos para que isso não ocorra.\newline

Mas no ambiente desses testes, nenhum tratamento para impedir isso foi feito, exatamente para simbolizar o pior cenário possível para uma aplicação com comunicação com bancos de dados.\newline

os containers utilizados foram desenvolvidos para os propósitos desta pesquisa, e estão descritos em \myref{sec}{Contêineres docker}\newline


%\section{geração de dados}
%\label{sec:geração de dados}
\sec{Geração de dados}
Os dados foram todos gerados para um sqlite projetado para ser simples de aceitar qualquer formato de dados que pudesse ser gerado para qualquer tabela.Essas etapas funcionam da seguinte forma: \newline
No início, os dados foram gerados em sqlite pelo fato que, caso houvesse algum problema e o computador, que estava gerando os dados, fosse abruptamente desligado, não se perdesse as informações que já haviam sido criadas e salvas no banco de dados.Desta forma, economiza  memória ram, já que não é necessário carregar o arquivo todo quando fosse necessária uma consulta de dados, e tempo uma vez que esta etapa é a mais demorada da geração de dados, como descrito em\myref{subsec}{Sqlite}.\newline
O código consegue gerar os dados de 3 formas,mas apenas a última é realmente utilizada.As outras duas foram feitas para propósito de testes:
\begin{itemize}
\item Gerar uma quantidade x de dados de uma tabela específica;
\item Gerar uma quantidade x de cada tipo de dado para cada tabela do banco de dados final;
\item Gerar uma quantidade aleatória de cada tipo de dado para as tabela do banco de dados final até atingir o total de operações informadas;
\end{itemize}

Todos esses tipos de geração são feitos pela mesma função que são alterados pelos parâmetros passados a ela.Assim, a função prioriza os parâmetros referentes aos três tipos de geração.\newline

Além dos parâmetros relacionados aos tipos de geração informados, existem os parâmetros relacionados a biblioteca faker e uma lista que define quais tipos de operação, descritos em \myref{subsec}{Tipos de dados gerados}, que define, caso não esteja vazia, quais os tipos de dados que serão gerados.Isso foi útil pois utilizou-se o tipo de criação de dados de inserção na primeira etapa de testes, como descrito em teste de tempo de operação de inserção no BD[referenciar], antes de gerar os dados dos outros tipos.\newline

Devido a limitações intencionais, o valor total de operações inseridas em cada execução deve considerar a quantidade da execução anterior.Isso se faz necessário pois o algoritmo verifica apenas a quantidade total de elementos cadastrados no sqlite, ou seja, caso sejam requisitadas 3 tipos de geração diferentes teriam que ser passadas da seguinte forma:
\begin{itemize}
\item Uma geração da quantidade X de dados, resultando em X dados gerados;
\item Uma geração de Y dados, sendo que Y é igual a X+A, resultando em Y dados gerados;
\item Uma geração de Z dados, sendo que Z é igual a X+A+B, resultando em Z dados gerados;
\end{itemize}
Sendo assim,os dados gerados teriam que ser algo como X=5, Y=10 e Z=15, onde cada etapa apenas teriam 5 dados adicionados ao sqlite.\newline

A geração de dados inicialmente foi pensada para rodar em um servidor de forma sequencial, isso simplesmente por que não teria processamento paralelo inicialmente no software, entretanto quando isso se tornou necessário também foi possível utilizar o código previamente existente da geração de dados para a geração de forma paralela.Isso se mostrou uma grande vantagem para a etapa de desenvolvimento, onde vários bancos de dados de testes foram gerados para que fosse garantido que todas as partes desenvolvidas do software estivessem funcionando corretamente, devido a forma como isso foi pensado.\newline

O grande limitador da velocidade de geração de dados é o fator randômico, devido a toda a recursão que ocorre em consequência aos tratamentos de erros, além disso o outro maior limitador é a velocidade da mídia de armazenamento, visto que a aplicação sqlite3 aceita apenas uma inserção por vez no banco de dados de forma paralela, isso faz com que quanto mais rápido fosse possível a escrita em disco, mais rapidamente esse fator limitador era deixado de lado.Devido ao fato de durante os testes da etapa de desenvolvimento todos terem sido usando um SSD para o salvamento desses dados isso não impactou em quase nada na velocidade de geração dos dados,mas na etapa de execução de testes isso se mostrou um problema, já que no dispositivo usado para executar o algoritmo dos testes o HD mecânico fez com que ocorresse diminuição da velocidade de leitura e escrita, sendo assim mesmo na operação de leitura, onde podem ser feitas várias leituras concorrentemente isso impactasse na performance e gerassem alguns erros como descrito em erro de leitura pela falta de velocidade de disco.Como descrito em \myref{subsec}{Erro de leitura pela falta de velocidade de disco}.

%\subsection{tipos de dados gerados}
%\label{subsec:tipos de dados gerados}
\subsec{Tipos de dados gerados}
Foram selecionadas para os teste apenas as operações mais utilizadas por um banco de dados:
\begin{enumerate}
\item Inserção de um novo dado;
\item Leitura completa de todos os dados de uma tabela;
\item Busca de elementos filtrados em determinada tabela;
\item Busca de apenas alguns dados de elementos filtrados em determinada tabela;
\item Edição de elementos;
\item Deleção de elementos filtrados;
\end{enumerate}
Antes de ser gerada, a operação de inserção passa por vários processos de tratamento de erro para se certificar que não houve dependência alguma que não foi gerada, como por exemplo, gerar uma cidade sem existir um país cadastrado.\newline

Esse foi um dos motivos de ter sido utilizado um arquivo sqlite ao invés de outro método de armazenamento.Dessa forma, pode-se executar essa consulta de dependência de forma rápida e apenas retornar índices válidos para associações de tabela.\newline

Os vários dados gerados por esse programa são usados parcialmente para a geração dos dados novos, mas todos os dados gerados são gerados de forma simplificada e sendo assim, poucas coisas que já haviam sido cadastrados, apenas os ids cadastrados são usados, isso porque  para a associação de dados é levado em conta os dados realmente existentes, ou seja, não são consultados os dados para as queries e nem nenhum outro dado como update.A maioria dos dados gerados não conseguem retornar algum valor, como updates ou deleções, isso foi feito dessa forma para simplificar o algoritmo, e seria totalmente possível a modificação para que esses dados sejam levados em conta no futuro.\newline

%\subsection{alimentação do algoritmo}
%\label{subsec:alimentação do algoritmo}
\subsec{Alimentação do algoritmo}
O algoritmo de geração de dados funciona de forma que qualquer banco de dados possa ser utilizado para ter seus dados gerados.Basta utilizar um arquivo json e seguir um determinado padrão que é composto por:\newline
\begin{itemize}
\item uma tag com o nome de uma tabela do banco de dados; 
\item dentro dela uma estrutura json com:
\begin{itemize}
\item uma tag com o nome da coluna;  
\item seu conteúdo em um array de string contendo;
\begin{itemize}
\item o primeiro tipo de dado;  
\item outros valores adicionais para a geração;
\end{itemize}
\end{itemize}
\end{itemize}

Dentro do algoritmo existem vários tipos de dados aceitáveis, tais como id, nome, associação e timestamp, sendo que cada um deles possui um tipo bem definido pelo seu nome, mas o único que vale a pena citar seu funcionamento é a associação.\newline

Como descrito em \myref{subsec}{Sqlite} existe uma tabela do sqlite contendo as quantidades de elementos associados a cada tabela do banco de dados final.O tipo de associação vai pegar esse valor e usar uma função de seleção randômica para que seja escolhido um elemento de id existente no intervalo descrito.Caso não exista algum elemento dessa tabela, por um tratamento de erro é gerado um elemento para ela, permitindo o funcionamento da associação no novo elemento que foi criado.\newline

Os únicos dados que não são passados para o algoritmo funcionar são: o país que deve ser gerado os dados de acordo com \myref{sec}{Biblioteca faker} e a quantidade de dados que devem ser gerados.Ambos sendo necessários de serem inseridos na chamada da função.Os outros dados relevantes referentes ao funcionamento da chamada da função estão em \myref{sec}{Geração de dados}\newline

%\subsection{sqlite}
%\label{subsec:sqlite}
\subsec{Sqlite}
O banco de dados do sqlite foi projetado para ser totalmente maleável e modular, de forma que não teriam que ser geradas várias tabelas para os vários tipos de dados do benchmark.Foi pensado no seguinte método para facilitar o desenvolvimento, sendo uma tabela de índices e uma tabela de operações.A tabela de índices possui apenas 3 colunas, uma id, uma com o nome da tabela e uma com o total de elementos dessa tabela.A outra tabela é um pouco mais complexa e está descrita a seguir:
\begin{itemize}
\item A tabela de operações a ser executada é constituída de uma coluna inteira para o tipo de operação que será realizada, de acordo com \myref{subsec}{Tipos de dados gerados};
\item Uma coluna é uma string contendo o nome do banco de dados que será executada a operação;
\item Uma coluna inteira para, se for necessário, conter o id no banco de dados do elemento trabalhado na operação.No caso de uma inserção é o id do novo elemento por exemplo;
\item Uma coluna text, nessa coluna serão inseridos valores adicionais necessários para a execução da operação, como os parâmetros de quais colunas devem ser atualizadas em um update.Aqui os dados inseridos são salvos em formato json para facilitar o trabalho com a linguagem Python, visto que existe uma conversão direta de string json para o tipo dictionary do Python.
\item Uma coluna text seguindo a mesma ideia da coluna anterior.Esses dados são os dados obrigatórios de qualquer operação, onde dependendo da operação os dados contidos são diferentes.
\end{itemize}
Dessa forma, independente se é apenas uma operação de listagem completa, que só necessita de ter preenchida a coluna com o nome do banco de dados e a coluna com o tipo de operação ou se for uma operação de update onde todos os campos podem estar preenchidos, o banco de dados sqlite consegue lidar de forma rápida e segura com qualquer uma das operações e dados gerados pelo algoritmo.Foi cogitado o uso de outras estruturações da tabela de operações, mas essa foi a mais simples de ser implementada, válida para todas as operações e a mais reaproveitável.


%\section{containers docker}
%\label{sec:containers docker}
\sec{Contêineres docker}
Os containers Dockerforam criados a partir do sistema Alpine Linux, no qual foram feitos 2 contêineres diferentes, um para o MariaDB e outro para o postgres.Os contêineres se certificam de criar o banco de dados de forma correta durante a inicialização dele, após isso o contêiner durante a sua inicialização se certifica que o Python está instalado e tudo necessário para que o daemon, descrito em \myref{sec}{Daemon de monitoramento},funcione após isso.O banco de dados do contêiner é finalmente iniciado.Essa forma de instalação do daemon certifica que tanto o interpretador Python3 quanto as bibliotecas usadas estão sempre atualizadas todas as vezes que o contêiner é instanciado.\newline

Apesar de esse método causar uma grande demora na primeira inicialização do contêiner, devido a forma como o script de inicialização funciona somente a primeira inicialização é impactada na sua velocidade de inicialização.Foi tentada a implementação de um heathcheck para saber se o contêiner já havia iniciado o banco de dados e se ele já estava acessível, entretanto além de ocorrer algum problema desconhecido que resultou numa falha nesse procedimento, sua necessidade se provou inexistente.Visto que seria verificada a saúde do contêiner antes da inicialização das execuções dos testes, mas apenas deixar um delay de alguns segundos bastou para que não ocorressem erros relacionados a isso.
Containers baseados no alpine possui uma especificidade, para a arquitetura armhf, presente no Orangepi PC +, só funcionam corretamente sem grandes modificações do sistema até a versão 3.12, isso devido a uma mudança no método como o sistema operacional manipula o relógio interno, o que quer dizer que não é possível utilizar o gerenciador de pacotes dele uma vez que os repositórios utilizam SSL e ele necessita do relógio funcionar corretamente para completar uma conexão, sendo assim a versão utilizada foi a versão 3.12.\newline

Outra especificidade do alpine é que ele é um dos poucos sistemas Linux que não possui o GCC incluso como pacote padrão do sistema, isso faz com que o Python tenha alguns problemas ao instalar algumas bibliotecas, dentre elas o psutil, que foi utilizado pelo \myref{sec}{Daemon de monitoramento}, para solucionar isso foi necessário instalar um programa chamado linux-headers que é um conjunto de programas e bibliotecas padrões das distribuições Linux, além é claro do próprio GCC, após a adição desses programas o contêiner pôde funcionar corretamente.

%\section{daemon de monitoramento}
%\label{sec:daemon de monitoramento}
\sec{Daemon de monitoramento}
O daemon de monitoramento monitora os status da máquina na qual está rodando, seja uma máquina física ou um container docker, para esse fim é utilizada a biblioteca \myref{sec}{Biblioteca psutil} que é a principal biblioteca Python quando se trata de monitoramento de hardware.O daemon utiliza também uma biblioteca feita para simplificar o tratamento de log,uma das funcionalidades contidas nesta biblioteca é a comunicação com o aglutinador de logs Logstash do\myref{sec}{Elasticsearch monitoring stack} ,isso feito em cima da biblioteca python-logstash.\newline

O arquivo de configuração do daemon é um json constituído de 2 partes, os parâmetros para se conectar ao Logstash e os dados que serão coletados da máquina local, esses dados coletados serão enviados para o servidor Logstash onde lá serão trabalhados.O daemon envia esses dados com um intervalo de 0.1 segundos, que é apenas passado para que não sejam enviados dados errados de cpu para o servidor de log, uma vez que é comum o erro de se enviar 0\% de uso de cpu caso as consultas sejam feitas muito rapidamente, mas poderia ser aumentado para diminuir o estresse na máquina que está rodando ele e diminuir um pouco o estresse do servidor de coleta de logs, que com as máquinas usadas não se provou necessário.Além é claro de diminuir a quantidade de dados no pós processamento de resultados descritos em \myref{sec}{Processamento de resultados}

%\section{ambiente de desenvolvimento}
%\label{sec:ambiente de desenvolvimento}
\sec{Ambiente de desenvolvimento}
O ambiente utilizado foi dividido em duas partes, programação local e remota.Na programação remota as execuções foram feitas em um servidor baseado em Raspberry PI 4 e na programação local foram feitas em duas máquinas diferentes, sendo computadores locais.A programação remota se provou bem útil quando houve a necessidade de troca de computador ou sistema operacional, facilitando ainda a implementação de um servidor unificado de análise de log pois era mais simples a comunicação entre o código executado e o servidor\myref{sec}{Elasticsearch monitoring stack}.\newline

Foram utilizados Visual Studio Code e DBeaver para o desenvolvimento da \myref{sec}{Software de benchmark} , e ainda foi utilizada uma implementação de um algoritmo de processamento para  \myref{sec}{Elasticsearch monitoring stack} com finalidade de gerar os gráficos e tabelas apresentadas neste trabalho.Os dois primeiros foram escolhidos dentre outros motivos por serem open-source e estarem disponíveis tanto para Linux quanto Windows, visto que ambos sistemas operacionais foram utilizados para o desenvolvimento de acordo com a necessidade.\newline

Para o controle de versão foi utilizado o Git, deixando registrado todo o histórico de alterações do programa, o que se mostrou bem útil para o rastreio de erros ocorridos durante o longo tempo de desenvolvimento do código.Para os testes iniciais do código foram utilizados containers Dockernão limitados durante a etapa de implementação dos scripts do DBbench, que demandam a existência dos servidores dos bancos de dados sendo executados, ao contrário do restante do desenvolvimento da aplicação, que não interagiu diretamente com os bancos de dados.A geração do banco de dados inicial, descrito em \myref{subsec}{Sqlite}, foi feita completamente em um Raspberry Pi 4 com um pequeno overclock, essa geração foi feita durante alguns dias, visto que o \myref{sig}{SBC}, de acordo com \myref{sec}{Testes de tempo}, consome menos energia e devido a sua configuração pré existente, possui um acesso headless mais simplificado que as outras máquinas utilizadas.


\sec{Processamento de resultados}
Os dados coletados pelo \myref{sec}{Elasticsearch monitoring stack} foram extraídos para CSV, processados para eliminação de dados irrelevantes, mesmo que durante o processo de \myref{sec}{Daemon de monitoramento}, apenas os dados selecionados fossem coletados, ainda existiam dados que posteriormente se provaram irrelevantes para os resultados deste trabalho.Após esse processamento inicial é usado um segundo processamento para eliminar duplicatas, e para separar em quatro arquivos diferentes os resultados, um para cada banco de dados em cada máquina.A última etapa é a plotagem dos gráficos utilizando a biblioteca altair que gera gráficos SVG que devido a sua natureza vetorial se mostraram de melhor manuseio já que mesmo aumentando o zoom ela não se distorcia,o que provou ser de grande valia, estas imagens são as inclusas dentro deste trabalho.\newline

Ainda tem uma verificação manual para se certificar que os dados coletados estão corretamente associados ao servidor relativo a elas, isso resulta na certificação de que os dados antes de serem processados estejam corretamente identificados, o que é importante devido a forma como os dados são coletados e armazenados, principalmente os dados de tempo, que decidem semi-aleatoriamente qual a ordem que serão armazenados no array de tempos do arquivo json de resultados.Isso porque caso o índice 1 seja o amd ele se manterá o mesmo até o final da execução, o que ocorreu na maioria dos testes realizados, mas não em todos.\newline

Uma última etapa de processamento foi feita para a geração de vários arquivos pequenos ao invés de um único arquivo grande, foi detectado que todas as vezes que o container reiniciava, os dados de tráfego de rede retornavam a zero.Sendo assim, todas as vezes que o algoritmo identificou que o valor de rede era menor que o valor anterior do mesmo container ele dividia a seção anterior para um arquivo novo, resultando em mais de 600 arquivos csv diferentes para o teste descrito em \myref{subsec}{Teste de tempo de operações paralelas}.\newline

Cada um sendo correspondente a uma interação.Após isso o algoritmo de processamento juntava uma quantidade máxima definida de testes por arquivo svg, resultando nas 12 imagens de cada container apresentadas nos anexos deste trabalho.

\ch{Resultados}

\sec{Resultados de inserção fracionada}
O resultado encontrado do primeiro teste de manipulação de bancos de dados, que é o teste de inserção contínua, onde foram inseridos de acordo com \myref{subsec}{Teste de tempo de operação de inserção no BD}, esses dados são comprovadamente sem ocorrência de erros de acordo com o código descrito em \myref{sec}{Geração de dados}, de acordo com os dados coletados pelo \myref{sec}{Contêineres docker} em todos os núcleos disponíveis para o contêiner existe uma variação de porcentagem de uso, como descrito nos arquivos de logs anexos e na tabela \myref{tab}{Resultados insercao fracionada}.Essa variação ocorre, no computador \myref{sig}{ARM} por ter mais núcleos físicos, portanto é mais complicado de ser avaliada a porcentagem de uso devido a forma como o Dockerdistribui a carga de uso de cpu.Em relação ao uso de RAM, ele se manteve mais constante na arquitetura \myref{sig}{ARM}.O uso de RAM é bem menor que no \myref{sig}{AMD64}, nas duas arquiteturas a diferença do uso de RAM é de cerca de 5\%, onde no MariaDB a variação faz com que o uso de RAM seja ligeiramente maior no\myref{sig}{AMD64}.Para o postgres a velocidade de disco de escrita é em torno de 500kbps para o \myref{sig}{ARM} e 3Mbps para o amd.Já para o MariaDB é de 3.5Mbps para o \myref{sig}{ARM} e 9.5Mbps para o \myref{sig}{AMD64}.\newline

levando em conta a descrição de \myref{ch}{Testes}, essas variações das velocidades são provavelmente devido a otimizações das arquiteturas para cada banco de dados.já a velocidade de leitura de disco é praticamente 0\% o tempo todo, isso se deve a pouca necessidade de informações consultada dos dados cadastrados pelo algoritmo de benchmark.\newline

A principal diferença identificada em relação aos testes além do previamente informado é o tempo, em 60\% das vezes o postgres \myref{sig}{ARM} é mais rápido que o \myref{sig}{AMD64}, enquanto isso em 85\% das vezes do MariaDB o \myref{sig}{AMD64} é mais rápido.

\imagemsvg{resultados insercao fracionada}{insercao fracionada/insercao tempos.svg}{valores tempo benchmark inserção fracionada,o eixo x corresponde a quantidade de elementos totais inseridos e o eixo y corresponde ao tempo gasto em segundos para cada 5000 elementos inseridos}


\begin{easyTableAuto}{dados encontrados de uso de hardware teste inserção}{ container & média de cpu & valor máximo médio de cpu & média de ram & valor máximo médio de ram }{5}{p{.15\textwidth}|p{.15\textwidth}|p{.2\textwidth}|p{.15\textwidth}|p{.2\textwidth}}
%nome da tabela e label
%cabeçalho
%quantidade total de colunas
%formatação da tabela
 postgres arm & 8 & 25 & 27 & 28 \\ \hline
 postgres amd & 18 & 27 & 30 & 30 \\ \hline
 mariadb arm & 8 & 16 & 34 & 35 \\ \hline
 mariadb amd & 18 & 27 & 34 & 35 \\ \hline

\end{easyTableAuto}
%lable
%arquivo
%caption
\sec{Resultados de operação completa fracionada}
Ao contrário do que era esperado, os valores gerados pelo \myref{sec}{Software de benchmark} geraram de forma igualmente distribuída, ou seja,os dados foram gerados com uma distribuição de aproximadamente 20\% para cada tipo de operação.Isso por que por algum motivo desconhecido as operações de tipo 5, como descrito em \myref{subsec}{Tipos de dados gerados}, não foram gerados nenhuma vez durante os testes, fora isso todos os outros dados gerados ocorreram como o esperado, onde são feitas queries de seleção, pesquisa e inserção da forma como era esperada e as operações ocorreram como o esperado.\newline

Um fator interessante a se destacar é que, apesar da distribuição de operações ter sido homogênea, o custo de uso de hardware não foi.Em certos momentos houve um grande uso de cpu, mas nunca fugindo muito dos valores apresentados em \myref{sec}{Resultados de inserção fracionada}, e na maioria dos casos houve um maior uso de ram que o apresentado no dito teste, um fator a se destacar é o de que os primeiros ciclos de teste funciona da seguinte forma:
\pagebreak
\begin{itemize}
\item A maior parte, cerca de 60\% dos dados, foi de inserção e o restante de operações variadas, diferente do esperado, isso provavelmente se deve a algum problema durante a gerência dos arquivos salvos na máquina, não no algoritmo em si, isso se comprova nos próximos nove ciclos.
\item A partir do 11° ciclo, no postgres, houve um aumento significativo de RAM, os valores que variam entre 18 a 30\% começaram a variar de 18 a 53\% no \myref{sig}{AMD64} e no \myref{sig}{ARM} a variação saiu de 20\% a 34\% para de 20 a 52\%.
\end{itemize}
Os tempos apresentados por esse teste estão descritos em \autoref{imagem:resultados todos fracionada}
\imagemsvg{resultados todos fracionada}{todos fracionada/todos tempos.svg}{valores tempo benchmark de operações mistas fracionadas,o eixo x corresponde a quantidade de elementos totais inseridos em função de 10e6  e o eixo y corresponde ao tempo gasto em segundos para cada 5000 elementos inseridos}

Uma coisa interessante ocorreu em uma etapa do teste, onde aparentemente a máquina que estava executando o teste travou e voltou a funcionar em seguida, isso visto que como as imagens do \myref{subsec}{Resultados todos parte 9} demonstram, durante um intervalo de tempo nenhum dos containers estavam ativos,e sendo assim,nenhuma operação estava sendo realizada neles.\newline
%lable
%arquivo
%caption

\begin{easyTableAuto}{dados encontrados de uso de hardware teste completo}{ container & média de cpu & valor máximo médio de cpu & média de ram & valor máximo médio de ram }{5}{p{.15\textwidth}|p{.15\textwidth}|p{.2\textwidth}|p{.15\textwidth}|p{.2\textwidth}}
%nome da tabela e label
%cabeçalho
%quantidade total de colunas
%formatação da tabela
 postgres arm & 16 & 33 & 61 & 63 \\ \hline
 postgres amd & 9 & 45 & 62 & 63 \\ \hline
 mariadb arm & 16 & 23 & 30 & 30 \\ \hline
 mariadb amd & 9 & 16 & 35 & 35 \\ \hline
\end{easyTableAuto}

\sec{Problemas e erros}
aqui foram descritos os erros mais marcantes durante os processos necessários para a obtenção dos resultados.

\subsec{Desenvolvimento do algorítimo}
Durante o desenvolvimento, vários tipos de erros aconteceram.Em praticamente todas as etapas de desenvolvimento do algoritmo erros marcantes ocorreram, os principais ocorreram durante a etapa de criação do sqlite, no processamento paralelo e na inserção dentro do banco de dados finais.Os dados relevantes das máquinas usadas para o desenvolvimento foram um ryzen 3200g com 16GB de RAM e ssd de 480GB e um i7 7500u com 8GB de RAM e ssd de 240GB.

\subsubsec{Erros da geração do Sqlite}
Durante a geração do sqlite vários problemas relacionados a geração ocorreram.Um deles fez com que a funcionalidade de seleção de múltiplos países na geração de dados tivesse que ser travada apenas para o Brasil, isso principalmente por que dos vários dados gerados, alguns causam problemas ao ser trocado o país.Como foi dito em \myref{sec}{Biblioteca faker} existem vários parâmetros diferentes dependendo do país selecionado, o mais marcante desses dados no entanto é a geração de números de celular, visto que o brasil é um dos poucos países que possuem essa opção dentre os existentes na biblioteca.Apesar de não ser o único problema encontrado, existem também problemas com os parâmetros de geração de endereço e alguns poucos dados de informações pessoais.Todos esses erros podem facilmente ser corrigidos com tratamentos de erro internos em cada tipo, mas para os propósitos deste trabalho não se provaram proveitosos o bastante.\newline

\subsubsec{Erro do processamento paralelo de threads}
Durante a etapa de processamento paralelo, seus problemas de desenvolvimento e erros se misturam com a etapa de inserção de dados no banco de dados final, pois ambos foram desenvolvidos simultaneamente, apesar de o processamento paralelo ter sido iniciado primeiro.\newline

O processamento paralelo teve vários tipos de problemas,o primeiro problema marcante foi a implementação original dele.Originalmente foi pensado em utilizar a implementação de threads ao invés de subprocessos, isso porque as threads são mais fáceis de serem lidas caso ocorra um erro, isso por que os dados são comunicados diretamente pela classe queue, que é utilizada para se compartilhar dados em tempo real entre várias instâncias de processamento durante a execução de um programa Python.\newline

As palavras chave aqui são compartilhamento entre várias instâncias, isso quer dizer que ela não faz distinção se as threads foram ou não iniciadas pela mesma classe, desde que existam threads elas compartilham as mesmas informações e espaço de memória .Isso foi identificado devido a árvore de processos necessária para que os testes fossem feitos de forma simultânea, já que ao se iniciar uma thread de um processo, essa thread não pode iniciar uma outra thread hierarquicamente inferior a ela.Isso resulta num problema da implementação da linguagem C sobre a qual a classe de processamento paralelo Queue foi construída.\newline

Esse erro de acordo com as documentações encontradas é devido ao compartilhamento de endereços de memória na linguagem c chamada "double free or corruption (out)".Esse erro ocorre quando se remove ou adiciona alguma variável ou índice de vetor de um processamento paralelo, devido a forma como a biblioteca de processamento paralelo lida com valores das operações para evitar execução dupla de algum valor isso é necessário.Essa situação não ocorre quando se utiliza a biblioteca Manager ao invés da Queue, porém essa biblioteca está associada ao processamento paralelo de subprocessos, por isso a migração de threads para subprocessos foi escolhida.\newline

\subsubsec{Erro do processamento paralelo de subprocessos daemon}
Um dos problemas encontrados foi uma mensagem de erro chamada de "AssertionError: daemonic processes are not allowed to have children" esse erro impede que processos daemon tenham processos filhos, o que fez com que o processo de sub-processamento tivesse q ser convertido de daemon para um processo convencional, isso pode ser problemático quando se quer fazer um monitoramento do tempo de forma mais direta, isso pois no modo daemon é possível rodar um código enquanto aguarda a execução dos processos daemon serem terminadas, esse foi o método escolhido no final do desenvolvimento devido a modificação na forma como o processo que possui daemon foi implementado, sendo que apenas as threads filhas eram daemons, as threads principais, que são as onde o tempo é monitorado, foi utilizado o método de se esperar a execução de todos subprocessos terminarem e medir o tempo gasto pelo conjunto, onde essa thread retornava o tempo para a função que a chamou, o processo foi um pouco mais complexo de implementar que o previamente proposto, mas terminou com o mesmo resultado.\newline

\subsubsec{Rollback de dados no postgres}
Outro erro marcante foi o de tratamento de rollback nas operações do postgres, devido a forma como as operações dos bancos de dados foram geradas, nenhuma das operações além da inserção, é realmente válida, o que quer dizer que de acordo com os métodos de segurança e otimização do postgres é necessário executar um rollback após a sua execução para evitar problemas.Isso resulta entre outras coisas numa maior demora da execução do postgres quando dados considerados inválidos são executados e também numa maior necessidade de tratamento de erros na parte relacionada ao postgres da biblioteca \myref{subsec}{gerenciadorDeBD}, devido ao rollback necessário, durante a etapa de desenvolvimento foi necessário reformular os tratamentos de erro de várias formas para que apenas os erros que realmente necessitavam de rollback tivessem a operação executada, já que devido a hierarquia do tratamento de erro da biblioteca psycopg2, alguns erros que ocorriam eram entendidos como necessários de serem executados os rollback em vez do tratamento correto, principalmente o erro de timeout da conexão ou de conexão fechada.

\subsec{Erros dos testes finais}
Durante a etapa de testes finais,ou seja,após a etapa de testes de desenvolvimento,foi utilizado um servidor baseado no FX-6300, utilizando 4GB de RAM e um HD mecânico de 160GB.

\subsubsec{Erro de leitura pela falta de velocidade de disco}
O HD mecânico da máquina dos testes finais possui velocidades limitadas pela sua tecnologia, SATA 2.Isso impactou de forma considerável a execução dos testes, pois mesmo com a possibilidade de serem feitos diversas leituras simultâneas no sqlite, mesmo sendo possível várias leituras simultâneas nesse método de armazenamento de dados, isso pois a latência entre a requisição da consulta e todo o processo lógico e físico da leitura causasse um time out ocasional na biblioteca sqlite.Uma solução para isso foi a substituição da mídia de armazenamento do arquivo sqlite, foi utilizado um pendrive Kingston 3.0 de 16GB, com velocidades de leitura superiores, de quase o dobro da velocidade, e latência muito inferior que a tecnologia SATA 2, após essa substituição não foi mais visto nenhum erro de timeout durante os testes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                      Capítulo 6                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ch{Conclusão}
Como conclusão dos testes realizados, foi confirmado que a arquitetura a \myref{sig}{ARM} é a mais eficiente em relação ao desempenho por watt consumido.Mas os resultados de ambos foram bem próximos, quase iguais para cada banco de dados diferente.O que resultou numa eficiência de cerca de 9 vezes para a arquitetura arm, visto que o computador \myref{sig}{ARM} utilizado consome 10w de energia enquanto o computador \myref{sig}{AMD64} utilizado consome 90w de energia, isso considerando que o consumo de ambos foi de 100\% da capacidade das respectivas fontes o tempo todo.\newline

Os testes realizados foram focados em manter ambos os servidores com a mesma exata característica de carga e desempenho, isso sempre visando o objetivo final de fazer com que a maior parte dos dados coletados pudesse ser diretamente comparáveis, já que o mesmo número de núcleos, ram, velocidade de disco e rede estavam disponíveis para ambas máquinas e o clock de ambas também foi limitado para exatos 1ghz para que as contas finais de comparação fossem mais simples.Sendo assim pode-se considerar os testes como sendo testes 1 para 1 nas diferentes arquiteturas.\newline

Os dados coletados apontam que a arquitetura \myref{sig}{ARM} possui uma porcentagem de uso de cpu mais baixa que a da arquitetura \myref{sig}{AMD64}, o que indica uma otimização em relação a isso do ponto de vista dessa arquitetura.Essa diferença causou uma maior demora de processamento na arquitetura \myref{sig}{ARM}, isso levando em conta que a diferença é bem baixa se torna irrisória em relação às comparações de arquiteturas.Enquanto a arquitetura \myref{sig}{AMD64} apresentou um consumo maior de ram, sendo assim é possível indicar que os programas de banco de dados utilizados tiveram suas otimizações focadas em coisas diferentes.Os bancos de dados Mariadb e postgres apresentam diferenças visíveis entre si em relação a uso de RAM e CPU.\newline

Em resumo,levando em conta as comparações feitas no ambiente utilizado, o benchmark resultou em dados estatisticamente iguais em ambas as máquinas utilizadas, resultando apenas numa diferença final apenas em relação ao consumo energético entre as máquinas que, levando em conta que ambas máquinas estão bem ultrapassadas em quesitos de eficiência energética para suas respectivas arquiteturas, torna a arquitetura \myref{sig}{ARM} a mais indicada para ambientes de servidor de bancos de dados visto que pode resultar numa visível diferença de custos para a empresa que hospedar essas máquinas.



%\anexo{log tempo insercao}{teste insercao/valores_tempo_velocidade_benchmark_fracionado.json}
%\label{anexo:#1}
%\lstinputlisting{apendices/teste insercao/valores_tempo_velocidade_benchmark_fracionado.json}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                      REFERÊNCIAS                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\nocite{inteli5}
\nocite{m1vsi5}
\nocite{armv9}
\nocite{mariamongomysqlpostgre}
\nocite{mysqlpostgressqlserver}
\nocite{mysqlpostgres}
\nocite{dockerdoc}
\nocite{dockercomposedoc}
\nocite{psutil}
\nocite{portainer}
\nocite{multiprocessing}
\nocite{threading}
\nocite{sqlite3}
\nocite{logging}
\nocite{faker}
\nocite{dockerpython}
\nocite{elk}
\nocite{opipc}
\nocite{G405}
\nocite{E1}
\nocite{h3}
\nocite{postgrespython}
\nocite{mysqlpython}
\nocite{histARMEmbarcados}
\nocite{ARMv6Manual}
\nocite{ARMhist}
\nocite{ciscxrisc}
\nocite{cisc}
\nocite{risc}
\nocite{armevolution}
\nocite{riscvscisc}
\bibliography{abntex2-modelo-references}

% ---
% Finaliza a parte no bookmark do PDF, para que se inicie o bookmark na raiz
% ---
\bookmarksetup{startatroot}%
% ---

% ---------------------------------------------------------------------------------------------
% ELEMENTOS PÓS-TEXTUAIS
% ---------------------------------------------------------------------------------------------
\apendices
\ch{apendices relacionados ao teste completo}
\sec{imagens}
o eixo x em todos os graficos é o tempo decorrido,no grafico de cima o eixo y é o uso de cpu,onde cada cor é um nucleo diferente,no grafico do meio o eixo y é o uso de ram em porcentagem e no grafico de baixo o eixo y corresponde ao uso de disco em megabytes,ou bytes em escala de 10e6,onde em azul é a leitura de disco e em laranja é a leitura de disco
\subsec{todos tempos}
\apendicesvg{todos fracionada/todos tempos.svg}{valores tempo benchmark de operações mistas fracionadas,o eixo x corresponde a quantidade de elementos totais inseridos em função de 10e6  e o eixo y corresponde ao tempo gasto em segundos para cada 5000 elementos inseridos}
\pagebreak

\subsec{Resultados todos parte 0}
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo0.svg}{Intervalo 0 do uso de hardware do container mariadb na arquitetura amd64}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo0.svg}{Intervalo 0 do uso de hardware do container mariadb na arquitetura armhf}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo0.svg}{Intervalo 0 do uso de hardware do container postgres na arquitetura amd64}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo0.svg}{Intervalo 0 do uso de hardware do container postgres na arquitetura armhf}%
\pagebreak

%\subsec{Resultados todos parte 1}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo1.svg}{Intervalo 1 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo1.svg}{Intervalo 1 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo1.svg}{Intervalo 1 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo1.svg}{Intervalo 1 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 2}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo2.svg}{Intervalo 2 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo2.svg}{Intervalo 2 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo2.svg}{Intervalo 2 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo2.svg}{Intervalo 2 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 3}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo3.svg}{Intervalo 3 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo3.svg}{Intervalo 3 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo3.svg}{Intervalo 3 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo3.svg}{Intervalo 3 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 4}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo4.svg}{Intervalo 4 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo4.svg}{Intervalo 4 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo4.svg}{Intervalo 4 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo4.svg}{Intervalo 4 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 5}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo5.svg}{Intervalo 5 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo5.svg}{Intervalo 5 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo5.svg}{Intervalo 5 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo5.svg}{Intervalo 5 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 6}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo6.svg}{Intervalo 6 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo6.svg}{Intervalo 6 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo6.svg}{Intervalo 6 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo6.svg}{Intervalo 6 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 7}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo7.svg}{Intervalo 7 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo7.svg}{Intervalo 7 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo7.svg}{Intervalo 7 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo7.svg}{Intervalo 7 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 8}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo8.svg}{Intervalo 8 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo8.svg}{Intervalo 8 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo8.svg}{Intervalo 8 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo8.svg}{Intervalo 8 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 9}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo9.svg}{Intervalo 9 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo9.svg}{Intervalo 9 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo9.svg}{Intervalo 9 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo9.svg}{Intervalo 9 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 10}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo10.svg}{Intervalo 10 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo10.svg}{Intervalo 10 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo10.svg}{Intervalo 10 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo10.svg}{Intervalo 10 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 11}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo11.svg}{Intervalo 11 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo11.svg}{Intervalo 11 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo11.svg}{Intervalo 11 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo11.svg}{Intervalo 11 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

%\subsec{Resultados todos parte 12}
%\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo12.svg}{Intervalo 12 do uso de hardware do container mariadb na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo12.svg}{Intervalo 12 do uso de hardware do container mariadb na arquitetura armhf}%
%\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo12.svg}{Intervalo 12 do uso de hardware do container postgres na arquitetura amd64}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo12.svg}{Intervalo 12 do uso de hardware do container postgres na arquitetura armhf}%
%\pagebreak

\sec{Arquivos}
\subsec{Logs todas operações mariadb amd}
\fbox{\begin{minipage}{\textwidth}

uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 2, 2, 0, 15, 54]\newline
[6362, 50779, 216701, 273480, 32996, 555223, 99182, 3766, 341, 17]\newline
[22, 19, 5, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 40\newline
o valor com mais ocorrencias de uso de ram é 35\newline
\newline
\newline
\newline
uso de cpu\newline
[4, 7, 2, 1, 0, 1, 5, 2482, 51165, 700744]\newline
[0, 1288, 49, 11, 86, 3079, 290263, 2, 59534, 0]\newline
[0, 246, 682, 9325, 0, 10315, 30, 9474, 334, 0]\newline
[1448, 1, 0, 4629, 0, 142, 4702, 25, 738, 0]\newline
[0, 2022, 56, 5, 321, 2814, 383, 1, 0, 0]\newline
[0, 0, 1, 341, 1805, 181, 1, 80, 926, 0]\newline
[0, 237, 6, 1426, 55, 0, 762, 0, 2, 114]\newline
[0, 8, 1037, 1, 0, 487, 82, 83, 8, 0]\newline
[0, 856, 0, 463, 90, 7, 0, 2, 50, 0]\newline
[943, 647, 153, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}
\pagebreak

\subsec{Logs todos operações mariadb armhf}
\fbox{\begin{minipage}{\textwidth}
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 5, 16, 8]\newline
[16, 21, 58, 123, 903, 7033, 21051, 106000, 133555, 188308]\newline
[240178, 33226, 110, 31, 45, 21, 74, 106, 22, 131]\newline
[70, 7, 94, 4, 131, 52, 13, 276, 3, 168]\newline
[369, 19, 1, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 30\newline
o valor com mais ocorrencias de uso de ram é 30\newline
\newline
\newline
\newline
uso de cpu\newline
[21, 6, 7, 12, 15, 72, 129, 65494, 34474, 104121]\newline
[5, 252, 96, 132, 2292, 7845, 385212, 10, 30660, 5]\newline
[4, 1269, 188, 189609, 3, 22745, 145, 4737, 6845, 16]\newline
[5311, 41, 0, 7238, 0, 816, 3030, 23, 3269, 0]\newline
[1, 4067, 585, 12, 18, 1582, 2072, 6, 0, 0]\newline
[0, 0, 2, 1352, 1081, 18, 3, 239, 1733, 0]\newline
[0, 881, 1, 725, 174, 0, 1187, 0, 5, 646]\newline
[1, 123, 458, 12, 0, 802, 519, 5, 95, 0]\newline
[0, 227, 0, 433, 261, 77, 11, 2, 2, 0]\newline
[102, 215, 145, 3, 1, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}
\pagebreak

\subsec{Logs todos operações postgres amd}
\fbox{\begin{minipage}{\textwidth}
 uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 3263, 30386, 26906, 1113, 12273, 13977, 6987]\newline
[12137, 12152, 14554, 16969, 24602, 32591, 34546, 26028, 29965, 35166]\newline
[37614, 35360, 36454, 39982, 44499, 51398, 54360, 61957, 64734, 70274]\newline
[73288, 71273, 74495, 71518, 69823, 62375, 54838, 46323, 40031, 42772]\newline
[55185, 72958, 82168, 73553, 37296, 6388, 691, 523, 321, 93]\newline
[15, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 62\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 8, 1, 3, 1, 1, 31, 2597, 38173, 344957]\newline
[0, 17264, 1282, 143, 901, 7344, 166851, 17, 177235, 1]\newline
[0, 1847, 13955, 19279, 1, 94879, 784, 146286, 3954, 65]\newline
[23579, 346, 3, 101781, 1, 6089, 124456, 2092, 25778, 0]\newline
[3, 79642, 7366, 1016, 11027, 102958, 27511, 663, 2, 1]\newline
[1, 1, 891, 26264, 84182, 9902, 1478, 8258, 57722, 38]\newline
[18, 20908, 3810, 65989, 7925, 204, 60423, 14, 1976, 18270]\newline
[927, 7100, 55495, 3289, 15, 44659, 17674, 9914, 6742, 61]\newline
[35, 45854, 1037, 33769, 14665, 6772, 2917, 4874, 12472, 378]\newline
[45469, 37198, 23804, 5302, 2657, 991, 261, 52, 2, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}
\pagebreak

\subsec{Logs todos operações postgres armhf}
\fbox{\begin{minipage}{\textwidth}
 uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 255, 7152, 16283]\newline
[32831, 19896, 2336, 2662, 4372, 6181, 7587, 12039, 10345, 12301]\newline
[15140, 20210, 21261, 22132, 25138, 25781, 24380, 24325, 25114, 28020]\newline
[33401, 32594, 36043, 34009, 37117, 38893, 37737, 39704, 44899, 44957]\newline
[44297, 46854, 46327, 49719, 51753, 48376, 52095, 58927, 59520, 68535]\newline
[73293, 80115, 79706, 61333, 40287, 26496, 17648, 11358, 6472, 2002]\newline
[577, 220, 94, 22, 80, 29, 4, 51, 100, 59]\newline
[72, 55, 24, 12, 3, 27, 121, 72, 70, 61]\newline
[71, 14, 7, 2, 2, 3, 1, 83, 61, 112]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 61\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 12, 10, 28, 68, 588, 3618, 118494, 330874, 352961]\newline
[85, 10533, 4960, 2176, 16008, 92217, 623653, 285, 282050, 39]\newline
[7, 12853, 7361, 220074, 4, 274752, 2669, 134714, 22195, 439]\newline
[89115, 1320, 2, 169013, 19, 15285, 93588, 4316, 64198, 23]\newline
[36, 117739, 14214, 1406, 4456, 70651, 54517, 903, 19, 1]\newline
[0, 10, 934, 47887, 58121, 3592, 1484, 11312, 81406, 91]\newline
[69, 38937, 2630, 46263, 10104, 218, 75911, 31, 1597, 36127]\newline
[632, 9434, 43290, 3032, 46, 69151, 34191, 2579, 8050, 88]\newline
[52, 33862, 653, 46121, 23382, 6358, 2337, 1375, 1741, 188]\newline
[25154, 40896, 30033, 3361, 890, 339, 148, 70, 8, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}
\pagebreak

\ch{Apendices relacionados ao teste insercao}
\sec{Imagens}
primeira linha dos resultados mostra o uso decpu,na segunda mostra o uso de ram e na terceira mostra o uso de disco
\subsec{Todos tempos}
%%\apendicesvg{insercao fracionada/insercao tempos.svg}{valores tempo benchmark de operação de inserção,o eixo x corresponde a quantidade de elementos totais inseridos em função de 10e6  e o eixo y corresponde ao tempo gasto em segundos para cada 5000 elementos inseridos}
\subsec{Resultados insercao parte 0}
%%\apendicesvg{insercao fracionada/uso do container container_mariadb_amd_limpo0.svg}{Intervalo 1 do uso de hardware do container mariadb na arquitetura amd64}
%%\apendicesvg{insercao fracionada/uso do container container_mariadb_armhf_limpo0.svg}{Intervalo 1 do uso de hardware do container mariadb na arquitetura armhf}
%%\apendicesvg{insercao fracionada/uso do container container_postgres_amd_limpo0.svg}{Intervalo 1 do uso de hardware do container postgres na arquitetura amd64}
%%\apendicesvg{insercao fracionada/uso do container container_postgres_armhf_limpo0.svg}{Intervalo 1 do de hardware do container postgres na arquitetura amd64}
\pagebreak

\sec{Arquivos}
\subsec{Logs insercao mariadb amd}
\fbox{\begin{minipage}{\textwidth}
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 2, 2, 0, 15, 54]\newline
[6362, 50779, 216701, 273480, 32996, 555223, 99182, 3766, 341, 17]\newline
[22, 19, 5, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 40\newline
o valor com mais ocorrencias de uso de ram é 35\newline
\newline
\newline
\newline
uso de cpu\newline
[4, 7, 2, 1, 0, 1, 5, 2482, 51165, 700744]\newline
[0, 1288, 49, 11, 86, 3079, 290263, 2, 59534, 0]\newline
[0, 246, 682, 9325, 0, 10315, 30, 9474, 334, 0]\newline
[1448, 1, 0, 4629, 0, 142, 4702, 25, 738, 0]\newline
[0, 2022, 56, 5, 321, 2814, 383, 1, 0, 0]\newline
[0, 0, 1, 341, 1805, 181, 1, 80, 926, 0]\newline
[0, 237, 6, 1426, 55, 0, 762, 0, 2, 114]\newline
[0, 8, 1037, 1, 0, 487, 82, 83, 8, 0]\newline
[0, 856, 0, 463, 90, 7, 0, 2, 50, 0]\newline
[943, 647, 153, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}
\pagebreak

\subsec{Logs insercao mariadb armhf}
\fbox{\begin{minipage}{\textwidth}
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 5, 16, 8]\newline
[16, 21, 58, 123, 903, 7033, 21051, 106000, 133555, 188308]\newline
[240178, 33226, 110, 31, 45, 21, 74, 106, 22, 131]\newline
[70, 7, 94, 4, 131, 52, 13, 276, 3, 168]\newline
[369, 19, 1, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 30\newline
o valor com mais ocorrencias de uso de ram é 30\newline
\newline
\newline
\newline
uso de cpu\newline
[21, 6, 7, 12, 15, 72, 129, 65494, 34474, 104121]\newline
[5, 252, 96, 132, 2292, 7845, 385212, 10, 30660, 5]\newline
[4, 1269, 188, 189609, 3, 22745, 145, 4737, 6845, 16]\newline
[5311, 41, 0, 7238, 0, 816, 3030, 23, 3269, 0]\newline
[1, 4067, 585, 12, 18, 1582, 2072, 6, 0, 0]\newline
[0, 0, 2, 1352, 1081, 18, 3, 239, 1733, 0]\newline
[0, 881, 1, 725, 174, 0, 1187, 0, 5, 646]\newline
[1, 123, 458, 12, 0, 802, 519, 5, 95, 0]\newline
[0, 227, 0, 433, 261, 77, 11, 2, 2, 0]\newline
[102, 215, 145, 3, 1, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}
\pagebreak

\subsec{Logs insercao postgres amd}
\fbox{\begin{minipage}{\textwidth}
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 3263, 30386, 26906, 1113, 12273, 13977, 6987]\newline
[12137, 12152, 14554, 16969, 24602, 32591, 34546, 26028, 29965, 35166]\newline
[37614, 35360, 36454, 39982, 44499, 51398, 54360, 61957, 64734, 70274]\newline
[73288, 71273, 74495, 71518, 69823, 62375, 54838, 46323, 40031, 42772]\newline
[55185, 72958, 82168, 73553, 37296, 6388, 691, 523, 321, 93]\newline
[15, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 62\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 8, 1, 3, 1, 1, 31, 2597, 38173, 344957]\newline
[0, 17264, 1282, 143, 901, 7344, 166851, 17, 177235, 1]\newline
[0, 1847, 13955, 19279, 1, 94879, 784, 146286, 3954, 65]\newline
[23579, 346, 3, 101781, 1, 6089, 124456, 2092, 25778, 0]\newline
[3, 79642, 7366, 1016, 11027, 102958, 27511, 663, 2, 1]\newline
[1, 1, 891, 26264, 84182, 9902, 1478, 8258, 57722, 38]\newline
[18, 20908, 3810, 65989, 7925, 204, 60423, 14, 1976, 18270]\newline
[927, 7100, 55495, 3289, 15, 44659, 17674, 9914, 6742, 61]\newline
[35, 45854, 1037, 33769, 14665, 6772, 2917, 4874, 12472, 378]\newline
[45469, 37198, 23804, 5302, 2657, 991, 261, 52, 2, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}
\pagebreak

\subsec{Logs insercao postgres armhf}
\fbox{\begin{minipage}{\textwidth}
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 255, 7152, 16283]\newline
[32831, 19896, 2336, 2662, 4372, 6181, 7587, 12039, 10345, 12301]\newline
[15140, 20210, 21261, 22132, 25138, 25781, 24380, 24325, 25114, 28020]\newline
[33401, 32594, 36043, 34009, 37117, 38893, 37737, 39704, 44899, 44957]\newline
[44297, 46854, 46327, 49719, 51753, 48376, 52095, 58927, 59520, 68535]\newline
[73293, 80115, 79706, 61333, 40287, 26496, 17648, 11358, 6472, 2002]\newline
[577, 220, 94, 22, 80, 29, 4, 51, 100, 59]\newline
[72, 55, 24, 12, 3, 27, 121, 72, 70, 61]\newline
[71, 14, 7, 2, 2, 3, 1, 83, 61, 112]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 61\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 12, 10, 28, 68, 588, 3618, 118494, 330874, 352961]\newline
[85, 10533, 4960, 2176, 16008, 92217, 623653, 285, 282050, 39]\newline
[7, 12853, 7361, 220074, 4, 274752, 2669, 134714, 22195, 439]\newline
[89115, 1320, 2, 169013, 19, 15285, 93588, 4316, 64198, 23]\newline
[36, 117739, 14214, 1406, 4456, 70651, 54517, 903, 19, 1]\newline
[0, 10, 934, 47887, 58121, 3592, 1484, 11312, 81406, 91]\newline
[69, 38937, 2630, 46263, 10104, 218, 75911, 31, 1597, 36127]\newline
[632, 9434, 43290, 3032, 46, 69151, 34191, 2579, 8050, 88]\newline
[52, 33862, 653, 46121, 23382, 6358, 2337, 1375, 1741, 188]\newline
[25154, 40896, 30033, 3361, 890, 339, 148, 70, 8, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}
\postextual


% ---------------------------------------------------------------------------------------------
% Referências bibliográficas
% ---------------------------------------------------------------------------------------------

% ---------------------------------------------------------------------------------------------
% Glossário
% ---------------------------------------------------------------------------------------------
%
% Consulte o manual da classe abntex2 para orientações sobre o glossário.
%
%\glossary

% ---------------------------------------------------------------------------------------------

% Anexos
% ---------------------------------------------------------------------------------------------

% ---
% Inicia os anexos
% ---

% ---------------------------------------------------------------------------------------------
% INDICE REMISSIVO
% ---------------------------------------------------------------------------------------------

\printindex

\end{document}

\documentclass[
% -- opções da classe memoir --
12pt,				% tamanho da fonte
openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
oneside,			% para impressão em verso e anverso. Oposto a oneside
a4paper,			% tamanho do papel.
% -- opções da classe abntex2 --
%chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
%section=TITLE,		% títulos de seções convertidos em letras maiúsculas
%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
%subsubsection=TITLE,% títulos de subsubseções convertidos em letras maiúsculas
% -- opções do pacote babel --
english,			% idioma adicional para hifenização
french,				% idioma adicional para hifenização
spanish,			% idioma adicional para hifenização
brasil,				% o último idioma é o principal do documento
]{abntex2}


% ---
% PACOTES
% ---
% ---
% Pacotes fundamentais
% ---
\usepackage{cmap}				% Mapear caracteres especiais no PDF
%\usepackage{lmodern}			% Usa a fonte Latin Modern
\usepackage{helvet}
\usepackage[T1]{fontenc}		% Selecao de codigos de fonte.
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{lastpage}			% Usado pela Ficha catalográfica
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{color}				% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{underscore}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{graphicx} % Usado para outros tipos de imagens
\usepackage{float} % Usado para posicionamento de imagens
\usepackage[notransparent]{svg}  % Eis o pacote que queremos.
\usepackage{alltt}
\usepackage{filecontents}
\usepackage{listings}
\usepackage{subfiles}
\linespread{1.5} % espaçamento entre linhas
% ---
% Pacotes adicionais, usados apenas no âmbito do Modelo Canônico do abnteX2
% ---
\usepackage{lipsum}				% para geração de dummy text
% ---

% ---
% Pacotes de citações
% ---
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{listings}
\hypersetup{
	colorlinks=false,
	pdfpagemode=FullScreen,
	pdftitle={benchmark bancos de dados multi arquitetura},
}
\hypersetup{final}
\urlstyle{same}
% ---
% CONFIGURAÇÕES DE PACOTES
% ---

% ---
% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
%\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
\renewcommand{\backrefpagesname}{}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
% Define os textos da citação
%\renewcommand*{\backrefalt}[4]{
%	\ifcase #1 %
%	Nenhuma citação no texto.%
%	\or
%	%Citado na página #2.%
%	\else
%	%Citado #1 vezes nas páginas #2.%
%	\fi}%
% ---


% ---
% Informações de dados para CAPA e FOLHA DE ROSTO
%
\titulo{Benchmark de desempenho entre bancos de dados em diferentes arquiteturas}

\autor{Miguel Magalhães Lopes}
\local{Rio Pomba}
\data{20XX}
\orientador{Gustavo Henrique da Rocha Reis}
\coorientador{CICLANO}
%\instituicao{}
\tipotrabalho{Trabalho de Conclusão de Curso}
% O preambulo deve conter o tipo do trabalho, o objetivo,
% o nome da instituição e a área de concentração
\preambulo{Trabalho de Conclusão apresentado ao Campus Rio Pomba, do Instituto Federal de Educação, Ciência e Tecnologia do Sudeste de Minas Gerais, como parte das exigências do curso de Bacharelado em Ciência da Computação para a obtenção do título de Bacharel em Ciência da Computação.}
% ---


% ---
% Configurações de aparência do PDF final

% alterando o aspecto da cor azul
\definecolor{blue}{RGB}{41,5,195}

% informações do PDF
%\makeatletter
%\hypersetup{
	%pagebackref=true,
	%		pdftitle={\@title},
	%		pdfauthor={\@author},
	%    	pdfsubject={\imprimirpreambulo},
	%	    pdfcreator={Matheus F O Baffa},
	%		pdfkeywords={content-based image retrieval}{desenvolvimento web}{exame de fundo de olho}{histograma backprojection}{íris},
	%		colorlinks=true,       		% false: boxed links; true: colored links
	%    	linkcolor=black,          	% color of internal links
	%    	citecolor=black,        		% color of links to bibliography
	%    	filecolor=black,      		% color of file links
	%		urlcolor=black,
	%		bookmarksdepth=4
	%}
\makeatother
\graphicspath{ {./imagens/} }
% ---

% ---
% Espaçamentos entre linhas e parágrafos
% ---

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.3cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}  % tente também \onelineskip

% ---
% compila o indice
% ---
\makeindex
% ---

% ----
% Início do documento
% ----
\begin{document}

	% Retira espaço extra obsoleto entre as frases.
	\frenchspacing

	% ----------------------------------------------------------
	% ELEMENTOS PRÉ-TEXTUAIS
	% ----------------------------------------------------------
	% \pretextual

	% ---
	% Capa
	% ---
	\begin{center}
		\textbf{
			INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNOLOGIA DO SUDESTE DE MINAS GERAIS - CAMPUS RIO POMBA}
	\end{center}

	\imprimircapa
	% ---

	% ---
	% Folha de rosto
	% (o * indica que haverá a ficha bibliográfica)
	% ---
	\imprimirfolhaderosto*
	% ---

	% ---
	% Inserir a ficha bibliografica
	% ---

	% Isto é um exemplo de Ficha Catalográfica, ou ``Dados internacionais de
	% catalogação-na-publicação''. Você pode utilizar este modelo como referência.
	% Porém, provavelmente a biblioteca da sua universidade lhe fornecerá um PDF
	% com a ficha catalográfica definitiva após a defesa do trabalho. Quando estiver
	% com o documento, salve-o como PDF no diretório do seu projeto e substitua todo
	% o conteúdo de implementação deste arquivo pelo comando abaixo:
	%
	% \begin{fichacatalografica}
		%     \includepdf{fig_ficha_catalografica.pdf}
		% \end{fichacatalografica}
	\begin{fichacatalografica}
		\vspace*{\fill}					% Posição vertical
		\hrule							% Linha horizontal
		\begin{center}					% Minipage Centralizado
			\begin{minipage}[c]{12.5cm}		% Largura

				\imprimirautor

				\hspace{0.5cm} \imprimirtitulo  / \imprimirautor. --
				\imprimirlocal, \imprimirdata-

				\hspace{0.5cm} \pageref{LastPage} p. : il. (algumas color.) ; 30 cm.\\

				\hspace{0.5cm} \imprimirorientadorRotulo~\imprimirorientador\\

				\hspace{0.5cm}
				\parbox[t]{\textwidth}{\imprimirtipotrabalho~--~Instituto Federal de Educação, Ciência e Tecnologia do Sudeste de Minas, Campus Rio Pomba,
					\imprimirdata.}\\

				\hspace{0.5cm}
				1.
				2.
				I.
				II.
				III.
				IV. \\

				\hspace{8.75cm} %CDU 02:141:005.7\\

			\end{minipage}
		\end{center}
		\hrule
	\end{fichacatalografica}
	% ---

	% ---
	% Inserir errata
	% ---
	%\begin{errata}
	%Elemento opcional da \citeonline[4.2.1.2]{NBR14724:2011}. %Exemplo:

	%\vspace{\onelineskip}
	%
	%FERRIGNO, C. R. A. \textbf{Tratamento de neoplasias ósseas apendiculares com
		%reimplantação de enxerto ósseo autólogo autoclavado associado ao plasma
		%rico em plaquetas}: estudo crítico na cirurgia de preservação de membro em
	%cães. 2011. 128 f. Tese (Livre-Docência) - Faculdade de Medicina Veterinária e
	%Zootecnia, Universidade de São Paulo, São Paulo, 2011.

	%\begin{table}[htb]
	%\center
	%\footnotesize
	%\begin{tabular}{|p{1.4cm}|p{1cm}|p{3cm}|p{3cm}|}
	%  \hline
	%   \textbf{Folha} & \textbf{Linha}  & \textbf{Onde se lê} % & \textbf{Leia-se}  \\
	%    \hline
	%    1 & 10 & auto-conclavo & autoconclavo\\
	%   \hline
	%\end{tabular}
	%\end{table}
	%
	%\end{errata}
	% ---

	% ---
	% Inserir folha de aprovação
	% ---

	% Isto é um exemplo de Folha de aprovação, elemento obrigatório da NBR
	% 14724/2011 (seção 4.2.1.3). Você pode utilizar este modelo até a aprovação
	% do trabalho. Após isso, substitua todo o conteúdo deste arquivo por uma
	% imagem da página assinada pela banca com o comando abaixo:
	%
	% \includepdf{folhadeaprovacao_final.pdf}
	%
	\begin{folhadeaprovacao}

		\begin{center}
			{\ABNTEXchapterfont\large\imprimirautor}

			\vspace*{\fill}\vspace*{\fill}
			{\ABNTEXchapterfont\bfseries\Large\imprimirtitulo}
			\vspace*{\fill}

			\hspace{.45\textwidth}
			\begin{minipage}{.5\textwidth}
				\imprimirpreambulo
			\end{minipage}%
			\vspace*{\fill}
		\end{center}

		Trabalho aprovado. \imprimirlocal, 00 de dezembro de 20XX.

		\assinatura{\textbf{\imprimirorientador}, Orientador, IF Sudeste MG - Rio Pomba}
		\assinatura{\textbf{CICLANO}, Coorientador, IF Sudeste MG - Rio Pomba}
		\assinatura{\textbf{Dr. BELTRANO} \\ IF Sudeste MG - Rio Pomba}
		\assinatura{\textbf{Me. XXXXXXXXXXXXX} \\ IF Sudeste MG - Rio Pomba }
		%\assinatura{\textbf{Professor W} \\ IF Sudeste MG - Rio Pomba}

		\begin{center}
			\vspace*{0.5cm}
			{\large\imprimirlocal}
			\par
			{\large\imprimirdata}
			\vspace*{1cm}
		\end{center}

	\end{folhadeaprovacao}
	% ---


	% ---
	% Dedicatória
	% ---
	\begin{dedicatoria}
		\vspace*{\fill}
		\begin{flushright}
			Este trabalho é dedicado a todos\\
			aqueles que me inspiraram, em especial\\
			XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX \\
			XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.
		\end{flushright}
	\end{dedicatoria}
	% ---

	% ---
	% Agradecimentos
	% ---
	\begin{agradecimentos}

	\end{agradecimentos}

	% resumo em português
	\begin{resumo}
		\noindent

		\vspace{\onelineskip}

		\noindent
		\textbf{Palavras-chaves:} palavra1. palavra2. palavra3. palavra4.
	\end{resumo}

	% resumo em inglês
	\begin{resumo}[Abstract]
		\begin{otherlanguage*}{english}
			\vspace{\onelineskip}
			\noindent

			\vspace{\onelineskip}

			\noindent  \textbf{Key-words}:  word1. word2. word3. word4. word5.
		\end{otherlanguage*}
	\end{resumo}
	\urlstyle{same}

	\pdfbookmark[0]{\listfigurename}{lof}
	\listoffigures*
	\cleardoublepage

	\pdfbookmark[0]{\listtablename}{lot}
	\listoftables*
	\cleardoublepage

	\DeclareRobustCommand{\beginAutoTable}[4]{
		%nome da tabela e label
		%cabeçalho
		%quantidade total de colunas
		%formatação da tabela
		\label{tab:#1}
		\begin{longtable}{#4}
			\caption{#1}
			\\ \hline \multicolumn{#3}{c}{\textbf{#1}} \\ \hline
			#2 \\ \hline \endfirsthead
			#2 \\ \hline \endhead
		}
		\newenvironment{easyTableAuto}[4]{
			\beginAutoTable{#1}{#2}{#3}{#4}
		}{
		\end{longtable}
	}
	\newenvironment{easyTable2}[2]{
		\beginAutoTable{#1}{#2}{2}{p{.15\textwidth}|p{.80\textwidth}}
	}{
	\end{longtable}
}
\newenvironment{easyTable3}[2]{
	\beginAutoTable{#1}{#2}{3}{p{.16\textwidth}|p{.1\textwidth}|p{.70\textwidth}}
}{
\end{longtable}
}
\DeclareRobustCommand{\myref}[2]{
\textit{#2}$^{\text{#1\ref{#1:#2}}}$
}
\newcounter{sig}
\DeclareRobustCommand{\sig}[1]{
\refstepcounter{sig}
\label{sig:#1}
\item[#1]
}
\newcounter{ch}
\DeclareRobustCommand{\ch}[1]{
\refstepcounter{ch}
\chapter{#1}
\label{ch:#1}
}
\newcounter{sec}
\DeclareRobustCommand{\sec}[1]{
\refstepcounter{sec}
\section{#1}
\label{sec:#1}
}
\newcounter{subsec}
\DeclareRobustCommand{\subsec}[1]{
\refstepcounter{subsec}
\subsection{#1}
\label{subsec:#1}
}
%\patchcmd{\verbatim@input}{\@verbatim}{\scriptsize\@verbatim}{}{}

\newcounter{anexo}
\DeclareRobustCommand{\anexo}[2]{
\refstepcounter{anexo}
\label{anexo:#1}
\lstinputlisting{{\detokenize{apendices/#2}}}
}

\newcounter{imagem}
\DeclareRobustCommand{\imagemsvg}[3]{
%lable
%arquivo
%caption
\refstepcounter{imagem}
\begin{figure}[htbp]
\includesvg[width=\textwidth]{#2}
\caption{#3}
\label{imagem:#1}
\end{figure}
}
\DeclareRobustCommand{\imagempng}[3]{
%lable
%arquivo
%caption
\refstepcounter{imagem}
\begin{figure}[htbp]
\includegraphics[width=\textwidth]{#2}
\caption{#3}
\label{imagem:#1}
\end{figure}
}
\DeclareRobustCommand{\apendicesvg}[2]{
%lable
%arquivo
%caption
\refstepcounter{imagem}
\begin{figure}[htbp]
\includesvg[width=\textwidth]{{\detokenize{#2}}}
\caption{#1}
\label{imagem:#1}
\end{figure}
}
%\begin{figure}
%\includegraphics{artigos relacionados/oltp mysql.png}
%\caption{valores encontrados para o container mysql no artigo citado}
%\label{fig:valores encontrados oltp mysql}
%\end{figure}

\begin{siglas}
\sig{DACC} Departamento Acadêmico de Ciência da Computação

\sig{UFJF} Universidade Federal de Juiz de Fora

\sig{arm} ARM, originalmente Acorn RISC Machine, e depois Advanced RISC Machine, é uma família de arquiteturas RISC desenvolvida pela empresa britânica ARM Holdings

\sig{IDE}

\sig{x64} evolução da arquitetura \myref{sig}{x86} evoluida para 64 bit

\sig{x86} arquitetura 32 bit comum nos computadores domésticos atuais

\sig{aarch64} evolução 64bit da arquitetura \myref{sig}{arm}

\sig{JVM} JVM (Java Virtual Machine) é uma máquina abstrata. É uma especificação que fornece um ambiente de tempo de execução no qual o bytecode do java pode ser executado.
As JVMs estão disponíveis para muitas plataformas de hardware e software (ou seja, a JVM depende da plataforma).

\sig{IOT} internet das coisas,

\sig{SBC} single board computer,ou computador de placa unica,é um tipo de computador utilizado hoje em dia em que no mesmo chipset você encontra todas as estruturas principais do computador estão juntas obrigatóriamente os SBC possuem CPU e memória RAM e podem conter outras estruturas de um computador

\sig{WINE} O Wine é uma camada de tradução capaz de executar aplicações Windows em Linux e em outros sistemas operacionais compatíveis com POSIX

\end{siglas}


\tableofcontents*

\textual
\setcounter{page}{1}
% ---------------------------------------------------------------------------------------------
% Introdução
% ---------------------------------------------------------------------------------------------
\chapter*{Introdução}
\addcontentsline{toc}{chapter}{\textbf{Introdução}}
\markright{Introdução}
\label{ch:introducao}
Com a  crescente adoção de processadores \myref{sig}{arm}, que entregam eficiência energética superior a comumente utilizada nos computadores e servidores (arquitetura \myref{sig}{x86}),
que possui também uma versão 64 bits (\myref{sig}{x64}), que é praticamente a única variante utilizada atualmente. Essa arquitetura é, no geral, apenas uma variante aditiva da \myref{sig}{x86} , na qual são adicionadas instruções e suportes, sendo o principal deles comandos 64 bits. Esta pesquisa foi desenvolvida considerando o uso de servidores arm presentes no mundo corporativo. Dessa forma, foi feita uma comparação na utilização desses processadores para a simulação de uma aplicação de banco de dados. Essa aplicação simula, de forma realística, a utilização de uma base de dados de uma locadora.\newline
%O mesmo pode ser dito para a arquitetura \myref{sig}{aarch64} ou arm64 que é uma variante aditiva da \myref{sig}{arm},essa não é ,como a \myref{sig}{x64} uma versão única,
%mas sim uma "denominação" das variantes e evoluções da arquitetura \myref{sig}{arm} com suporte a 64bit.As arquiteturas passaram a ser denominadas dessa forma a partir da armv8,
%entretanto existem versões do \myref{sig}{arm},como o armv7l, que consegue trabalhar com instruções de 64bit,apesar de ser uma arquitetura 32 bits.\newline
Foi criado um programa para a geração de dados baseado na biblioteca faker implementada na linguagem Python. Estes dados são gerados para cada país, em idiomas e caracteres compatíveis com a região escolhida. O que permite que estes dados como, nome, telefone, endereço e até mesmo usuário e senha sejam possíveis. Essa forma de inserção foi escolhida, pois um preenchimento de dados totalmente randômico, e de tamanho fixo, pode apresentar discrepância em relação ao desempenho num ambiente real de uso, afetando tanto o tempo, quanto a carga dos processadores de forma negativa. Os dados utilizados em cada ciclo de teste foram exatamente os mesmos, simulando o uso em ambiente real. Desta forma o benchmark se torna melhor aplicável à realidade e de fácil comparação de desempenho que outros algoritmos encontrados.\newline

\ch{fundamentação teórica}

\sec{virtualização}
Virtualização é uma técnica usada para simular um computador dentro de outro. Dependendo do método utilizado, ele pode simular apenas uma camada, ou mais de uma das camadas de hardware e software de um computador. Um sistema virtualizado pode receber vários nomes de acordo com o método utilizado para virtualizar. Alguns dos mais utilizados atualmente são máquinas virtuais e containers docker. A principal diferença deles é a camada de hardware na qual ele é executado.

\sec{maquina virtual}
Uma máquina virtual é rodada por um programa dentro de um sistema operacional. Máquinas virtuais possuem várias limitações, dentre elas, um menor desempenho de processamento, além de não permitir acesso a outros hardwares do computador. Majoritariamente neste tipo de virtualização é permitido o acesso direto à memória principal, dispositivos de armazenamento de dados e hardwares plug’n’play como dispositivos de entrada e saída USB. Entretanto, não é possível utilizar placas de vídeo ou outros hardwares PCI de forma eficiente.


\sec{arquiteturas}
Por definição, arquitetura de computador é um conjunto de circuitos eletrônicos padronizados, associados a um conjunto de instruções, de forma a simplificar a programação para que executem comandos diferentes do binário. Os compiladores utilizam esses conjuntos de instrução para que o código de uma linguagem de programação de alto nível seja convertido para uma de baixo nível. A arquitetura também define e limita várias propriedades do hardware, como quantidade máxima de RAM, de armazenamento, suporte de saída de vídeo, capacidades de rede, etc.\newline

%Uma micro arquitetura é quando adiciona-se tanto um circuito eletrônico novo ao circuito original da arquitetura quanto apenas uma simplificação ou reorganização dos comandos originais de uma arquitetura,
%entretanto, em uma micro arquitetura essas modificações são muito pequenas de forma a serem mais similares a arquitetura original do que uma nova arquitetura.
%Dessa forma as micro arquiteturas podem ser consideradas updates de uma arquitetura e quando são acumulados muitos desses updates, pode ser que seja gerada uma nova arquitetura,
%como foi o caso da arquitetura \myref{sig}{x86} para a arquitetura \myref{sig}{x64}, onde nesta última foi um upgrade grande o bastante da \myref{sig}{x86} a ponto de ser considerado uma nova arquitetura.
%A principal e mais visível diferença entre esses dois é a mudança de 32bit(na \myref{sig}{x86}) para 64bit(no \myref{sig}{x64}).\newline

As arquiteturas também podem ser definidas além da CPU. O que inclui a GPU, TPU e vários outros módulos de hardware de um computador. Inclusive existem arquiteturas especiais que são aplicadas em nível de software. Estas não são necessariamente arquiteturas de computador, mas sim um tipo diferente de arquitetura, que existe em máquinas abstratas que simplificam a programação de uma linguagem para que ela funcione com maior compatibilidade em várias máquinas de arquiteturas de hardware diferentes. Portanto, se faz necessário otimizações na parte do código, e da máquina virtual, como o caso da \myref{sig}{JVM} da linguagem Java.\newline

As arquiteturas não são limitadas apenas a esses previamente citados, elas também podem estar presentes em todos os tipos de circuitos integrados.
Como por exemplo os processadores de roteadores e aparelhos \myref{sig}{IOT}, tais como lâmpadas e tomadas inteligentes.
Isso quer dizer que uma arquitetura não necessariamente é algo que precise de um hardware potente ou que só funcione ou exista em computadores, mas sim a forma como os algoritmos são interpretados no hardware,sendo eles algoritmos como softwares de computador ou como sequências de instruções realizadas por alguém.
Sendo assim, desde que exista um software e um hardware que se comuniquem, existe uma arquitetura e provavelmente houve uma conversão da linguagem de programação para a linguagem de máquina dessa arquitetura neste dispositivo.\newline


--verificar--
As arquiteturas de computador são por si só hardwares específicos para rodar algorítimos, mas os softwares não necessariamente precisam de ser funcionais apenas em uma única arquitetura, por mais que ela seja diferente de outra.
Isso é devido pelo fato dos conjuntos de instruções poderem ser diferentes mas suas funcionalidades gerais podem ser iguais. Mesmo que uma arquitetura seja totalmente diferente entre si, as instruções chamadas para a execução de uma funcionalidade podem existir em outra arquitetura,sendo assim o software de uma arquitetura pode rodar em outra por mais que sejam necessárias algumas adaptações.
Algumas dessas adaptações podem ser tão grandes que às vezes é muito complexo essa adaptação de código. Para esses casos, ou mesmo para testar o código de uma arquitetura em outra,
sem a necessidade dessa adaptação são usados programas chamados de emuladores ou simuladores.
Estes programas funcionam como uma camada de compatibilidade entre a arquitetura real da máquina que está rodando e a arquitetura na qual o programa foi projetado para funcionar.
Entretanto esse processo pode acarretar em uma perda considerável de desempenho, podendo resultar em casos onde máquinas com  516 gigaflops sejam necessárias para se emular máquinas com 230 gigaflops,
como no caso de um emulador do sistema de console Playstation 3 utilizando o emulador rpcs3, e mesmo com essa ineficiência, esse emulador não tem 100\% de compatibilidade com os softwares existentes na plataforma,isso pois a arquitetura do playstation 3 é muito diferente e complexa de se adaptar para a arquitetura amd64.
isso resulta em nem todos os softwares dessa plataforma funcionam exatamente como deveriam, ou mesmo impedindo que funcionem. Por mais que ambas as máquinas executem o mesmo kernel de sistema,visto que é possivel rodar o rpcs3 em sistemas linux e o sistema operacional do playstation 3 é basedo em kernel linux , ainda sim haverá perda de desempenho muito grande pois apesar de,em teoria, serem o mesmo kernel,que deveria facilitar essa comunicação, a diferença de arquiteturas possui um peso muito maior do que o kernel utilizado.\newline

Esse é um exemplo de como mesmo com tudo para ser um cenário igual de utilização ou mesmo um cenário melhor ao se trocar uma arquitetura de um computador inúmeras adaptações devem ser feitas ou,como no caso do macos,
criadas camadas de compatibilidade.Após o lançamento dos macbooks de 2020 com processador M1 ,que funcionam com a arquitetura \myref{sig}{aarch64},
a apple lançou uma camada de compatibilidade dos softwares com arquitetura \myref{sig}{x64} para \myref{sig}{aarch64} chamado de rosetta2 esse software funciona parcialmente como um emulador,
exceto que ele faz as adaptações num nível mais próximo do da máquina real e do sistema operacional nativo da máquina,resultando num desempenho muito superior a qualquer emulador existente,
o rosetta2 funciona de forma análoga ao projeto \myref{sig}{WINE} do Linux que reinterpreta os programas windows para funcionarem no Linux,você tem uma pequena perda de desempenho por esse processo de reinterpretação em alguns casos,
mas em outros essa perda é bem mais visível,e até mesmo,em raros casos,pode até mesmo ocorrer um ganho de desempenho.\newline

As arquiteturas de computador podem variar em diversos fatores de uma para outra de forma que existam varias funcionalidades que não foram pensadas para uma arquitetura que existem em outras.
existem também propósitos diferentes para diferentes arquiteturas,como o caso dos processadores \myref{sig}{arm} que foram pensados para entregar uma grande eficiência energética,
enquanto os processadores \myref{sig}{x86} foram pensados para apresentarem grande poder de processamento.\newline

O principal propósito da arquitetura \myref{sig}{arm} entretanto não é se diferenciar tanto da arquitetura \myref{sig}{x86}, mas sim tornar os computadores mais energeticamente eficientes,
tanto que um computador doméstico comum utiliza de 200 a 300w por hora enquanto um computador raspberry pi 4, que é o computador \myref{sig}{arm} mais potente atualmente da marca mais popular dentre os SBC,
consome em torno de 15w hora. É uma grande diferença, principalmente levando em conta que ambos tem a capacidade de utilizar os mesmos programas de trabalho,
se considerarmos sistema operacional Linux e programas open source, tanto editores de texto, navegadores de internet quanto \myref{sig}{IDE}s de programação que estão disponíveis para ambos e para um uso comum funcionam tão bem quanto em um cenário real.\newline

Como os processadores \myref{sig}{arm} começaram a ficar mais comuns, visto que algumas fabricantes como a Apple e Gigabyte agora oferecem computadores e servidores baseados nessa arquitetura,
faz com que seja cada vez mais fácil de se utilizar tal arquitetura por existirem mais consumidores e consequentemente uma oferta maior de programas feitos para serem executados nessa arquitetura.
Visto o quanto um computador com processador \myref{sig}{arm} economiza energia para entregar o mesmo poder de processamento de um outro com processador \myref{sig}{x86},
essa diferença pode ser muito benéfica para os vários tipos de empresas que utilizam servidores, já que isso pode significar um impacto considerável no consumo energético da empresa dependendo do quanto ele é utilizado a nível de processamento.\newline
--verificar--


\sec{bancos de dados}
Banco de dados é um método de armazenamento de dados de forma estruturada para que as informações sejam associadas e consultadas com mais rapidez. Podem também, ser armazenadas de forma a economizar espaço de armazenamento, dependendo da otimização do banco de dados, além da possibilidade de realizar redundâncias de segurança dos dados.\newline
A partir dessas características, justifica-se a escolha dos bancos de dados como alvo do benchmark realizado para essa comparação de arquiteturas.\newline
Sistemas de computadores, dos mais diversos tipos, utilizam banco de dados para armazenamento de suas informações. Dessa forma, as informações ficam estruturadas em um formato padrão, o que permite acesso rápido a elas. Os tipos de bancos de dados analisados são sistemas SQL relacional (os mais genéricos), de forma que podem ser utilizados no máximo de aplicações diferentes possíveis. Isso faz com que esses tipos de sistema sejam os melhores para ser simulados.\newline


\sec{docker}
Docker é um sistema de virtualização de máquinas que busca simplicidade no gerenciamento e entrega de desempenho do hardware real da máquina que está sendo usada. O docker executa as chamadas de seus ambientes virtualizados, nomeados de contêineres, no mesmo nível do sistema operacional, logo acima do kernel do sistema. Isso possibilita dedicar parte do hardware da máquina real para um contêiner. E permite, dentre outras possibilidades, reservar de forma fixa porções do hardware, como por exemplo, definir limite de memória RAM ou quantidade de núcleos de cpu usados.\newline
Outra das funcionalidades do docker é a implementação de volumes. Que é a forma de isolar as pastas do contêiner, e mantê-las mesmo havendo a necessidade do contêiner ser reinstalado para realizar atualização.\newline
O docker foi desenvolvido a pedido da Google utilizando a linguagem Go, desenvolvida pela própria empresa. Ele foi criado visando a simplificação da gerência dos clusters de processamento da Google, que utilizam dezenas de computadores mais fracos para fazer o processamento. Portanto tem custo menor para compor um ambiente de processamento tão potente quanto fosse adquirida várias máquinas de maior valor. O docker também facilita a manutenção devido à fácil reimplementação de um contêiner caso a máquina tenha algum problema.\cite{dockerdoc}

\subsec{contêiner docker}
Um container docker executa em um nível logo acima do kernel. O que permite que qualquer dispositivo, ou dado disponível na máquina real do usuário, possa ser acessível por um container docker. Além disso, ele possui maior eficiência de uso de memória RAM e de CPU em comparação às máquinas virtuais ou outros métodos de virtualização.\newline
Os containers docker são imaginados para isolar programas do sistema operacional da máquina real. Isso evita que algum problema ocorra com o programa e afete a máquina real do usuário. Em muitas situações são utilizados como sistemas de desenvolvimento virtualizados, facilitando a replicação, e correção dos problemas durante a criação de um programa.\newline
Containers docker também costumam ter implementação mais simples e rápida do que máquinas virtuais. Visto que eles utilizam imagens docker para sua criação, que são geradas, ou a partir de arquivos dockerfile ou a partir de um repositório.\newline


\subsec{dockerfile}
Os arquivos dockerfile são mais leves de transportar, mas demoram mais para serem instalados. Uma imagem instalada dessa forma segue todos os parâmetros de criação de um script de instalação. Sendo assim, caso algum programa tenha sido especificado para ser compilado durante a instalação de  uma imagem, o mesmo será compilado todas as vezes que esta imagem for instalada. Os arquivos dockerfile também facilitam a modificação de uma imagem caso seja necessário.\newline

\subsec{imagem docker}
Uma imagem docker é gerada a partir de um arquivo dockerfile. E a principal diferença é que uma imagem docker,  após feito o download, é extraída na máquina onde o contêiner docker será executado. Uma imagem é composta de snapshots que correspondem às etapas de execução de uma dockerfile. Sendo assim, quando o download é realizado, apenas as partes diferentes de uma dockerfile previamente adquirida é baixada. O que facilita a atualização de contêineres.\newline
As imagens docker são distribuídas de duas formas: a partir de repositórios semelhantes aos dos sistemas Linux ou a partir de arquivos compactados. Os repositórios são o método mais utilizado para se distribuir essas imagens. O principal repositório é o Dockerhub, que é o repositório oficial do docker.\newline



\sec{docker-compose}
É um método de implementação de contêineres docker, que utiliza um arquivo de deploy para facilitar sua replicação,comumente utilizado junto de um arquivo de variáveis de ambiente .env. Esse arquivo contém variáveis para serem utilizadas no deploy do stack de contêineres. Fazendo com que o mesmo arquivo docker-compose possa ser utilizado em mais de um ambiente ou em máquinas diferentes.\cite{dockercomposedoc}\newline


\sec{elasticsearch monitoring stack}
É um conhecido método open-source de monitoramento de logs. Ele se baseia em três programas: Elasticsearch (indexador e processador de logs), Logstash (receptor e monitorador de logs) e Kibana (interface web para monitorar e trabalhar a exibição dos dados coletados). Por isso é conhecido como ELK. Esses programas são baseados em Java e consomem uma quantidade considerável de memória RAM. Motivo pelo qual o programa foi executado em uma máquina dedicada, para não influenciar na análise de desempenho das arquiteturas monitoradas.\newline
O ELK foi utilizado sem qualquer um dos seus plugins de processamento de informações. Fazendo uso apenas do elasticsearch para filtrar os resultados encontrados, e gerar os gráficos exibidos neste trabalho a partir de uma aplicação que utiliza seus dados.\newline

\sec{portainer}
Portainer é um painel de administração do docker, com o objetivo de simplificar a administração e configuração de várias opções mais complexas do docker. Inclusive facilitando a definição de uso do hardware que será usado por cada contêiner, e facilitando o backup e download dos volumes e imagens criados. Assim como a atualização dos mesmos para versões mais novas.\newline
O portainer permite controlar, a partir de diversos métodos, múltiplas máquinas executando docker, com um controle unificado e simples. Além disso, a interface web permite também a execução de comandos shell e a atualização dos contêineres de forma simplificada.\newline
Outra característica interessante é a possibilidade de unificar a administração dos diversos servidores utilizados durante o desenvolvimento e testes, sendo necessário apenas instalar o portainer em um deles, e nas outras máquinas apenas a ativação da conexão remota pelo docker socket. Desta forma o monitoramento de logs, uso de hardware e outros podem ser feitos diretamente pelo navegador.\cite{portainer}\newline


%\section{biblioteca faker}
%\label{sec:biblioteca faker}
\sec{biblioteca faker}
A biblioteca faker é conhecida para a geração de mock data, que são dados gerados aleatoriamente para testar a capacidade de um algoritmo em lidar com dados. Comumente utilizada na etapa de testes de um algoritmo, (seja para testes de segurança, para se proteger de bots de criação de contas ou algo semelhante). É também utilizado para testes de estresse, quanto para qualquer tipo de teste que dependa de dados reais.\newline
Essa biblioteca foi selecionada, pois é de fácil utilização e compreensão, e possui documentação abrangente e suporte para múltiplos idiomas.\newline
Apesar da biblioteca suportar todos os tipos de geração mais completos na localização dos EUA, possui um tipo que corresponde a todo um perfil de usuário, contendo desde endereço até força de senha.\newline
Para propósitos de testes, foram gerados apenas dados na localização do Brasil.\cite{faker}\newline

%\section{biblioteca psutil}
%\label{sec:biblioteca psutil}
\sec{biblioteca psutil}
O PSutil (Python System and Process Utilities) é uma biblioteca multiplataforma para recuperação de informações na execução de processos, e utilização do sistema (CPU, memória, discos, redes, sensores). É muito útil para sistemas de monitoramento, limitação de recursos de processamento, perfil e gerenciamento de processos em execução. Implementa também, funcionalidades oferecidas por linhas de comando, e de sistemas baseados em UNIX tais como: ps, top, lsof, netstat, ifconfig, who, df, kill, free, dentre outros.\cite{psutil}\newline

%\chapter{Trabalhos Relacionados}
%\label{ch: trabalhos relacionados}
\ch{Trabalhos Relacionados}

\sec{A Comparison of Database Performance of MariaDB and MySQL with OLTP Workload}
Foram utilizados vários tipos de bancos de dados além do Postgres e do MariaDB para a comparação de performance, sendo o foco principal entre MariaDB e MySQL. Foram monitorados CPU e memória RAM, e durante os testes foi usado um hypervisor chamado XEN nas máquinas com plataforma amd64 XEN, e 4 GB de memória RAM. A mesma estrutura de BD foi utilizada em todos os servidores.\newline
MariaDB e MySQL foram muito próximos em relação ao desempenho no 1º teste, e no 2º teste MariaDB foi ligeiramente mais pesado em relação a CPU que MySQL, conforme mostrado nos gráficos abaixo.\cite{MariaDBMySQLOLTP}\newline
\imagempng{valores encontrados oltp mariadb}{artigos relacionados/oltp mariadb.png}{valores encontrados para o container mariadb para o 1 teste no artigo citado}
\imagempng{valores encontrados oltp mysql}{artigos relacionados/oltp mysql.png}{valores encontrados para o container mysql para o 1 teste no artigo citado}
\newline\newline

\sec{Automatisation de Docker Swarm sur SoCs ARM avec support MPI et Analyse des Performances}
O artigo aborda uma análise de desempenho de docker swarm em soc arm onde foi usado MPI como base para os aplicativos. O sistema base dos contêineres é o Alpine Linux e foi utilizado em um ambiente onde uma ferramenta externa configura o ambiente MPI para processamento. Dessa forma foi possível automatizar a implementação e monitoramento do docker swarm.\newline
Uma das ferramentas utilizadas é o processo de escaneamento das conexões ativas, usando o netstat para simular o monitoramento do swarm de forma externa ao docker. O método usado para experimentar a plataforma virtualizada foi o WRF, que é um método de previsão do tempo.\newline
Para o ambiente de testes foram utilizados mini computadores Raspberry Pi versões 2 e 3, Nano Pi Neo, NTCP chip e Banana Pi. O ganho de desempenho de execução entre múltiplos núcleos é maior que o ganho de desempenho de múltiplas máquinas, segundo os autores do artigo. A porcentagem de ganho entre usar todos os núcleos do Raspberry é de 71\%. Mas ao usar processamento dentro do swarm, a aceleração é de 17\% de 1 a 2 máquinas e de 2\% de 2 a 3 máquinas. De acordo com o autor, isso ocorre devido a baixa velocidade de comunicação entre os Raspberry Pi 3. Isto é, devido ao próprio soc dele.\newline
Levando em conta o custo, para essa aplicação o uso de soc é viável, já que o WRF consegue apresentar resultados básicos diariamente ou até mesmo em intervalos de uma hora.\newline
O desempenho multi-core de apenas uma máquina é quase o mesmo que o de duas máquinas com multi-core em paralelo\cite{DockerSwarmsocmpi}


\sec{a comparative study of the effects of parallelization  on arm and intel based platforms}
Este artigo utiliza a mesma proposta abordada nesta pesquisa, cada vez mais máquinas arm são utilizadas ao redor do mundo,tendo em vista que hoje em dia todos celulares utilizam processadores \myref{sig}{arm} e os computadores estão começando a adotar essa arquitetura. O artigo aborda os múltiplos métodos de paralelização que são utilizados pelo autor  para realizar os testes, assim como as diferenças das implementações entre intel e arm. No processador arm é impossível usar a GPU para os testes, devido ao sistema operacional usado não ter drivers que possibilitasse esse uso.\newline
Como métricas de monitoramento, utiliza-se o total de frames por segundo(fps), visto que os algoritmos utilizados, são algoritmos de processamento de imagem e potência em joule (J) utilizada pelas máquinas analisadas. O monitoramento de fps era feito por um monitor interno ao cpu e não um sistema externo, e várias das aplicações foram otimizadas para que funcionassem da melhor forma possível em cada cpu, de forma que na otimização interferisse o mínimo possível nos resultados dos testes. Essas otimizações foram feitas em forma de kernels compilados diferentemente para o algoritmo.\newline
A partir das métricas coletadas, o autor calculou aproximadamente o total de energia gasta para processar cada frame, ou seja, o total de energia gasto pela função do código no método serial, que é o único exatamente igual em ambos. Existe uma diferença sutil, mas com maior eficiência energética por parte do processador \myref{sig}{arm}, visto que após ser levado em conta o consumo e a quantidade de frames gerados, é aplicada uma fórmula para comprovar a eficiência energética dos dispositivos utilizados.\newline
Usando um dos vários kernels diferentes, existe uma velocidade de processamento exponencialmente maior por parte da Intel que por parte do \myref{sig}{arm} no melhor cenário. No pior, a velocidade por parte da intel é 10 vezes maior que do \myref{sig}{arm}.\newline
O resultado é que o fps/J é maior no intel que no arm nos melhores casos de cada kernel. Mas essa diferença sutil em um dos kernels, e  alta em outro, chegando a cerca de 8.5 vezes mais eficiência no amd em relação ao arm no mesmo teste (no pior caso de cada). Portanto concluímos que para um dos testes, (teste SRAD), o ultrabook amd utilizado é claramente superior, enquanto que no outro teste, o ultrabook se mostrou superior. \newline
Entretanto o consumo energético do arm é 20\% menor no pior cenário, e no melhor é 60\% superior. O consumo de energia médio do \myref{sig}{arm} é 50\% do consumo do \myref{sig}{amd64}.\cite{armvsintel}\newline
Como conclusão sobre os valores apresentados, foi possível comprovar que no tempo presente, 8 anos depois, as placas \myref{sig}{arm} existentes consomem o mesmo tanto de energia, mas possuem muito mais poder computacional. Enquanto que os computadores \myref{sig}{amd64} portáteis, como o ultrabook utilizado, apesar de também consumirem uma quantidade equivalente de energia, não teve um ganho de performance tão grande quanto os computadores arm.\newline


\sec{KVM, Xen and Docker: a performance analysis for ARM based NFV and Cloud computing }
Os testes de desempenho são feitos com softwares que simulam o uso de servidor, e são algoritmos de benchmark.\newline
Trata-se de um estudo comparativo utilizando benchmarks sintéticos para encontrar um sistema de virtualização, com melhor performance para a virtualização de funções de rede para a arquitetura arm.\newline
Neste estudo foram utilizados KVM, xen e Docker. Todos métodos de virtualização conceituados nos servidores comerciais com o propósito de provar qual deles funciona melhor para entregar maior poder bruto de performance, enquanto mantém os aspectos de segurança necessários de um ambiente de mundo real.\newline
Este estudo aborda as diferenças entre containers e hypervisors, que se baseiam principalmente em os containers utilizarem os recursos diretamente do kernel da máquina física, enquanto os hypervisors buscam virtualizar tudo e simular um hardware em cada aplicação virtualizada. Cada uma tem suas vantagens que são abordadas neste artigo. As principais vantagens são que no container o acesso a poder computacional bruto é maior, e  nos hypervisors as camadas de segurança são maiores.\newline
Dentre os dados encontrados, vale ressaltar que o docker apresentou em média um resultado inferior quando comparado a velocidade de leitura e escrita em relação aos  outros métodos de virtualização. Apesar dessa diferença ser bem pequena numa aplicação de mundo real onde a diferença não chega a 100 bps na maioria dos casos.\newline
Outro ponto a se destacar é que na velocidade de transferência de rede, o docker apresentou em testes de transferência de rede valores mais lentos quando utilizados pacotes de poucos bytes ,onde para pacotes de até 4 bytes por pacote os valores eram em média iguais, mas para pacotes de 8 a 32 bytes as diferenças de velocidade eram consideravelmente maiores, onde o docker chega a ser cerca de 20 mbps mais lento que os outros métodos. Para pacotes maiores que isso, todos os métodos utilizam ao máximo a capacidade de transferência de rede do hardware utilizado,(100 mbps).\newline
Em conclusão, a autora disse que o kvm é mais simples de se portar para o arm em comparação ao xen, já que o QEMU no qual o kvm se baseia, existe em todas as arquiteturas, e o docker também já existe nativamente para o arm.  As leituras de disco e rede funcionam melhor nos hypervisors devido aos métodos de cache que ele possui e o docker não. Foi possível perceber também que para pacotes grandes, as velocidades de todos os métodos comparados são iguais ou maiores que a implementação nativa em todos os testes de performance. A diferença entre eles é bem pequena, e varia de acordo com o teste, sendo assim o ideal seria uma solução mista onde seria utilizado um dentro do outro para melhorar a escalabilidade e segurança, além de outros fatores dos ambientes reais.\cite{KVMXenDocker}

\sec{The Raspberry Pi: A Platform for Replicable Performance Benchmarks?}
As vantagens do uso do raspberry pi para benchmark, incluem sua facilidade de replicação usando ssh e raspbian. E mostra as diferenças de resultados entre os diferentes Raspberry pis usados nos testes. Os dados mostram que os resultados são bem aproximados, mas não são os mesmos resultados.\newline
Os raspberry pi usados foram o modelo 3. Eles foram comprados do mesmo vendedor com um intervalo de 2 semanas, para se provar que o dispositivo poderia ser de fácil replicação. Adicionalmente, foi comprado um terceiro raspberry pi de outro vendedor com um intervalo de diferença de alguns meses entre este e os 2 anteriores. Isso para comprovar que lotes de fabricação diferentes não influenciam a replicabilidade do dispositivo. Foi utilizada uma imagem de instalação padronizada, modificada pelos autores, usando como base o sistema operacional oficial da época: o Raspbian Isso para manter uma diferença zero em relação aos softwares usados, e a única existente sendo apenas no hardware usado. Os cartões de memória utilizados nos computadores, também possuíam o mesmo tamanho, mas não foram dados maiores detalhes sobre eles.\newline
Um dos testes demandava bastante uso de espaço de disco, sendo assim, foi necessário adicionar mais memória externa por meio de um HD externo.
O autor chegou à conclusão que o raspberry pi é uma boa plataforma para replicabilidade, principalmente se utilizado o docker para padronizar o ambiente de replicação. O autor concluiu ainda que versões posteriores do raspberry pi poderiam melhorar ainda mais esse cenário, devido às melhorias de hardware que ocorreriam.
\cite{rpiplatformreplicable}\newline
Cerca de 4 anos após a conclusão deste trabalho, foi lançada uma versão nova e exponencialmente mais útil, em termos de testes replicáveis, pois não há limitação às placas de 1 gb de RAM . E a baixas velocidades de transferência, tanto de disco quanto de rede.  A partir disso, as conclusões do autor  se comprovaram pouco tempo antes dessa versão ser lançada. E a tendência é de que continue lançando versões superiores,visto que após lançarem versões com 2gb e 4gb de ram a Raspberry pi foundation lançou mais uma versão de 8gb de ram, e posteriormente uma versão oficial do seu sistema operacional oficial, agora chamado de Raspberry pi OS,com suporte a instruções 64 bits. Essas melhorias ocorreram apenas em uma nova revisão da placa, as futuras evoluções tendem a ser ainda maiores levando em conta as evoluções que têm ocorrido nas revisões da arquitetura \myref{sig}{arm}.\newline

\sec{HS06 Benchmark for an ARM Server}
Se resume em um benchmark e análise de um servidor de arquitetura arm. Esse servidor possui 12 slots para encaixes das placas de soc, cada placa de soc possui 4 cpus com 4 núcleos, um pente de RAM,4 portas sata e um conector de porta 10 GBE para cada cpu. Resultando em 16 núcleos, 4 pentes e 16 portas sata por placa soc. Cada servidor consome cerca de 300w de energia, entretanto apenas um \myref{sig}{SOC} foi utilizado para os testes. \newline
Foram utilizados para essa comparação mais 5 servidores AMD64, sendo 1 hp, 3 IBM e 1 dell.\newline
O consumo energético desse servidor entre os analisados é o menor , o mais potente em relação ao consumo energético,visto que de acordo com a tabela de resultados apresentada no texto o único que conseguiu mais que 1 ponto por watt gasto foi o computador arm.\cite{hs06}\newline
Importante ressaltar que os resultados encontrados na máquina arm são inferiores em pontuação, em comparação com todos os outros servidores utilizados, mas ao mesmo tempo o consumo energético desse processador é exponencialmente menor que os outros servidores. Principalmente ao se levar em conta que ele consome cerca de 5w de energia, enquanto que os outros consomem entre 150w e 600w.\newline

%\chapter{testes}
%\label{ch: testes}
\ch{testes}
Os testes foram realizados utilizando um Orange Pi PC + \cite{opipc} e um notebook lenovo. O Orange Pi é um \myref{sig}{SBC} \myref{sig}{arm} baseado no processador allwinner h3 \cite{h3} com 3 USB 2.0 ,1GB de memória RAM DDR3, uma porta de rede 10/100 e wi-fi 4. Essa configuração é relativamente datada e seu processador é um 4-core de 1.3GHz no clock máximo. É um processador que ainda possui desempenho positivo se considerar um uso básico, entretanto considerando todas suas especificações, este \myref{sig}{SBC} não é bom o bastante para substituir um computador atual,devido a sua limitação de memória RAM e de capacidade gráfica.\newline

O notebook é um Lenovo G405 \cite{G405}, com um processador AMD E1-2100 \cite{E1}, (dual-core com clock máximo de 1.0GHz), 2 GB de memória RAM DDR3, 1 USB 2.0, 2 USB 3.0, porta de rede Gigabit e 2 portas sata3. Porém nem as portas sata nem as usb 3.0 serão usadas já que o propósito é manter as 2 máquinas o mais próximas em relação ao hardware possível. Para que haja proximidade em velocidade e especificações. Este computador também possui especificações técnicas obsoletas para os dias atuais, mas ainda é utilizável como um servidor doméstico.\newline

Considerando as velocidades de armazenamento disponíveis para as máquinas utilizadas, o Orange Pi teve o seu SO armazenado na sua memória interna emmc. E no computador amd num HD 2.5“ sata 3 de 500GB. A memória onde o sistema operacional do Orange Pi está armazenada está longe de ser rápida, mas como a velocidade deste disco de armazenamento apenas afeta o tempo de inicialização do sistema operacional da máquina host e não dos containers,sendo assim foi considerado como equivalente.\newline

Alguns métodos que serão utilizados para manter as máquinas com equivalência serão limitar o clock de ambos para que se mantenham o mais próximos possível. No Orange Pi foi definido para um clock máximo de 1GHz, esse sendo um valor para facilitar os cálculos de equivalência, (já que é o mesmo clock máximo do lenovo). Sendo assim é uma comparação direta e não uma comparação em escala. A memória usada será limitada a 1024 MB para o stack do docker, pois é a memória máxima do Orange Pi.\newline

Considerando as velocidades de armazenamento disponíveis para as máquinas utilizadas, o Orange Pi teve o seu SO armazenado na sua memória interna emmc. E no computador amd num HD 2.5“ sata 3 de 500GB. A memória onde o sistema operacional do Orange Pi está armazenada está longe de ser rápida, mas como a velocidade deste disco de armazenamento apenas afeta o tempo de inicialização do sistema operacional da máquina host e não dos containers,sendo assim foi considerado como equivalente.\newline

Alguns métodos que serão utilizados para manter as máquinas com equivalência serão limitar o clock de ambos para que se mantenham o mais próximos possível. No Orange Pi foi definido para um clock máximo de 1GHz, esse sendo um valor para facilitar os cálculos de equivalência, (já que é o mesmo clock máximo do lenovo). Sendo assim é uma comparação direta e não uma comparação em escala. A memória usada será limitada a 1024 MB para o stack do docker, pois é a memória máxima do Orange Pi.\newline

Para o armazenamento do docker nas 2 máquinas ele foi movido para um pendrive sandisk cruzer blade 2.0 de 16GB, ambos comprados simultaneamente do mesmo vendedor.\newline

Além disso, os softwares utilizados nessas máquinas foram versões do sistema debian, no Orange pi foi o armbian e no notebook o próprio debian netinstall, ambos na versão Buster. A versão do docker usado em ambos, é a versão community edition 20.10.12. E a versão do docker-compose é a versão 2.2.3. Essas sendo as versões mais atuais no início da execução dos testes.Todos os outros softwares instalados diretamente na máquina, são irrelevantes para o propósito dos testes realizados. E os demais serão descritos em \myref{sec}{contêineres docker}.



%\section{testes de tempo}
%\label{sec:testes de tempo}
\sec{testes de tempo}
os algorítimos principais do código são a geração do sqlite e a inserção nos BDs finais,sendo assim ambos foram testados de formas diferentes e de métodos diferentes,que serão descritos a seguir.
o algorítimo de geração de banco de dados é muito impactado pela quantidade de núcleos de cpu da maquina na qual foi rodada,mais do que a arquitetura ou clock dela,
enquanto na inserção do banco de dados as especificações do computador não pareceram interferir tanto quanto a aleatoriedade da consistência do funcionamento das threads,
essa inconsistência acabou fazendo com que os testes tivessem que ser realizados sob supervisão,sendo muitas vezes necessário interromper uma etapa e depois reiniciá-la ,
também por isso varias das operações foram testadas de formas diferentes.\newline
foram utilizadas sempre 2 etapas de testes ,primeiro um teste generalizado de funcionalidade com valores pequenos e outro para comprovar eficacia com valores variáveis,
esses valores alteram varias coisas,mas principalmente quantidade de elementos gerados,isso para saber se a quantidade de elementos afeta a velocidade das operações.

%\subsection{teste de tempo de criação do bd}
%\label{subsec:teste de tempo de criação do bd}
\subsec{teste de tempo de criação do BD}
o teste dessa etapa foi feito para dentre outras coisas comprovar o funcionamento do algorítimo de geração de dados descrito em \myref{subsec}{geradorDeSql} a medida que o desenvolvimento dessa biblioteca acontecia testes de geração tiveram que ser feitos,
esses testes dentre outros propósitos foram usados para saber a eficiência da geração de dados,isso por que os dados gerados levavam uma quantidade parcialmente aleatória para serem gerados,muito devido aos dados gerados serem semi-procedurais,
isso pois eles seguiam uma regar para serem gerados de forma aleatória,isso fez com que fosse necessário essa etapa de testes para saber se os dados gerados no final geravam dados que funcionariam com o propósito esperado,ou seja,
se eram funcionais em um banco de dados sql relacional,seja MariaDB ou postgres.\newline
outra coisa que foi necessária durante o desenvolvimento que fez com que essa etapa de testes tivesse que ser mais bem feita foi a etapa de geração de dados de inserção,
que foi desenvolvida para que apenas dados de inserção válidos fossem possíveis de serem gerados,diferente dos demais dados que apenas são queries de consulta aleatórias.\newline
na etapa principal desse teste foi feito um teste aditivo que testou 30 ciclos com adição de 100 em 100 elementos em cada ciclo. Foram feitos um teste de 4 sub ciclos internos para cada um dos 30 ciclos,
tendo como objetivo o quanto de tempo é gasto em média para casos com muitos ou poucos dados gerados ,
podendo assim gerar um valor de base de valor mínimo gasto obrigatoriamente para cada interação além de gerar bases de dados viáveis para os testes descritos em \myref{subsec}{teste de tempo de operação de inserção no BD}.\newline
Os testes desta etapa foram realizados em um PC arm64 e dois PCS amd64. Os dados resultaram em valores de tempo consistente em relação a diferença de frequências dos computadores.\newline
Sendo assim, se existe um valor de perda entre as arquiteturas para esse teste é um valor irrisório,
sendo que o PC amd64 mais potente apresentou testes cerca de 2 vezes mais rápidos e seu clock é aproximadamente o dobro do arm64.
Esses valores foram dados em relação ao tempo gasto por elemento em cada iteração.
com base nos resultados desses testes des e que o computador tenha vários núcleos o algorítimo será tão eficiente quanto,
isso se deve ao fato que levando em conta o um PC com amd64 com 4 núcleos e 4 threads a um clock de 3.6GHz a 4.0GHz e um outro PC AMD64 de 2 núcleos e 4 threads a um clock de 2.7GHz a 3.5GHz os valores de tempo do PC amd64 mais fraco levou cerca de 97\% do tempo do amd mais potente,isso devido tecnologia intel chamada "Tecnologia Intel® Turbo Boost frequência 2.0" que quando detecta que o coputador precisa de mais potencia aumenta o clock do cpu,em contra partida o processador amd64 mais potente não chegou a sentir tanto impacto deste teste e por isso usou da tecnologia amd chamada "Precision Boost 2" essa tecnologia permite que o processador varie seu clock de acordo com a necessidade tanto aumentando quanto diminuindo ele para economizar energia,dessa forma o clock do processador provavelmente foi diminuido já que apenas 1 dos nucleos do processador estava em carga alta e essa tecnologia leva em conta a porcentagem de todos os nucleos somados para funcionar,essa informação se baseia em testes descritos pela internet,visto que a amd não detalha muito esse processo da sua tecnologia.\newline
também foi realizado um segundo teste referente a esse ,seguindo os mesmos parâmetros,mas utilizando o processamento paralelo
o maior diferencial entre os testes da arquitetura \myref{sig}{arm} e x86 foi que na arquitetura \myref{sig}{arm} devido a limitações dos recursos disponíveis,
foi necessário utilizar um HD ao invés de um ssd e como dito em \myref{sec}{geração de dados} isso impacta consideravelmente na velocidade da geração dos dados.\newline


\subsec{teste de tempo de operação de inserção no BD}
este teste foi proposto para ser um teste de dois tipos,primeiro um teste de operações sem falha,segundo um teste de operações de inserção para bancos de dado mais utilizados para esse propósito:
\begin{itemize}
\item os dados de inserção foram projetados para não dar erro e sempre retornarem o resultado de operação inserida com sucesso,isso quer dizer que,caso nada tenha dado errado,apenas operações sem erro foram realizadas.
\item muitos bancos de dados são usados primariamente para inserção de dados,como bancos de dados de log e de analise de dados,como o próprio \myref{sec}{elasticsearch monitoring stack} utilizado durante os testes,onde operações de busca,listagem e filtragem não são a maioria,sendo assim é um comparativo para esse propósito de teste
\end{itemize}
para esse propósito foi utilizada uma variação do benchmark de criação de BD,foi usada uma inserção fracionada dos dados,o que quer dizer que foram realizadas as operações em grupos de 5000 até completar os 100.000.
para que a maquina onde os testes finais não travasse foi definido um valor mais baixo de subprocessos,sendo 1 para cada núcleo do processador da maquina,onde 3 executavam os testes para o \myref{sig}{arm} e 3 para o amd.


\subsec{teste de tempo de operações variadas no BD}
após a confirmação da funcionalidade de forma satisfatória da geração do sqlite foi iniciado o processo de interação com o banco de dados,
esse processo foi dividido em algumas etapas,primeiramente para verificar se a operação funcionava corretamente,essa etapa foi feita seguindo os testes de funcionalidade já descritos,
onde uma pequena quantidade de operações era gerada,usando a geração de sqlite,em ambos os bancos de dados ao mesmo tempo,após essa etapa de confirmação de funcionalidade não foi feito um teste de desempenho,
pois foi deixado para a etapa de testes paralelos,a qual se mostrou mais importante,visto que após a confirmação de funcionalidade mais testes para essa etapa não eram necessárias.\newline
apenas testes de realização de operações sem retorno,leitura de arquivos,criação de usuários e comunicação geral com o banco de dados foram feitos,
todos esses testes tiveram resultados satisfatórios tornando possíveis as funcionalidades utilizadas da biblioteca \myref{subsec}{gerenciadorDeBD},
os dados gerados foram gerados seguindo o seguinte processo:\newline
foram gerados 50.000 operações de inserção,e posteriormente foram pedidos 5.000.000 operações randômicas,
o que resultou em 50.000 operações de inserção seguidos de 4.950.000 operações randômicas gerados.\newline
o principal propósito desse teste foi de que muitos bancos de dados principalmente de sites de comércio eletrônico e sistemas de gerencia de estoque utilizam muitos tipos variados de operações,como as que foram utilizadas nesse teste,isso faz com que os resultados sejam facilmente aplicáveis para essas situações de mundo real mais cotidianas.
assim como no teste de inserção para que a maquina onde os testes finais não travasse foi definido um valor mais baixo de subprocessos,sendo 1 para cada núcleo do processador da maquina,onde 3 executavam os testes para o \myref{sig}{arm} e 3 para o amd.

%\subsection{teste de tempo de operações paralelas}
%\label{subsec:teste de tempo de operações paralelas}
\subsec{teste de tempo de operações paralelas}
essa foi a parte que demandou mais testes,estudos e desenvolvimento dos testes implementados,visto que alem da programação paralela ser mais complexa que a programação linear,
ela é bem mais difícil de se testar,ela apenas foi possível de testar após as outras classes principais,\myref{subsec}{gerenciadorDeBD} e \myref{subsec}{geradorDeSql}

%\section{testes de eficiencia}
%\label{sec:testes de eficiencia}
\sec{testes de eficiência}
esses testes não apenas levam em conta o tempo que foi gasto para concluir a operação,mas também a forma como elas foram concluídas,
isso quer dizer que o tempo é um parâmetro para a sua avaliação,mas também a quantidade de falhas apresentadas,
quantidade de cpu gasto e quantidade de interação do operador do algorítimo para que ele funcione como deveria

%\subsection{teste de eficiencia de operações paralelas}
%\label{subsec:teste de eficiencia de operações paralelas}
\subsec{teste de eficiência de operações paralelas}
esse foi o teste que mais demandou tempo e esforço dentre os realizados,isso por que devido a complexidade da programação paralela,como já dito em \myref{subsec}{teste de tempo de operações paralelas},
uma atenção e quantidade maior de testes foram demandadas.
um dos grandes motivadores desse tipo de teste foi a etapa de testes descrita em \myref{subsec}{teste de tempo de inserção no BD} apesar de essa etapa não ter sido complicada por si só ela demandou muita atenção pois apresentava muitos erros,
essas operações demandaram muitos testes manuais de modo de programação paralela,
sendo usando threads ou subprocessos,quantidade de operadores paralelos,
quantidade de elementos inseridos,forma dos elementos inseridos.
Tudo isso pois em vários momentos foram apresentados erros randomicamente sem nenhum indicio de justificativa para eles,
os erros apareciam em certos momentos quando era usado o processamento paralelo em threads e em outros utilizando o processamento paralelo de subprocessos,
os mesmos erros eram corrigidos para que em sequencia ao se implementar a próxima funcionalidade necessária o mesmo erro se repetisse,isso gerou um loop do processo de desenvolvimento muito grande,
onde muitos testes eram realizados e alternados com leitura de documentação das bibliotecas utilizadas ou mesmo leitura de exemplos de códigos de fórum e sites.
essa etapa se misturou muito com o desenvolvimento do programa,pois a otimização do código era necessária para que certas partes dele funcionassem,mas também se misturou com as outras etapas de teste,
isso muito por que as outras etapas de teste acabaram por servir como etapas desse mesmo teste.
foi detectado que caso seja usado menos q 2 subprocessos pra cada servidor o algorítimo apresenta algum erro que foi deixado de lado devido a não necessidade do aprofundamento nessa opção de implementação,
sendo assim ao invés de ser usado um subprocesso foi usada a implementação sequencial
além disso foram detectados outros fatores interessantes,primeiro que o postgres apresenta uma demora maior na sua execução caso ocorram operações que não retornam nada,esse tipo de operação constitui a maioria das operações geradas para os testes,
isso devido a única que é garantida de não dar problema é a operação de inserção,alem disso foi detectado que o quadro se inverte nas operações válidas,onde o postgres é bem mais rápido que o MariaDB.
outro fator detectado é que caso seja feita uma implementação sequencial a inserção dos dados será feita mais rapidamente que uma implementação paralela,alem de apresentar menos erros,próximos a zero.




%\chapter{Metodologia}
%\label{ch: materiais e métodos}
\ch{Metodologia}
O desenvolvimento do software foi feito utilizando vários métodos de análise de log com o objetivo de agilizar a depuração,
possibilitando que os dados gerados pudessem ser facilmente conferidos durante o desenvolvimento.\newline
Durante esse capítulo, serão descritos os procedimentos mais importantes das etapas de desenvolvimento e funcionamento do software, com o intuito de proporcionar um entendimento simples.\newline

%\section{bibliotecas criadas}
%\label{sec:bibliotecas criadas}
\sec{bibliotecas criadas}
algumas bibliotecas foram criadas para facilitar o desenvolvimento,delas algumas valem a pena serem mencionadas mais detalhadamente,
mas outras apenas vão ser citadas aqui.
foi criada uma biblioteca para gerenciar a interação com arquivos sqlite,
essa biblioteca trabalha de forma simplificada para o acesso ser mais rápido de se implementar e lidar apenas com comunicação de parâmetros em formato json,
dessa forma quando se é feita uma query o input deve ser um dictionary com as keys sendo os nomes das colunas e os conteúdos os valores buscados,
isso só é válido pois ele só busca valores iguais,
não se preocupa com valores aproximados ou limiares,
isso poderia ter sido implementado,mas não foi visto como necessário para o propósito dos testes propostos.
A outra vantagem é que os retornos das consultas é dado em formato dictionary e quando valores são inseridos apenas são necessários os dictionaries compatíveis com o sqlite.
uma outra dessas bibliotecas foi uma para o tratamento de erros,
essa classe é uma derivação da classe padrão do Python de exceção,
essa biblioteca é composta de 3 classes cada uma para um tipo de mensagem e tratamento de erro,
apenas para simplificar e facilitar o debug do codigo durante a manipulação dele,
ela não faz real diferença em relação ao funcionamento em si,
exceto no fator de poderem ser chamadas correções especificas dos erros quando um try-catch é usado numa função.
ainda foi criada uma biblioteca de timer,usada nos testes de tempo do projeto,
essa biblioteca apenas é uma contração de forma simples e com tratamento de erro do uso da biblioteca time do Python,
essa técnica de medida de tempo é amplamente utilizada,
mas apenas para fins de simplificação no momento do uso foi criada essa biblioteca.

%\subsection{loggingSystem}
%\label{subsec:loggingSystem}
\subsec{loggingSystem}
essa biblioteca é a responsável por toda a gerencia e logs e por todo o monitoramento do \myref{subsec}{monitorContainer},
essa biblioteca basicamente é um complemento da biblioteca padrão de logs do Python \cite{logging},
que tem uma implementação de comunicação com os servidores Logstash,a biblioteca de forma inteligente verifica se os parâmetros de comunicação com o Logstash estão funcionais,
senão automaticamente salva todos os logs em um arquivo .log cujo nome foi informado durante a instancia do objeto da classe,
a classe apenas consegue fazer essa verificação durante sua instancia,caso após isso a conexão seja perdida os logs não são enviados a lugar algum.
as mensagens de erro são gerenciadas de forma simplificada,onde existe um parâmetro que define o formato da mensagem de log e o nome do gerenciador de log,
alem de outros pequenos parâmetros para identificação de onde saiu o log que foi registrado.
existem alguns métodos nessa biblioteca que auxiliam no tratamento do stack overflow,onde esses métodos monitoram de onde saiu a execução do elemento que executou essa função,
como no caso do tratamento de erro do stack overflow na criação de um dado de inserção da classe de criação de banco de dados,
onde caso durante o tratamento de erro que faz com que a classe seja chamada novamente em loop até que consiga retornar um valor válido essa chamada recursiva não gere um esgotamento de memória,
já que caso chegue a um valor máximo de execuções outra exceção é chamada e simplesmente em vez de retornar um valor de inserção é retornado um valor nulo.
alem de saber qual a função que a chamou esse método existe uma outra implementação onde retorna toda a pilha de chamadas do algorítimo,
sendo assim permitindo que um tratamento de erro mais complexo seja possível sem grandes alterações no código.

%\subsection{paralelLib}
%\label{subsec:paralelLib}
\subsec{paralelLib}
essa biblioteca possui 2 implementações diferentes de paralelização,utilizando a classe threading \cite{threading} e a classe multiprocessing \cite{multiprocessing},
a classe threading utiliza threads para a paralelização de execuções,
esse método foi inicialmente utilizado por ser de mais simples implementação e mais simples monitoramento da execução,entretanto devido as limitações de segurança dessa classe foi escolhida uma implementação utilizando a classe multiprocessing,
onde essa classe cria um grupo de subprocessos para o codigo que irão ser responsáveis pela execução do algorítimo selecionado.
ambas as classes implementadas,a derivada de threading e a derivada de multiprocessing foram feitas de formas análogas e de simples substituição em codigo de uma para a outra de acordo com a necessidade,sendo assim funcionam muito parecidas.
ambas funcionam com uma classe de gerencia chamada paralel,no caso de threading sendo paralel_thread e no caso de multiprocessing sendo paralel_subprocess,assim como classes worker com nomes semelhantes,worker_thread e worker_subprocess.
as classes de gerencia funcionam gerando um array de objetos da classe worker,
sendo cada um equivalente a um subprocesso/thread da execução paralela,também existe um array ,que pode ser apenas um elemento,
com as funções que serão executadas no processamento paralelo,
alem disso gera um objeto que contem os elementos que serão processados durante o processamento paralelo,
esses objetos são passados como kwargs das funções que serão executadas,
podem ser aceitas varias funções des de que sigam apenas uma regra,essas funções devem ser exatamente iguais,
mas de objetos instanciados diferentes,como no caso utilizado no algorítimo,onde cada função é de um objeto com uma credencial diferente para a comunicação com o banco de dados,
de forma que não seja executada mais de uma comunicação com uma credencial por vez.
os workers vão ciclando as funções a medida que vão iterando pelo array dos parâmetros.
durante a execução dessas funções vão sendo removidas do objeto contendo os kwargs um por um o kwarg logo antes de ser usado,
dessa forma garantido que uma operação não será feita 2 vezes ,isso é importante visto o propósito desse algorítimo,que é simular a mesma quantidade e operações em bancos de dados diferentes,
se um elemento fosse utilizado mais de uma vez esses valores se alterariam.caso um dos elementos já tenha sido usado e acabe sendo pelo pelo worker,um erro vai ocorrer,
o worker vai ignorar esse elemento e tentará o próximo disponível,caso o numero de elementos seja menor que 1 ele irá então terminar o loop e parar a execução
após o fim da execução de todos os processos paralelos o objeto de gerencia ,se for requisitado,irá retornar os resultados das operações onde o processamento paralelo foi pedido,
para os propósitos deste algorítimo isso não foi necessário nenhuma vez,sendo assim essa funcionalidade está incompleta.
essa biblioteca demandou muito tempo do desenvolvimento devido aos diversos problemas possíveis de acontecerem durante o manuseio de aplicações paralelas,
para lidar com isso foram utilizadas algumas adaptações do funcionamento normal da classe de processamento paralelo nativa do Python,
a principal diferença foi a utilização de varias funções diferentes que ficam ciclando até que as operações desejadas sejam concluídas,
isso acontece pois antes da execução dos subprocessos são inseridos entre dois tipos diferentes de funções,uma função simples ou um array contendo referencias a varias funções diferentes,
entretanto,todas essas funções precisam ser iguais,a única diferença entre elas é o objeto que a contem,pois eles sim podem ser diferentes,
isso foi usado nos testes para que cada função chamada fosse associada a um usuário e senha diferentes para acessar o banco de dados,
isso foi usado pois os bancos de dados usados não aceitam mais de uma operação simultânea para cada usuário,isso faz com que o processamento paralelo fosse impossível,
mas com essa adaptação varias contas diferentes possam ser usadas sem ter que necessariamente recriar o objeto de gerencia do banco de dados a todo momento,
o que demandaria mais tempo e faria com que a velocidade do benchmark fosse impactada.
a outra modificação foi a implementação de um time out para a execução dessas funções,
de forma que as operações mesmo que travem não apresentem problema no benchmark,
isso foi um problema percebido que impactava muito na velocidade do benchmark gerando subprocessos zumbis,
já que uma operação do banco de dados acabava levando mais tempo que o necessário e em algum momento os subprocessos acabavam gerando um problema de travar um ao outro devido a essa demora

%\subsection{monitorContainer}
%\label{subsec:monitorContainer}
\subsec{monitorContainer}
essa biblioteca se baseia na biblioteca \myref{sec}{biblioteca psutil} essa biblioteca utiliza um método não muito seguro chamado eval,
uma função nativa do Python que consegue executar uma função declarada como um string,
sendo assim podendo muito facilmente serem alterados os parâmetros que seriam consultados do hardware onde o contêiner está sendo rodado.
essa biblioteca faz a consulta a partir de um arquivo json que lista as funções da biblioteca psutil que devem ser executadas,
acompanhadas dos parâmetros de entrada e o filtro de retorno que será aplicado,
isso faz com que muito facilmente possam ser pesquisadas apenas as informações realmente necessárias,
simplificando assim o trabalho da analise de logs.
a biblioteca ainda implementa o uso da biblioteca de logs para poder enviar todos os logs de forma automática para o Logstash ou para um arquivo de log local,
como descrito em \myref{subsec}{loggingSystem}

%\subsection{gerenciadosDeBD}
%\label{subsec:gerenciadosDeBD}
\subsec{gerenciadorDeBD}
essa biblioteca é feita para que a gerencia das conexões do banco de dados seja mais fácil,
visto que tem as funções adaptadas para serem iguais para o MariaDB e para o postgres,
alem disso existem tratamentos de erro customizados para todos os erros que foram observados durante a etapa de desenvolvimento,
dessa forma todos os erros q acontecem são tratados de forma similar,
mas como as bibliotecas são diferentes e desenvolvidas por entidades diferentes,
varias das correções de erros e funcionamentos são diferentes,
um exemplo simples disso é q para a biblioteca do postgres para executar um arquivo sql só precisa do arquivo ser aberto e executada a função read,
que retorna o string contido nele,mas na biblioteca do MariaDB tem que ser lido linha a linha e executada linha a linha,
na biblioteca criada foram feitas as adaptações para que independente do banco de dados usado a função de executar um arquivo sql apenas precisa do caminho do arquivo no sistema,ela já abre o arquivo e o executa.
algumas outras coisas são feitas,no postgres por exemplo existe uma função de rollback,
que é usada para desfazer alguma operação quando ela é identificada como acontecendo com erro numa comunicação com o banco de dados,
não existe algo equivalente para o MariaDB,sendo assim a classe criada trata esse erro tentando executar mais 5 vezes a operação,para garantir que não foi algum erro de conexão aberta,
após essas 5 vezes o algorítimo considera q a operação inserida está com problema e a ignora.
essa biblioteca serve principalmente para essa generalização,alem de controlar a inserção,
execução de sql,ainda gerencia consulta,criação de usuário,
ler diretamente o sqlite para realizar as operações escritas lá,dessa forma essa biblioteca simplifica muito a interação com o banco de dados,
essa simplificação chega num ponto que tornou possível a paralelização ,visto que uma adaptação para isso é bastante complexa caso o código não tenha sido pensado nisso des de o começo,
sendo assim o algorítimo sendo modularizado acabou fazendo possível a implementação de forma paralela.
a biblioteca ainda faz com que seja possível consultar o sqlite dos dados gerados diretamente na comunicação com o banco de dados final,
isso faz também com que seja mais econômico de memória RAM o algorítimo,mas faz também com que ele consuma por mais tempo disco e cpu,
mas não necessariamente em maior quantidade,isso faz com que tenha sido necessário um controle mais preciso da quantidade de threads na execução do benchmark,
pois como o cpu é usado por mais tempo isso poderia causar um travamento da maquina que está gerando os testes e uma subsequente inconsistência dos dados de benchmark gerados.

%\subsection{geradorDeSql}
%\label{subsec:geradorDeSql}
\subsec{geradorDeSql}
essa é a classe referida na seção \myref{sec}{geração de dados},todas as informações detalhadas dela estão descritas nessa seção

%\section{software de benchmark}
%\label{sec:software de benchmark}
\sec{software de benchmark}
o benchmark foi feito utilizando um software desenvolvido para o propósito deste teste,
o software de benchmark está mais para um software para gerar estresse na maquina na qual está rodando o banco de dados por meio de varias execuções de comandos direto no banco de dados.
o software de benchmark funciona carregando e construindo os dados a partir das inserções no arquivo sqlite,os testes de estresse foram tentados de algumas formas:\newline
\begin{itemize}
\item primeiramente o algorítimo inicia o contêiner que contém o banco de dados que está sendo analisado
\item após isso é inserindo uma quantidade definida de operações que é lida de forma sequencial do banco de dados inicial
\item após isso são executadas essas operações até que terminem,depois disso o mesmo procedimento é feito para a outra maquina
\item após isso o contêiner com o banco de dados é desligado e o próximo tipo de banco de dados é iniciado nas duas maquinas,e o processo se repete\newline
a outra forma é um pouco mais rápida e eficiente em relação a execução das múltiplas maquinas.
\end{itemize}
Isso se dá pelo fato que o processo de inserção é feito de forma paralela,de forma que as inserções de cada banco de dados em todas as maquinas é feito simultaneamente,
mas também de forma sequencial,o funcionamento é muito parecido com o da anterior,primeiro é criada uma thread para cada maquina,
em cada thread é lido de forma sequencial as operações que serão inseridas,
assim que as operações acabam em qualquer uma das threads o contêiner do banco de dados é parado e aguara a outra thread acabar para poder começar o mesmo procedimento para o outro tipo de banco de dados\newline
a terceira forma é parecida com a segunda,diferente apenas na forma como as operações são executadas,a partir desse método as operações são inseridas de forma paralela,
sendo assim cada thread de cada maquina possui uma quantidade definida de threads filhas,
essas threads filhas executam as operações a partir do que existe numa queue de elementos que quer dizer que uma operação não necessariamente será executada ,
visto que pode depender de uma operação que ainda não foi executada,isso é possível em alguns casos raros,
assim como num ambiente real,onde um funcionário de uma empresa pode editar um elemento ao mesmo tempo que outro edita o mesmo elemento,
em ambientes reais existem tratamentos para que isso não ocorra,
mas no ambiente desses testes,nenhum tratamento para impedir isso foi feito,
exatamente para simbolizar o pior cenário possível para uma aplicação com comunicação com bancos de dados\newline
a ultima forma é uma variante da segunda e terceira formas de operação,
onde são feitos os testes para cada maquina de forma sequencial, mas a execução das operações é paralela,
essa ultima foi pensada para que possam ser testadas alguns ambientes a procura de erros,
não foi pensada necessariamente para o uso no benchmark final\newline
o software de benchmark por si só não é o bastante para analisar o desempenho das arquiteturas,
ele depende do contêiner docker descrito em \myref{sec}{contêineres docker},
esse contêiner modificado possui um método de monitorar de dentro para fora tudo que acontece dentro dele por meio do \myref{sec}{daemon de monitoramento} \newline


%\section{geração de dados}
%\label{sec:geração de dados}
\sec{geração de dados}
os dados foram todos gerados para um sqlite projetado para ser simples de aceitar qualquer formato de dados que pudesse ser gerado para qualquer tabela
Essas etapas funcionam da seguinte forma:\newline
No início, os dados foram gerados em sqlite pelo fato que, caso haja algum problema e o computador, que estava gerando os dados, seja abruptamente desligado,
não se perdem as informações que já foram criadas e salvas no banco de dados. Desta forma, economiza tempo uma vez que esta etapa é a mais demorada da geração de dados,para mais informações sobre o sqlite consulte o \myref{subsec}{sqlite}.\newline
o codigo consegue gerar os dados de 3 formas,apenas a ultima é realmente utilizada.
As outras duas foram feitas para propósito de testes

\begin{itemize}
\item gerar uma quantidade x de dados de uma tabela específica
\item gerar uma quantidade x de cada tipo de dado para cada tabela do banco de dados final
\item gerar uma quantidade aleatória de cada tipo de dado para cada tabela do banco de dados final até atingir o total de operações informadas
\end{itemize}

Todos esses tipos de geração são feitos pela mesma função que são alterados pelos parâmetros passados a ela.
Assim a função prioriza os parâmetros referentes aos três tipos de geração.\newline
Além dos parâmetros relacionados aos tipos de geração informados, existem os parâmetros relacionados a \myref{sec}{biblioteca faker} e uma lista que define quais tipos de operação,
descritos em \myref{subsec}{tipos de dados gerados}, que define, caso não esteja vazia,
quais os tipos de dados que serão gerados.
Isso foi útil pois utilizou-se o tipo de criação de dados de inserção na primeira etapa de testes,como descrito em \myref{subsec}{teste de tempo de operação de inserção no BD}, antes de gerar os dados dos outros tipos.\newline
Devido a limitações intencionais, o valor total de operações inseridos em cada operação deve considerar a quantidade da operação anterior.
Isso se faz necessário pois o algorítimo verifica apenas a quantidade total de elementos cadastrados no sqlite,
ou seja, caso sejam requisitadas 3 tipos de geração diferentes teriam que ser passadas da seguinte forma:
\begin{itemize}
\item uma geração da quantidade X de dados,resultando em X dados gerados
\item uma geração de Y dados,sendo que Y é igual a X+A,resultando em Y dados gerados
\item uma geração de Z dados,sendo que Z é igual a X+A+B,resultando em Z dados gerados
\end{itemize}
sendo assim,os dados gerados teriam que ser algo como X=5,Y=10 e Z=15,onde cada etapa apenas teriam 5 dados adicionados ao sqlite

a geração de dados inicialmente foi pensada para rodar em um servidor de forma sequencial,
isso simplesmente por que não teria processamento paralelo inicialmente no software,
entretanto quando isso se tornou necessário também foi possível utilizar o codigo previamente existente da geração de dados para a geração de forma paralela,
isso se mostrou uma grande vantagem para a etapa de desenvolvimento onde vários bancos de dados de testes foram gerados para que fosse garantido que todas as partes desenvolvidas do software estivessem funcionando corretamente,
devido a forma como isso foi pensado,o grande limitador da velocidade de geração de dados é o fator randômico,
devido a toda a recurção que ocorre em consequência aos tratamentos de erros,
além disso o outro maior limitador é a velocidade de disco,
visto que a aplicação do sqlite3 aceita apenas uma inserção por vez no banco de dados de forma paralela,
isso faz com que quanto mais rápido fosse possível a escrita em disco mais rapidamente esse fator limitador era deixado de lado,
devido ao fato de durante os testes da etapa de desenvolvimento todos terem sido usando um ssd para o salvamento desses dados isso não impactou em quase nada na velocidade de geração dos dados,mas na etapa de execução de testes isso se mostrou um problema,já que no dispositivo usado para executar o algoritmo dos testes o HD mecânico fez com que uma imensa diminuição da velocidade de leitura e escrita,sendo assim mesmo na operação de leitura,onde podem ser feitas varias leituras concorrentemente isso impactasse na performance e gerassem alguns erros como descrito em \myref{subsec}{erro de leitura pela falta de velocidade de disco}

%\subsection{tipos de dados gerados}
%\label{subsec:tipos de dados gerados}
\subsec{tipos de dados gerados}
Foram selecionadas para os teste apenas as operações mais utilizadas por um banco de dados:
\begin{itemize}
\item inserção de um novo dado
\item leitura completa de todos os dados de uma tabela
\item busca de elementos filtrados em determinada tabela
\item busca de apenas alguns dados de elementos filtrados em determinada tabela
\item edição de elementos
\item deleção de elementos filtrados
\end{itemize}
Antes de serem geradas, a operação de inserção passa por vários processos de tratamento de erro para se certificar que não houve dependência alguma que não foi gerada como,
por exemplo, gerar uma cidade sem existir um país cadastrado. Esse foi um dos motivos de ter sido utilizado um arquivo sqlite ao invés de outro método de armazenamento.
Dessa forma pode-se executar essa consulta de dependência de forma rápida e apenas retornar índices válidos para associações de tabela.
os vários dados gerados pelo programa de geração de dados são usados parcialmente para a geração dos dados novos,
mas todos os dados gerados são gerados da forma mais simplificada e sendo assim,poucas coisas que já existiam dentro do banco de dados dos dados já cadastrados,
apensas os ids cadastrados são usados,apenas para que as associações de dados sejam possíveis,os outros dados são ignorados,
sendo assim não são consultados os dados para as queries e nem nenhum outro dado como update,sendo assim,
a maioria dos dados gerados não conseguem retornar algum valor,como updates ou deleções,isso foi feito dessa forma apenas para simplificar o algorítimo,
e seria totalmente possível a modificação para que esses dados sejam levados em conta no futuro.


%\subsection{alimentação do algoritmo}
%\label{subsec:alimentação do algoritmo}
\subsec{alimentação do algoritmo}
O algoritmo de geração de dados funciona de forma que qualquer banco de dados possa ser utilizado para ter seus dados gerados.
Basta utilizar um arquivo json e seguir um determinado padrão que é composto por:
uma tag com o nome de uma tabela do banco de dados e dentro dela uma estrutura json com uma tag com o nome da coluna com seu conteúdo em um array de string contendo o primeiro tipo de dado e os outros valores adicionais para a geração.\newline
Dentro do algorítimo existem vários tipos de dados aceitáveis, tais como id, nome, associação e timestamp,
sendo que cada um deles possui um tipo bem definido pelo seu nome, mas o único que vale a pena citar seu funcionamento é o associação.
Como descrito em \myref{subsec}{sqlite} existe uma tabela do sqlite contendo as quantidades de elementos associados a cada tabela do banco de dados final.
O tipo de associação vai pegar esse valor e usar uma função de seleção randômica para que seja escolhido um elemento de id existente no intervalo descrito,
caso não exista algum elemento dessa tabela, por um tratamento de erro é gerado um elemento para ela, permitindo o funcionamento da associação no novo elemento que foi criado.\newline
Os únicos dados que não são passados para o algoritmo funcionar são o país que deve ser gerado os dados, de acordo com \myref{sec}{biblioteca faker},
e a quantidade de dados que devem ser geradas, ambos sendo necessários de serem inseridos na chamada da função.
Os outros dados relevantes referentes ao funcionamento da chamada da função estão em \myref{sec}{geração de dados}

%\subsection{sqlite}
%\label{subsec:sqlite}
\subsec{sqlite}
O banco de dados do sqlite foi projetado para ser totalmente maleável e modular,
de forma que não teriam que ser geradas várias tabelas para os vários tipos de dados do benchmark.
Foi pensado no seguinte método para se facilitar o desenvolvimento sendo uma tabela de índices e uma tabela de operações, a tabela de índices possui apenas 3 colunas,uma id,uma com o nome da tabela e uma com o total de elementos dessa tabela,a outra tabela é um pouco mais complexa e está descrita a seguir:
\begin{itemize}
\item a tabela de operações a ser executada é constituída de uma coluna inteira para o tipo de operação que será realizada, de acordo com {subsec}{tipos de dados gerados}
\item uma coluna é uma string contendo o nome do banco de dados que será executada a operação
\item uma coluna inteira para, se for necessário, conter o id no banco de dados do elemento trabalhado na operação. No caso de uma inserção é o id do novo elemento por exemplo
\item uma coluna text, nessa coluna serão inseridos valores adicionais necessários para a execução da operação, como os parâmetros de quais colunas devem ser atualizadas em um update.
Aqui os dados inseridos são salvos em formato json para facilitar o trabalho com a linguagem Python, visto que existe uma conversão direta de string json para o tipo dictionary do Python.
\item uma coluna text seguindo a mesma ideia da coluna anterior. Esses dados os dados obrigatórios de qualquer operação,onde dependendo da operação os dados contidos são diferentes.
\end{itemize}
Dessa forma, independente se é apenas uma operação de listagem completa,
que só necessita de ter preenchida a coluna com o nome do banco de dados e a coluna com o tipo de operação ou se for uma operação de update onde todos os campos podem estar preenchidos,
o banco de dados sqlite consegue lidar de forma rápida e segura com qualquer uma das operações e dados gerados pelo algoritmo.
foi cogitado o uso de outras estruturações da tabela de operações,mas essa foi a que foi mais simples de ser implementada,valida para todas as operações e a mais reaproveitável


%\section{containers docker}
%\label{sec:containers docker}
\sec{contêineres docker}
os contêineres docker foram criados a partir do sistema alpine Linux,no qual foram feitos 2 contêineres diferentes,
um deles para o MariaDB e outro para o postgres,os contêineres se certificam de criar o banco de dados de forma correta durante a inicialização dele,
após isso o contêiner durante a sua inicialização se certifica que o Python está instalado e tudo necessário para que o daemon ,
descrito em \myref{sec}{daemon de monitoramento},funcione,após isso o banco de dados do contêiner é finalmente iniciado.
essa forma de instalação do Python se certifica que tanto o interpretador quanto as bibliotecas usadas estão sempre atualizadas todas as vezes que o contêiner é instanciado,
apesar de esse método causar uma grande demora na primeira inicialização do contêiner,mas devido a forma como o script de inicialização funciona somente a primeira inicialização é impactada na sua velocidade de inicialização.
os contêineres também possuem um healthcheck para verificar se o banco de dados está acessível por fora do contêiner,
entretanto o contêiner não consegue exibir corretamente a saúde do contêiner devido a algum bug que não foi possível de corrigir
o contêiner baseado no alpine possui uma especificidade,para a arquitetura armhf,presente no Orangepi PC +,
ele só funciona até a versão 3.12 sem ter grandes modificações,isso devido a uma mudança no método como o sistema operacional manipula o relógio do sistema,
o que quer dizer que não é possível utilizar o gerenciador de pacotes dele que ,para se conectar ao servidor online,utiliza o SSL que,dentre outras coisas,
utiliza o horário do sistema para certificar que a conexão é segura.Sendo assim a versão utilizada foi a versão 3.12.
outra especificidade do alpine é que ele é um dos poucos sistemas Linux que não possui o GCC incluso como pacote padrão do sistema,
isso faz com que o Python tenha alguns problemas ao instalar algumas bibliotecas,dentre elas o psutil,que foi utilizado pelo \myref{sec}{daemon de monitoramento},
para solucionar isso foi necessário instalar um programa chamado linux-headers que é um conjunto de programas e bibliotecas padrões das distribuições Linux,
alem é claro do próprio GCC,após a adição desses programas o contêiner pôde funcionar corretamente.

%\section{daemon de monitoramento}
%\label{sec:daemon de monitoramento}
\sec{daemon de monitoramento}
o daemon de monitoramento monitora os status da maquina na qual está rodando,seja uma maquina física ou um contêiner docker,
para esse fim é utilizada a \myref{sec}{biblioteca psutil} que é a principal biblioteca Python quando se trata de monitoramento de hardware.
o daemon utiliza também uma biblioteca feita para simplificar o tratamento de log,uma das funcionalidades contidas nessa biblioteca é a comunicação com o aglutinador de logs Logstash do \myref{sec}{elasticsearch monitoring stack},isso feito em cima da biblioteca python-logstash.
o arquivo de configuração do daemon é um json constituído de 2 partes,os parâmetros para se conectar ao Logstash e os dados que serão coletados da maquina local,
esses dados coletados serão enviados para o servidor Logstash onde lá serão trabalhados
o daemon envia esses dados com um intervalo de 0.1 segundos,que é apenas passado para que não sejam enviados dados errados de cpu para o servidor de log,
mas poderia ser aumentado para diminuir o estresse na maquina que está rodando ele e diminuir um pouco o estresse do servidor de coleta de logs,que com as maquinas usadas não é necessário,alem é claro de diminuir a quantidade da dados processados no pós processamento de resultados descritos em \myref{sec}{processamento de resultados}

%\section{ambiente de desenvolvimento}
%\label{sec:ambiente de desenvolvimento}
\sec{ambiente de desenvolvimento}
O ambiente utilizado foi dividido em duas partes, programação local e remota. Na programação remota as execuções foram feitas em um servidor baseado em Raspberry PI 4 e na programação local foram feitas em duas maquinas diferentes sendo computadores locais.
A programação remota se provou bem útil quando houve a necessidade de troca de computador ou sistema operacional, facilitando ainda a implementação de um servidor unificado de análise de log pois era mais simples a comunicação entre o codigo executado e o servidor \myref{sec}{elasticsearch monitoring stack}.\newline
Foram utilizados Visual Studio Code e DBeaver para o desenvolvimento da aplicação principal e ainda foi utilizada uma implementação do \myref{sec}{elasticsearch monitoring stack} de análise de log.
Os dois primeiros foram escolhidos dentre outros motivos por serem open-source e estarem disponíveis tanto para Linux quanto Windows,
visto que ambos sistemas operacionais foram utilizados para o desenvolvimento de acordo com a necessidade no momento.\newline
Para o controle de versão foi utilizado o Gita, deixando registrado todo o histórico de alterações do programa,
o que se mostrou bem útil para o rastreio de erros ocorridos durante o longo tempo de desenvolvimento do código.\newline
Para os testes iniciais do código foram utilizados contêineres docker não limitados durante a etapa de implementação dos scripts do DBbench,
que demandam a existência dos servidores dos bancos de dados sendo executados,
ao contrário do restante do desenvolvimento da aplicação, que não interagiu diretamente com os bancos de dados.\newline
A geração do banco de dados inicial,descrito em \myref{subsec}{sqlite}, foi feito completamente em um Raspberry Pi 4 com um pequeno overclock,
essa geração foi feita durante alguns dias, visto que o SBC, de acordo com testes de velocidade feitos \myref{sec}{testes de tempo},
consome menos energia e ,devido a sua configuração,possui um acesso headless mais simplificado que as outras maquinas utilizadas.

\sec{processamento de resultados}
os dados coletados pelo \myref{sec}{elasticsearch monitoring stack} são extraídos para CSV,processados para eliminação de dados irrelevantes,mesmo que durante o processo de \myref{sec}{daemon de monitoramento} apenas os dados selecionados sejam coletados,ainda existem dados irrelevantes na composição desses dados,após esse processamento inicial é usado um segundo processamento para eliminar duplicatas e para separar em 4 arquivos diferentes os resultados,um para cada banco de dados em cada maquina,a ultima etapa é a plotagem dos gráficos utilizando a biblioteca altair que gera gráficos interativos em HTML que facilitam a pesquisa dos dados e exploração do gráfico,ainda tem uma verificação manual para se certificar que os dados coletados estão corretamente associados ao servidor correto,isso resulta na certificação de que os dados antes de serem processados estejam corretamente identificados,o que é importante devido a forma como os dados são coletados e armazenados,principalmente os dados de tempo,que decidem semi-aleatoriamente qual a ordem que serão armazenados no array de tempos do arquivo json de resultados,isso por que caso o índice 1 seja o amd ele se manterá o mesmo até o final da execução,o que ocorreu na maioria dos testes realizados,mas não em todos.
os gráficos gerados pelo altair são arquivos HTML,mas devido ao massivo numero de dados gerados pelos logs o arquivo se torna muito grande e consome uma imensa quantidade de ram,inclusive em um dos computadores utilizados para a analise não sequer possível abrir o arquivo HTML para a analise,e foi necessário abrir em outra maquina,existem otimizações possíveis para esse problema,mas nenhuma das soluções propostas foi capaz de corrigir o problema.
foi gerado também um arquivo HTML que exibe todos os resultados de todas as maquinas ao mesmo tempo,ele é tão massivo que só foi possível abrir o gerado pelo  \myref{subsec}{teste de tempo de operação de inserção no BD},o \myref{subsec}{teste de tempo de operações variadas no BD} resultou num HTML que o próprio navegador não consegue terminar o processo de carregar o arquivo.

%\chapter{problemas e erros}
%\label{ch:problemas e erros}
\ch{problemas e erros}
aqui foram descritos os erros mais marcantes durante os processos necessários para a obtenção dos resultados deste texto
\sec{desenvolvimento do algorítimo}
durante o desenvolvimento vários tipos de erros aconteceram,em praticamente todas as etapas de desenvolvimento do algorítimo erros marcantes ocorreram,
os principais ocorreram durante a etapa de criação do sqlite,no processamento paralelo e na inserção dentro do banco de dados finais\newline
os dados relevantes das maquinas usadas para o desenvolvimento foram um ryzen 3200g com 16GB de RAM e ssd de 480GB e um i7 7500u com 8GB de RAM e ssd de 240GB.
\subsec{erros da geração do sqlite}
durante a geração do sqlite vários problemas relacionados a geração ocorreram,
um deles fez com que a funcionalidade de seleção de múltiplos países na geração de dados tivesse q ser travada apenas para o brasil,
isso principalmente por que dos vários dados gerados,alguns causam problemas ao ser trocado o pais,
pois como foi dito em \myref{sec}{biblioteca faker} existem vários parâmetros diferentes dependendo do pais selecionado,o mais marcante desses dados no entanto é a geração de números de celular,
visto que o brasil é um dos poucos países que possuem essa opção dentre os existentes na biblioteca,apesar de não ser o único problema encontrado,
existem também problemas com os parâmetros de geração de endereço e alguns poucos dados de informações pessoais.\newline

\subsec{erro do processamento paralelo de threads}
já durante a etapa de processamento paralelo,seus problemas de desenvolvimento e erros se misturam com a etapa de inserção de dados no banco de dados final,
pois ambos foram desenvolvidos simultaneamente,apesar de o processamento paralelo tenha sido iniciado primeiro.\newline
o processamento paralelo teve vários tipos de problemas,o primeiro problema marcante foi a implementação original dele,
originalmente foi pensado em utilizar a implementação de threads ao invés de subprocessos,isso porque as threads são mais fáceis de serem lidadas caso ocorra um erro,
isso por que os dados são comunicados diretamente pela classe queue,que é utilizada para se compartilhar dados em tempo real entre varias instancias de processamento durante a execução de um programa Python.
As palavras chave aqui são compartilhamento entre varias instancias,isso quer dizer que ela não faz distinção se as threads foram ou não iniciadas pela mesma classe,des de que existam threads elas compartilham as mesmas informações e espaço de memória\newline
isso foi identificado devido a arvore de processos necessária para que os testes fossem feitos de forma simultânea,já que ao se iniciar uma thread de um processo,
essa thread não pode iniciar uma outra thread hierarquicamente inferior a ela,isso resulta num problema da implementação da linguagem C sobre a qual a classe de processamento paralelo queue foi construída.\newline
Esse erro de acordo com as documentações encontradas é devido ao compartilhamento de endereços de memória na linguagem c chamada "double free or corruption (out)" esse erro ocorre quando se remove ou adiciona alguma variável ou índice de vetor de um processamento paralelo,
devido a forma como a biblioteca de processamento paralelo lida com valores das operações para evitar execução dupla de algum valor isso é necessário,
entretanto quando se utiliza a biblioteca Manager ao invés da queue isso não ocorre,entretanto essa biblioteca está associada ao processamento paralelo de subprocessos,
por isso a migração de threads para subprocessos foi necessária\newline
\subsec{erro do processamento paralelo de subprocessos daemon}
um dos problemas encontrados foi uma mensagem de erro chamada de "AssertionError: daemonic processes are not allowed to have children" esse erro impede que processos daemon tenham processos filhos,
isso fez com que o processo de sub-processamento tivesse q ser convertido de daemon para um processo convencional,isso pode ser problemático quando se quer fazer um monitoramento do tempo de forma mais direta , isso pois no modo daemon é possível rodar um codigo enquanto aguarda a execução dos processos daemon serem terminadas,esse foi o método escolhido no final do desenvolvimento,devido a modificação na forma como o processo que possui daemon foi implementado,sendo que apenas as threads filhas eram deamons,as threads principais,que são as onde o tempo é monitorado,foi utilizado o método de se esperar a execução de todos subprocessos terminarem e medir o tempo gasto pelo conjunto,onde essa thread retornava o tempo para a função que a chamou,o processo foi um pouco mais complexo de se implementar que o previamente proposto,mas terminou com o mesmo resultado.\newline
\subsec{rollback de dados no postgres}
outro erro marcante foi o de tratamento de rollback nas operações do postgres,devido a forma como as operações dos bancos de dados foram geradas,
nenhuma das operações ,além é claro da inserção, é realmente válida ,o que quer dizer que de acordo com os métodos de segurança e otimização do postgres é necessário executar um rollback após a sua execução para evitar problemas,
isso resulta entre outras coisas numa maior demora da execução do postgres quando dados considerados inválidos são executados e também numa maior necessidade de tratamento de erros na parte relacionada ao postgres da biblioteca \myref{subsec}{gerenciadorDeBD},devido ao rollback necessário,durante a etapa de desenvolvimento foi necessário se reformular os tratamentos de erro de varias formas para que apenas os erros que realmente necessitavam de rollback tivessem a operação executada,já que devido a hierarquia do tratamento de erro da biblioteca psycopg2,alguns erros que ocorriam eram entendidos como necessários de serem executados os rollback em vez do tratamento correto,principalmente o erro de time-out da conexão ou de conexão fechada.
\sec{erros dos testes finais}
durante a etapa de testes finais,ou seja,pós a etapa de testes de desenvolvimento,foi utilizado um servidor baseado no FX-6300,utilizando 4GB de RAM e um HD mecânico de 160GB
\subsec{erro de leitura pela falta de velocidade de disco}
o HD mecânico da maquina dos testes finais possui velocidades limitadas pela sua tecnologia ,SATA2,isso impactou de forma considerável a execução dos testes,isso pois mesmo com a possibilidade de serem feitos diversas leituras simultâneas no sqlite,mesmo sendo possível varias leituras simultâneas ao mesmo tempo nesse método de armazenamento de dados,isso pois a latência entre a requisição da consulta e todo o processo logico e físico da leitura causasse um time out ocasional na biblioteca sqlite.
uma solução para isso foi a substituição da mídia de armazenamento do arquivo sqlite,foi utilizado um pendrive Kingston 3.0 de 16GB,com velocidades de leitura superiores,de quase o dobro da velocidade, e latência muito inferior que a tecnologia SATA2,após essa substituição não foi mais visto nenhum erro de time-out durante os testes.


%\chapter{Resultados}
%\label{ch: resultados}
\ch{Resultados}

\sec{resultados de inserção fracionada}
o resultado encontrado do primeiro teste de manipulação de bancos de dados,que é o teste de inserção continua,onde foram inseridos de acordo com \myref{subsec}{teste de tempo de operação de inserção no BD},
esses dados são comprovadamente sem ocorrência de erros de acordo com o codigo descrito em \myref{sec}{geração de dados},
de acordo com os dados coletados pelo \myref{sec}{contêineres docker} em todos os núcleos disponíveis para o contêiner existe uma variação de porcentagem de uso,como o descrito nos arquivos de logs anexos e na tabela \myref{tab}{resultados insercao fracionada} essa variação ocorre,entretanto o computador \myref{sig}{arm} por ter mais núcleos físicos,é mais complicado de ser avaliada a porcentagem de uso devido a forma como o docker distribui a carga de uso de cpu.\newline
Em relação ao uso de ram,ele se manteve mais constante,na arquitetura armhf o uso de RAM é bem menor que no amd64,
nas duas arquiteturas diferença do uso de RAM é de cerca de 5\% ,onde no MariaDB a variação faça com que o uso de RAM seja ligeiramente maior no amd64.
para o postgres a velocidade de disco de escrita é em torno de 500kbps para o \myref{sig}{arm} e 3Mbps para o amd,já para o MariaDB é de 3.5Mbps para o \myref{sig}{arm} e 9.5Mbps para o amd.\newline
levando em conta a descrição de hardware de \myref{ch}{testes}, essas variações das velocidades são provavelmente devido a otimizações das arquiteturas para cada banco de dados.
já a velocidade de leitura de disco é praticamente 0\% o tempo todo,isso provavelmente se deve a pouca necessidade de informações consultada dos dados cadastrados pelo algorítimo de benchmark.\newline
a principal diferença identificada em relação aos testes alem do previamente informado é o tempo,em 60\% das vezes o postgres \myref{sig}{arm} é mais rápido que o amd,enquanto isso em 85\% das vezes do MariaDB o amd é mais rápido.\newline

\imagemsvg{resultados insercao fracionada}{insercao fracionada/insercao tempos.svg}{valores tempo benchmark inserção fracionada}
\begin{easyTableAuto}{dados encontrados de uso de hardware teste inserção}{ container & média de cpu & valor máximo médio de cpu & média de ram & valor máximo médio de ram }{5}{p{.15\textwidth}|p{.15\textwidth}|p{.2\textwidth}|p{.15\textwidth}|p{.2\textwidth}}
%nome da tabela e label
%cabeçalho
%quantidade total de colunas
%formatação da tabela
 postgres arm & 8 & 25 & 27 & 28 \\ \hline
 postgres amd & 18 & 27 & 30 & 30 \\ \hline
 mariadb arm & 8 & 16 & 34 & 35 \\ \hline
 mariadb amd & 18 & 27 & 34 & 35 \\ \hline

\end{easyTableAuto}
%lable
%arquivo
%caption
\sec{resultados de operação completa fracionada}
ao contrário do que era esperado,os valores gerados pelo \myref{sec}{software de benchmark} geraram de forma igualmente distribuida,ou seja,os dados gerados foram gerados com uma distribuição de aproximadamente 20\% para cada tipo de operação,isso por que por algum motivo desconhecido as operações de tipo 5,como descrito em \myref{subsec}{tipos de dados gerados},não foram gerados nenhuma vez durante os testes,fora isso todos os outros dados gerados ocorreram como o esperado,onde são feitas queries de seleção ,pesquisa e inserção da forma como era esperada e as operações ocorreram como o esperado.\newline
um fator interessante a se destacar é o de que,apesar da distribuição de operações ter sido homogênea,o custo de uso de hardware não foi,em certos momentos houve um grande uso de cpu ,mas nunca fugindo muito dos valores apresentados em \myref{sec}{resultados de inserção fracionada},e na maioria dos casos houve um maior uso de ram que o apresentado no dito teste,um fator a se destacar é o de que os primeiros ciclos de teste funcionaram da seguinte forma:
\begin{itemize}
\item a maior parte,cerca de 60\% dos dados , foi de inserção e o restante de operações variadas,diferente do esperado,isso provavelmente se deve a algum problema durante a gerencia dos arquivos salvos na maquina,não no algoritimo em si,isso se comprova nos próximos nove ciclos
\item nos próximos nove ciclos,apenas dados de inserção foram gerados
\item a partir do 11° ciclo ,no postgres ,houve um aumento significativo de ram,os valores que variavam entre 18 a 30\% começaram a varias de 18 a 53\% no amd e no \myref{sig}{arm} a variação saiu de 20 a 34\% para de 20 a 52\%,
\end{itemize}
os tempos apresentados por esse teste estão descritos na \autoref{fig:resultados todos fracionada}
\imagemsvg{resultados todos fracionada}{todos fracionada/todos tempos.svg}{valores tempo benchmark todas operações fracionadas}

uma coia interessante ocorreu em uma etapa do teste,onde aparentemente a maquina que estava executando o teste travou e voltou a funcionar em seguinda,isso visto que como as imagens do \myref{anexo}{resultados todos parte 9} demonstram,durante um intervalo de tempo nenhum dos containers estavam ativos,e sendo assim,nenhuma operação estava sendo realizada neles.\newline
%lable
%arquivo
%caption

\begin{easyTableAuto}{dados encontrados de uso de hardware teste completo}{ container & média de cpu & valor máximo médio de cpu & média de ram & valor máximo médio de ram }{5}{p{.15\textwidth}|p{.15\textwidth}|p{.2\textwidth}|p{.15\textwidth}|p{.2\textwidth}}
%nome da tabela e label
%cabeçalho
%quantidade total de colunas
%formatação da tabela
 postgres arm & 16 & 33 & 61 & 63 \\ \hline
 postgres amd & 9 & 45 & 62 & 63 \\ \hline
 mariadb arm & 16 & 23 & 30 & 30 \\ \hline
 mariadb amd & 9 & 16 & 35 & 35 \\ \hline
\end{easyTableAuto}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                      Capítulo 6                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ch{Conclusão}
como conclusão dos testes realizados foi descoberto que a arquitetura \myref{sig}{arm} é ,como esperado, a mais potente em relação a desempenho por watt de consumo,mas diferentemente do esperado os resultados de ambos foram bem proximos,quase iguais para cada banco de dados diferente,o que resultou numa eficiencia de cerca de 9 vezes para a arquitetura arm,visto que o computador \myref{sig}{arm} utilizado consome 10w de energia enquanto o computador amd64 utilizado concome 90w de energia,isso considerando que o consumo de ambos foi de 100\% de consumo energetico o tempo todo.\newline
os testes realizados foram focados em manter ambos os servidores com a mesma exata característica de carga e desempenho,isso sempre visando o objetivo final de fazer com que a maior dos dados coletados pudessem ser diretamente comparáveis já que o mesmo numero de núcleos,ram,velocidade de disco e rede estavam disponiveis para ambas maquinas e o clock de ambas também foi limitado para exatos 1ghz para que as contas finais de comparação fossem mais simples,sendo assim pode-se considerar os testes como sendo testes 1 para 1 nas diferentes arquiteturas.\newline
os dados coletados apontam que a arquitetura \myref{sig}{arm} possuiu uma porcentagem de uso de cpu mais baixa que a da arquitetura amd64,o que indica uma otimização em relação a isso do ponto de vista dessa arquitetura,essa diferença causou uma maior demora de processamento na arquitetura armhf,isso levando em conta que a diferença é bem baixa se tora irrisória em relação as comparações de arquiteturas.\newline
enquanto a arquitetura amd64 apresentou umconsumo maior de ram,sendo assim é possivel se indicar que os programas de banco de dados utilizados tiveram suas otimizações focadas em coisas diferentes.
os bancos de dados mariadb e postgres apresentam diferenças visiveis entre si em relação a uso de ram e cpu.\newline




%\anexo{log tempo insercao}{teste insercao/valores_tempo_velocidade_benchmark_fracionado.json}
%\label{anexo:#1}
%\lstinputlisting{apendices/teste insercao/valores_tempo_velocidade_benchmark_fracionado.json}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                      REFERÊNCIAS                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ---
% Finaliza a parte no bookmark do PDF, para que se inicie o bookmark na raiz
% ---
\bookmarksetup{startatroot}%
% ---

% ---------------------------------------------------------------------------------------------
% ELEMENTOS PÓS-TEXTUAIS
% ---------------------------------------------------------------------------------------------

%\ch{anexos}
apendices relacionados ao teste completo\newline
imagens
\textbf{todos tempos}\label{anexo:todos tempos}\newline%
\apendicesvg{todos fracionada/todos tempos.svg}{todos fracionada/todos tempos.svg}
\textbf{resultados todos parte 0}\label{anexo:resultados todos parte 0}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo0.svg}{todos fracionada/uso do container container_mariadb_amd_limpo0.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo0.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo0.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo0.svg}{todos fracionada/uso do container container_postgres_amd_limpo0.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo0.svg}{todos fracionada/uso do container container_postgres_armhf_limpo0.svg}%
\pagebreak\newline
\textbf{resultados todos parte 1}\label{anexo:resultados todos parte 1}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo1.svg}{todos fracionada/uso do container container_mariadb_amd_limpo1.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo1.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo1.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo1.svg}{todos fracionada/uso do container container_postgres_amd_limpo1.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo1.svg}{todos fracionada/uso do container container_postgres_armhf_limpo1.svg}%
\pagebreak\newline
\textbf{resultados todos parte 2}\label{anexo:resultados todos parte 2}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo2.svg}{todos fracionada/uso do container container_mariadb_amd_limpo2.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo2.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo2.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo2.svg}{todos fracionada/uso do container container_postgres_amd_limpo2.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo2.svg}{todos fracionada/uso do container container_postgres_armhf_limpo2.svg}%
\pagebreak\newline
\textbf{resultados todos parte 3}\label{anexo:resultados todos parte 3}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo3.svg}{todos fracionada/uso do container container_mariadb_amd_limpo3.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo3.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo3.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo3.svg}{todos fracionada/uso do container container_postgres_amd_limpo3.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo3.svg}{todos fracionada/uso do container container_postgres_armhf_limpo3.svg}%
\pagebreak\newline
\textbf{resultados todos parte 4}\label{anexo:resultados todos parte 4}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo4.svg}{todos fracionada/uso do container container_mariadb_amd_limpo4.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo4.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo4.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo4.svg}{todos fracionada/uso do container container_postgres_amd_limpo4.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo4.svg}{todos fracionada/uso do container container_postgres_armhf_limpo4.svg}%
\pagebreak\newline
\textbf{resultados todos parte 5}\label{anexo:resultados todos parte 5}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo5.svg}{todos fracionada/uso do container container_mariadb_amd_limpo5.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo5.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo5.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo5.svg}{todos fracionada/uso do container container_postgres_amd_limpo5.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo5.svg}{todos fracionada/uso do container container_postgres_armhf_limpo5.svg}%
\pagebreak\newline
\textbf{resultados todos parte 6}\label{anexo:resultados todos parte 6}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo6.svg}{todos fracionada/uso do container container_mariadb_amd_limpo6.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo6.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo6.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo6.svg}{todos fracionada/uso do container container_postgres_amd_limpo6.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo6.svg}{todos fracionada/uso do container container_postgres_armhf_limpo6.svg}%
\pagebreak\newline
\textbf{resultados todos parte 7}\label{anexo:resultados todos parte 7}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo7.svg}{todos fracionada/uso do container container_mariadb_amd_limpo7.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo7.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo7.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo7.svg}{todos fracionada/uso do container container_postgres_amd_limpo7.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo7.svg}{todos fracionada/uso do container container_postgres_armhf_limpo7.svg}%
\pagebreak\newline
\textbf{resultados todos parte 8}\label{anexo:resultados todos parte 8}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo8.svg}{todos fracionada/uso do container container_mariadb_amd_limpo8.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo8.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo8.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo8.svg}{todos fracionada/uso do container container_postgres_amd_limpo8.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo8.svg}{todos fracionada/uso do container container_postgres_armhf_limpo8.svg}%
\pagebreak\newline
\textbf{resultados todos parte 9}\label{anexo:resultados todos parte 9}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo9.svg}{todos fracionada/uso do container container_mariadb_amd_limpo9.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo9.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo9.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo9.svg}{todos fracionada/uso do container container_postgres_amd_limpo9.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo9.svg}{todos fracionada/uso do container container_postgres_armhf_limpo9.svg}%
\pagebreak\newline
\textbf{resultados todos parte 10}\label{anexo:resultados todos parte 10}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo10.svg}{todos fracionada/uso do container container_mariadb_amd_limpo10.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo10.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo10.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo10.svg}{todos fracionada/uso do container container_postgres_amd_limpo10.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo10.svg}{todos fracionada/uso do container container_postgres_armhf_limpo10.svg}%
\pagebreak\newline
\textbf{resultados todos parte 11}\label{anexo:resultados todos parte 11}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo11.svg}{todos fracionada/uso do container container_mariadb_amd_limpo11.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo11.svg}{todos fracionada/uso do container container_mariadb_armhf_limpo11.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo11.svg}{todos fracionada/uso do container container_postgres_amd_limpo11.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo11.svg}{todos fracionada/uso do container container_postgres_armhf_limpo11.svg}%
\pagebreak\newline
\textbf{resultados todos parte 12}\label{anexo:resultados todos parte 12}\newline%
\apendicesvg{todos fracionada/uso do container container_mariadb_amd_limpo12.svg}{todos fracionada/uso do container container_mariadb_amd_limpo12.svg}%
\apendicesvg{todos fracionada/uso do container container_mariadb_armhf_limpo12}{todos fracionada/uso do container container_mariadb_armhf_limpo12.svg}%
\apendicesvg{todos fracionada/uso do container container_postgres_amd_limpo12}{todos fracionada/uso do container container_postgres_amd_limpo12.svg}%
%\apendicesvg{todos fracionada/uso do container container_postgres_armhf_limpo12}{todos fracionada/uso do container container_postgres_armhf_limpo12.svg}%
\pagebreak\newline
\pagebreak
arquivos\newline
%\fbox{\begin{minipage}{\textwidth}
\fbox{\begin{minipage}{\textwidth}
\textbf{logs todos mariadb_amd_processados}\label{anexo:logs todos mariadb_amd_processados.log}\newline
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 2, 2, 0, 15, 54]\newline
[6362, 50779, 216701, 273480, 32996, 555223, 99182, 3766, 341, 17]\newline
[22, 19, 5, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 40\newline
o valor com mais ocorrencias de uso de ram é 35\newline
\newline
\newline
\newline
uso de cpu\newline
[4, 7, 2, 1, 0, 1, 5, 2482, 51165, 700744]\newline
[0, 1288, 49, 11, 86, 3079, 290263, 2, 59534, 0]\newline
[0, 246, 682, 9325, 0, 10315, 30, 9474, 334, 0]\newline
[1448, 1, 0, 4629, 0, 142, 4702, 25, 738, 0]\newline
[0, 2022, 56, 5, 321, 2814, 383, 1, 0, 0]\newline
[0, 0, 1, 341, 1805, 181, 1, 80, 926, 0]\newline
[0, 237, 6, 1426, 55, 0, 762, 0, 2, 114]\newline
[0, 8, 1037, 1, 0, 487, 82, 83, 8, 0]\newline
[0, 856, 0, 463, 90, 7, 0, 2, 50, 0]\newline
[943, 647, 153, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}

\fbox{\begin{minipage}{\textwidth}
\textbf{logs todos mariadb_armhf_processados}\label{anexo:logs todos mariadb_armhf_processados.log}\newline
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 5, 16, 8]\newline
[16, 21, 58, 123, 903, 7033, 21051, 106000, 133555, 188308]\newline
[240178, 33226, 110, 31, 45, 21, 74, 106, 22, 131]\newline
[70, 7, 94, 4, 131, 52, 13, 276, 3, 168]\newline
[369, 19, 1, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 30\newline
o valor com mais ocorrencias de uso de ram é 30\newline
\newline
\newline
\newline
uso de cpu\newline
[21, 6, 7, 12, 15, 72, 129, 65494, 34474, 104121]\newline
[5, 252, 96, 132, 2292, 7845, 385212, 10, 30660, 5]\newline
[4, 1269, 188, 189609, 3, 22745, 145, 4737, 6845, 16]\newline
[5311, 41, 0, 7238, 0, 816, 3030, 23, 3269, 0]\newline
[1, 4067, 585, 12, 18, 1582, 2072, 6, 0, 0]\newline
[0, 0, 2, 1352, 1081, 18, 3, 239, 1733, 0]\newline
[0, 881, 1, 725, 174, 0, 1187, 0, 5, 646]\newline
[1, 123, 458, 12, 0, 802, 519, 5, 95, 0]\newline
[0, 227, 0, 433, 261, 77, 11, 2, 2, 0]\newline
[102, 215, 145, 3, 1, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}

\fbox{\begin{minipage}{\textwidth}
\textbf{logs todos postgres_amd_processados}\label{anexo:logs todos postgres_amd_processados.log}\newline
 uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 3263, 30386, 26906, 1113, 12273, 13977, 6987]\newline
[12137, 12152, 14554, 16969, 24602, 32591, 34546, 26028, 29965, 35166]\newline
[37614, 35360, 36454, 39982, 44499, 51398, 54360, 61957, 64734, 70274]\newline
[73288, 71273, 74495, 71518, 69823, 62375, 54838, 46323, 40031, 42772]\newline
[55185, 72958, 82168, 73553, 37296, 6388, 691, 523, 321, 93]\newline
[15, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 62\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 8, 1, 3, 1, 1, 31, 2597, 38173, 344957]\newline
[0, 17264, 1282, 143, 901, 7344, 166851, 17, 177235, 1]\newline
[0, 1847, 13955, 19279, 1, 94879, 784, 146286, 3954, 65]\newline
[23579, 346, 3, 101781, 1, 6089, 124456, 2092, 25778, 0]\newline
[3, 79642, 7366, 1016, 11027, 102958, 27511, 663, 2, 1]\newline
[1, 1, 891, 26264, 84182, 9902, 1478, 8258, 57722, 38]\newline
[18, 20908, 3810, 65989, 7925, 204, 60423, 14, 1976, 18270]\newline
[927, 7100, 55495, 3289, 15, 44659, 17674, 9914, 6742, 61]\newline
[35, 45854, 1037, 33769, 14665, 6772, 2917, 4874, 12472, 378]\newline
[45469, 37198, 23804, 5302, 2657, 991, 261, 52, 2, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}

\fbox{\begin{minipage}{\textwidth}
\textbf{logs todos postgres_armhf_processados}\label{anexo:logs todos postgres_armhf_processados.log}\newline
 uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 255, 7152, 16283]\newline
[32831, 19896, 2336, 2662, 4372, 6181, 7587, 12039, 10345, 12301]\newline
[15140, 20210, 21261, 22132, 25138, 25781, 24380, 24325, 25114, 28020]\newline
[33401, 32594, 36043, 34009, 37117, 38893, 37737, 39704, 44899, 44957]\newline
[44297, 46854, 46327, 49719, 51753, 48376, 52095, 58927, 59520, 68535]\newline
[73293, 80115, 79706, 61333, 40287, 26496, 17648, 11358, 6472, 2002]\newline
[577, 220, 94, 22, 80, 29, 4, 51, 100, 59]\newline
[72, 55, 24, 12, 3, 27, 121, 72, 70, 61]\newline
[71, 14, 7, 2, 2, 3, 1, 83, 61, 112]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 61\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 12, 10, 28, 68, 588, 3618, 118494, 330874, 352961]\newline
[85, 10533, 4960, 2176, 16008, 92217, 623653, 285, 282050, 39]\newline
[7, 12853, 7361, 220074, 4, 274752, 2669, 134714, 22195, 439]\newline
[89115, 1320, 2, 169013, 19, 15285, 93588, 4316, 64198, 23]\newline
[36, 117739, 14214, 1406, 4456, 70651, 54517, 903, 19, 1]\newline
[0, 10, 934, 47887, 58121, 3592, 1484, 11312, 81406, 91]\newline
[69, 38937, 2630, 46263, 10104, 218, 75911, 31, 1597, 36127]\newline
[632, 9434, 43290, 3032, 46, 69151, 34191, 2579, 8050, 88]\newline
[52, 33862, 653, 46121, 23382, 6358, 2337, 1375, 1741, 188]\newline
[25154, 40896, 30033, 3361, 890, 339, 148, 70, 8, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}
%\end{minipage}}

apendices relacionados ao teste insercao\newline
\textbf{tempo insercao}\label{anexo:tempo insercao}\newline%
\apendicesvg{insercao fracionada/insercao tempos.svg}{insercao fracionada/insercao tempos.svg}
\textbf{resultados insercao parte 0}\label{anexo:resultados insercao parte 0}\newline%
\apendicesvg{insercao fracionada/uso do container container_mariadb_amd_limpo0.svg}{insercao fracionada/uso do container container_mariadb_amd_limpo0.svg}
\apendicesvg{insercao fracionada/uso do container container_mariadb_armhf_limpo0.svg}{insercao fracionada/uso do container container_mariadb_armhf_limpo0.svg}
\apendicesvg{insercao fracionada/uso do container container_postgres_amd_limpo0.svg}{insercao fracionada/uso do container container_postgres_amd_limpo0.svg}
\apendicesvg{insercao fracionada/uso do container container_postgres_armhf_limpo0.svg}{insercao fracionada/uso do container container_postgres_armhf_limpo0.svg}

arquivos\newline
\fbox{\begin{minipage}{\textwidth}
\textbf{logs insercao mariadb_amd_processados}\label{anexo:logs insercao mariadb_amd_processados.log}\newline
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 2, 2, 0, 15, 54]\newline
[6362, 50779, 216701, 273480, 32996, 555223, 99182, 3766, 341, 17]\newline
[22, 19, 5, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 40\newline
o valor com mais ocorrencias de uso de ram é 35\newline
\newline
\newline
\newline
uso de cpu\newline
[4, 7, 2, 1, 0, 1, 5, 2482, 51165, 700744]\newline
[0, 1288, 49, 11, 86, 3079, 290263, 2, 59534, 0]\newline
[0, 246, 682, 9325, 0, 10315, 30, 9474, 334, 0]\newline
[1448, 1, 0, 4629, 0, 142, 4702, 25, 738, 0]\newline
[0, 2022, 56, 5, 321, 2814, 383, 1, 0, 0]\newline
[0, 0, 1, 341, 1805, 181, 1, 80, 926, 0]\newline
[0, 237, 6, 1426, 55, 0, 762, 0, 2, 114]\newline
[0, 8, 1037, 1, 0, 487, 82, 83, 8, 0]\newline
[0, 856, 0, 463, 90, 7, 0, 2, 50, 0]\newline
[943, 647, 153, 2, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}
\fbox{\begin{minipage}{\textwidth}
\textbf{logs insercao mariadb_armhf_processados}\label{anexo:logs insercao mariadb_armhf_processados.log}\newline
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 5, 16, 8]\newline
[16, 21, 58, 123, 903, 7033, 21051, 106000, 133555, 188308]\newline
[240178, 33226, 110, 31, 45, 21, 74, 106, 22, 131]\newline
[70, 7, 94, 4, 131, 52, 13, 276, 3, 168]\newline
[369, 19, 1, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 30\newline
o valor com mais ocorrencias de uso de ram é 30\newline
\newline
\newline
\newline
uso de cpu\newline
[21, 6, 7, 12, 15, 72, 129, 65494, 34474, 104121]\newline
[5, 252, 96, 132, 2292, 7845, 385212, 10, 30660, 5]\newline
[4, 1269, 188, 189609, 3, 22745, 145, 4737, 6845, 16]\newline
[5311, 41, 0, 7238, 0, 816, 3030, 23, 3269, 0]\newline
[1, 4067, 585, 12, 18, 1582, 2072, 6, 0, 0]\newline
[0, 0, 2, 1352, 1081, 18, 3, 239, 1733, 0]\newline
[0, 881, 1, 725, 174, 0, 1187, 0, 5, 646]\newline
[1, 123, 458, 12, 0, 802, 519, 5, 95, 0]\newline
[0, 227, 0, 433, 261, 77, 11, 2, 2, 0]\newline
[102, 215, 145, 3, 1, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}
\fbox{\begin{minipage}{\textwidth}
\textbf{logs insercao postgres_amd_processados}\label{anexo:logs insercao postgres_amd_processados.log}\newline
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 3263, 30386, 26906, 1113, 12273, 13977, 6987]\newline
[12137, 12152, 14554, 16969, 24602, 32591, 34546, 26028, 29965, 35166]\newline
[37614, 35360, 36454, 39982, 44499, 51398, 54360, 61957, 64734, 70274]\newline
[73288, 71273, 74495, 71518, 69823, 62375, 54838, 46323, 40031, 42772]\newline
[55185, 72958, 82168, 73553, 37296, 6388, 691, 523, 321, 93]\newline
[15, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 62\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 8, 1, 3, 1, 1, 31, 2597, 38173, 344957]\newline
[0, 17264, 1282, 143, 901, 7344, 166851, 17, 177235, 1]\newline
[0, 1847, 13955, 19279, 1, 94879, 784, 146286, 3954, 65]\newline
[23579, 346, 3, 101781, 1, 6089, 124456, 2092, 25778, 0]\newline
[3, 79642, 7366, 1016, 11027, 102958, 27511, 663, 2, 1]\newline
[1, 1, 891, 26264, 84182, 9902, 1478, 8258, 57722, 38]\newline
[18, 20908, 3810, 65989, 7925, 204, 60423, 14, 1976, 18270]\newline
[927, 7100, 55495, 3289, 15, 44659, 17674, 9914, 6742, 61]\newline
[35, 45854, 1037, 33769, 14665, 6772, 2917, 4874, 12472, 378]\newline
[45469, 37198, 23804, 5302, 2657, 991, 261, 52, 2, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 10\newline
o valor com mais ocorrencias de uso de cpu é 09\newline
\end{minipage}}
\fbox{\begin{minipage}{\textwidth}
\textbf{logs insercao postgres_armhf_processados}\label{anexo:logs insercao postgres_armhf_processados.log}\newline
uso de ram\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 255, 7152, 16283]\newline
[32831, 19896, 2336, 2662, 4372, 6181, 7587, 12039, 10345, 12301]\newline
[15140, 20210, 21261, 22132, 25138, 25781, 24380, 24325, 25114, 28020]\newline
[33401, 32594, 36043, 34009, 37117, 38893, 37737, 39704, 44899, 44957]\newline
[44297, 46854, 46327, 49719, 51753, 48376, 52095, 58927, 59520, 68535]\newline
[73293, 80115, 79706, 61333, 40287, 26496, 17648, 11358, 6472, 2002]\newline
[577, 220, 94, 22, 80, 29, 4, 51, 100, 59]\newline
[72, 55, 24, 12, 3, 27, 121, 72, 70, 61]\newline
[71, 14, 7, 2, 2, 3, 1, 83, 61, 112]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de ram é de 60\newline
o valor com mais ocorrencias de uso de ram é 61\newline
\newline
\newline
\newline
uso de cpu\newline
[6, 12, 10, 28, 68, 588, 3618, 118494, 330874, 352961]\newline
[85, 10533, 4960, 2176, 16008, 92217, 623653, 285, 282050, 39]\newline
[7, 12853, 7361, 220074, 4, 274752, 2669, 134714, 22195, 439]\newline
[89115, 1320, 2, 169013, 19, 15285, 93588, 4316, 64198, 23]\newline
[36, 117739, 14214, 1406, 4456, 70651, 54517, 903, 19, 1]\newline
[0, 10, 934, 47887, 58121, 3592, 1484, 11312, 81406, 91]\newline
[69, 38937, 2630, 46263, 10104, 218, 75911, 31, 1597, 36127]\newline
[632, 9434, 43290, 3032, 46, 69151, 34191, 2579, 8050, 88]\newline
[52, 33862, 653, 46121, 23382, 6358, 2337, 1375, 1741, 188]\newline
[25154, 40896, 30033, 3361, 890, 339, 148, 70, 8, 0]\newline
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\newline
a faixa com mais ocorrencias de uso de cpu é de 20\newline
o valor com mais ocorrencias de uso de cpu é 16\newline
\end{minipage}}
\postextual


% ---------------------------------------------------------------------------------------------
% Referências bibliográficas
% ---------------------------------------------------------------------------------------------
\bibliography{abntex2-modelo-references}

% ---------------------------------------------------------------------------------------------
% Glossário
% ---------------------------------------------------------------------------------------------
%
% Consulte o manual da classe abntex2 para orientações sobre o glossário.
%
%\glossary

% ---------------------------------------------------------------------------------------------

% Anexos
% ---------------------------------------------------------------------------------------------

% ---
% Inicia os anexos
% ---

% ---------------------------------------------------------------------------------------------
% INDICE REMISSIVO
% ---------------------------------------------------------------------------------------------

\printindex

\end{document}
